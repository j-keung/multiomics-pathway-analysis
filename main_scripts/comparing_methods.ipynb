{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is used to 1.) construct the naive difference network, 2.) construct the differential network, 3.) construct a consensus network from the edges that are significant in both the naive difference network, which also can be used to compare the two methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing condition-specific networks (mild vs severe) with the full correlation results and then constructing the naive difference network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries \n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sspa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input is either: metabolomic, proteomic, integrated\n",
    "#FOR THE EDGES MUST SORT OUT INTO TUPLES AS SOME TUPLES ARE THE SAME BUT ARE IN A DIFFERENT ORDER\n",
    "#i.e.('R-HSA-192456', 'R-HSA-112315') and ('R-HSA-112315', 'R-HSA-192456')\n",
    "\n",
    "full_network = nx.read_gml(\"../Cytoscape/proteomic_final_commoncases.gml\")\n",
    "all_nodes = list(G.nodes())\n",
    "all_edges = list(G.edges())\n",
    "all_edges = [tuple(sorted(tuple1)) for tuple1 in all_edges]\n",
    "\n",
    "\n",
    "mild_network = nx.read_gml(\"../Cytoscape/proteomic_final_mildcases.gml\")\n",
    "mild_nodes = list(mild_network.nodes())\n",
    "mild_edges = list(mild_network.edges())\n",
    "mild_edges =  [tuple(sorted(tuple1)) for tuple1 in mild_edges]\n",
    "\n",
    "\n",
    "severe_network = nx.read_gml(\"../Cytoscape/proteomic_final_severecases.gml\")\n",
    "severe_nodes = list(severe_network.nodes())\n",
    "severe_edges = list(severe_network.edges())\n",
    "severe_edges = [tuple(sorted(tuple1)) for tuple1 in severe_edges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR THE EDGES MUST SORT OUT INTO TUPLES AS SOME TUPLES ARE THE SAME BUT ARE IN A DIFFERENT ORDER\n",
    "#i.e.('R-HSA-192456', 'R-HSA-112315') and ('R-HSA-112315', 'R-HSA-192456')\n",
    "\n",
    "#This code can be used to check which edges are the same but in a different order\n",
    "#Shouldn't be a problem now as the edges have been sorted as tuples\n",
    "for i in severe_edges:\n",
    "    for j in mild_edges:\n",
    "        edges_i = list(i)\n",
    "        edges_j = list(j)\n",
    "        if edges_i[0] == edges_j[1] and edges_j[0] == edges_i[1]:\n",
    "            print(edges_i, edges_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm that the mild and severe nodes DO NOT have new nodes that the full network doesn't\n",
    "print(\"Number of nodes in full correlation network: \", len(all_nodes))\n",
    "print(\"Number of nodes in mild network: \", len(mild_nodes))\n",
    "print(\"Number of nodes in severe network: \", len(severe_nodes))\n",
    "print(\"Number of nodes in both mild network and full correlation network: \", len(list(set(all_nodes).intersection(set(mild_nodes)))))\n",
    "print(\"Number of nodes in both severe network and full correlation network: \",len(list(set(all_nodes).intersection(set(severe_nodes)))))\n",
    "\n",
    "#Metabolomic severe network has 3 new nodes  #{'R-HSA-211859', 'R-HSA-5663205', 'R-HSA-9734207'}\n",
    "#Proteomic same nodes for all\n",
    "#Integrated mild network has 4 new nodes and severe network has 3 new nodes  #{'R-HSA-192105', 'R-HSA-193368', 'R-HSA-211976', 'R-HSA-5619084'} {'R-HSA-174824', 'R-HSA-83936', 'R-HSA-8956321'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find nodes which are present in mild/severe network not present in full network\n",
    "print(set((mild_nodes)).difference(set(all_nodes).intersection(set(mild_nodes))))\n",
    "print(set((severe_nodes)).difference(set(all_nodes).intersection(set(severe_nodes))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print out number of edges\n",
    "print(\"Number of edges in full correlation network: \",len(all_edges))\n",
    "print(\"Number of edges in mild network: \", len(mild_edges))\n",
    "print(\"Number of edges in severe network: \", len(severe_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example code from https://stackoverflow.com/questions/41125909/python-find-elements-in-one-list-that-are-not-in-the-other\n",
    "list_1=[\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
    "list_2=[\"a\", \"f\", \"c\", \"m\"]\n",
    "set(list_2) - set(list_1)\n",
    "\n",
    "#set(['f', 'm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Edges present in the mild network but not the severe network\n",
    "print(len(list(set(mild_edges) - set(severe_edges))))\n",
    "mild_naive = list(set(mild_edges) - set(severe_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Edges present in the severe network but not the mild network\n",
    "print(len(list(set(severe_edges) - set(mild_edges))))\n",
    "severe_naive = list(set(severe_edges) - set(mild_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Edges present in both mild and severe\n",
    "print(len(list(set(severe_edges) & set(mild_edges))))\n",
    "mild_severe_naive = list(set(severe_edges) & set(mild_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list(set(mild_naive) - set(all_edges)))) #Edges in the mild network (but not severe network) not in the full network         \n",
    "\n",
    "print(len(list(set(severe_naive) - set(all_edges)))) #Edges in the severe network (but not mild network) not in the full network \n",
    "\n",
    "print(len(list(set(mild_severe_naive) - set(all_edges)))) #Edges in the mild network AND severe network not in the full network\n",
    "\n",
    "print(len(all_edges)) #edges in full correlation network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary in which the naive difference network edges are classed as mild or severe\n",
    "mild_dict = {mild_naive[i]:\"Mild\" for i in range(0,len(mild_naive))}\n",
    "severe_dict = {severe_naive[i]:\"Severe\" for i in range(0,len(severe_naive))}\n",
    "\n",
    "condition_dict = mild_dict.copy()\n",
    "for key, value in severe_dict.items():\n",
    "    condition_dict[key] = value\n",
    "\n",
    "print(condition_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(condition_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the naive difference network\n",
    "G=nx.from_edgelist(mild_naive+severe_naive)\n",
    "print(len(G.edges()))\n",
    "nx.set_edge_attributes(G, condition_dict, \"Condition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the node attributes here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Must filter out some of the edges first\n",
    "\n",
    "#Add the betweenness centrality as a node attribute\n",
    "betweenness= nx.betweenness_centrality(G, normalized=True) #output as dictionary\n",
    "#display(betweenness)\n",
    "nx.set_node_attributes(G, betweenness, \"betweenness\")\n",
    "\n",
    "#Add the betweenness centrality as a node attribute\n",
    "degree= nx.degree_centrality(G) #output as dictionary\n",
    "#display(degree)\n",
    "nx.set_node_attributes(G, degree, \"degrees\")\n",
    "\n",
    "\n",
    "#Check\n",
    "print(G.number_of_nodes()) \n",
    "#G.nodes['R-HSA-110331']#[\"betweenness\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Cecilia's code\n",
    "\n",
    "#Creating graph\n",
    "hierarchy = pd.read_csv('../Data/ReactomePathwaysRelation.txt', sep='\\t', header=None)\n",
    "\n",
    "#From the pathways, subset to Homo sapiens only\n",
    "hierarchy_hsa = hierarchy[hierarchy[0].str.contains('HSA')]\n",
    "\n",
    "#Return unique values in the first column that is not in the second column as a numpy array\n",
    "#These values are not child pathways in any instances\n",
    "hierarchy_hsa_parents = np.setdiff1d(hierarchy_hsa[0], hierarchy_hsa[1])\n",
    "\n",
    "#Add the unique values not in the second column as a second attached dataset to the bottom of the original data\n",
    "#The first column represents the parent column, the second column is the child column\n",
    "hierarchy_hsa_all = pd.concat([hierarchy_hsa, pd.DataFrame([hierarchy_hsa_parents, hierarchy_hsa_parents], index=[0, 1]).T])\n",
    "\n",
    "#DiGraph is a directed graph\n",
    "H = nx.from_pandas_edgelist(hierarchy_hsa, source=0, target=1, create_using=nx.DiGraph())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert pathway ID to name\n",
    "root_path = pd.read_excel('../Data/Root_pathways.xlsx', header=None)\n",
    "root_pathway_dict = {root_path[0][i]:root_path[1][i] for i in range(0,len(root_path))}\n",
    "\n",
    "#Using Cecilia's code\n",
    "\n",
    "#Find the root pathway\n",
    "\n",
    "def find_root(H,child):\n",
    "    #Find parent from child \n",
    "    parent = list(H.predecessors(child))\n",
    "\n",
    "    #Keep the loop going until the highest level is reached\n",
    "    if len(parent) == 0:\n",
    "        return child\n",
    "    else:  \n",
    "        return find_root(H, parent[0])\n",
    "\n",
    "hierarchy_hsa_all['Root'] = [find_root(H, i) for i in hierarchy_hsa_all[1]]\n",
    "\n",
    "hierarchy_hsa_all.columns = ['Parent', 'Child', 'Root']\n",
    "\n",
    "#There are instances of duplicates, however all the child duplicates have the same root (even though different parents) after checking\n",
    "\n",
    "root_pathways = {}\n",
    "for pathway in list(H.nodes):\n",
    "    index = hierarchy_hsa_all.Child[hierarchy_hsa_all.Child == pathway].index.tolist()[0]\n",
    "    root_pathway  = hierarchy_hsa_all.Root[index]\n",
    "    label = root_pathway_dict[root_pathway]\n",
    "    root_pathways[pathway] = label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Cecilia's code\n",
    " \n",
    "#Shows all the root pathways in Reactome\n",
    "set(hierarchy_hsa_all['Root'] )\n",
    "#Shows all the root pathways present in the original dataset\n",
    "set(root_pathways.values())\n",
    "\n",
    "nx.set_node_attributes(G, root_pathways, \"root_pathway\")\n",
    "\n",
    "print(G.number_of_nodes()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering with Louvain algorithm\n",
    "\n",
    "#For some reason, not sure if really clustering by weight since it works with a typo \n",
    "#I think it works though, since changing the name gives a diff num of clusters even with seed set\n",
    "#Resolution = 1 is the default, increasing resolution will yield more communities\n",
    "louvain_clusters = nx.community.louvain_communities(G, weight='Squared_corr',seed=100,resolution=1.2)\n",
    "print(len(louvain_clusters))\n",
    "\n",
    "louvain_dict = {}\n",
    "for index,grouping in enumerate(louvain_clusters):\n",
    "    for pathway in grouping:\n",
    "        louvain_dict[pathway] = index+1\n",
    "\n",
    "nx.set_node_attributes(G, louvain_dict, \"louvain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign pathway name to node\n",
    "\n",
    "#If looking at metabolomic network:\n",
    "#reactome_pathways = sspa.process_gmt(\"../Data/Reactome_Homo_sapiens_pathways_compounds_R84.gmt\") \n",
    "\n",
    "#If looking at proteomic network:\n",
    "reactome_pathways = sspa.process_reactome('Homo sapiens', infile = '../Data/UniProt2Reactome_All_Levels_ver84.txt', download_latest = False, filepath = None)\n",
    "\n",
    "#If looking at integrated network:\n",
    "#reactome_pathways = pd.read_csv(\"../Data/Reactome_multi_omics_ChEBI_Uniprot.csv\", index_col=0,dtype=\"str\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign pathway name to node\n",
    "\n",
    "pathway_name_dict = {reactome_pathways.index[i]:reactome_pathways[\"Pathway_name\"][i] for i in range(0,len(reactome_pathways))}\n",
    "#Filter dictionary to the pathways in the dataset only\n",
    "pathway_name_dict = {k:pathway_name_dict[k] for k in list(G.nodes)}\n",
    "\n",
    "nx.set_node_attributes(G, pathway_name_dict, \"pathway_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save naive difference network\n",
    "\n",
    "#nx.write_gml(G,'../Cytoscape/metabolomic_naive_diff.gml')\n",
    "#nx.write_gml(G,'../Cytoscape/proteomic_naive_diff.gml')\n",
    "#nx.write_gml(G,'../Cytoscape/integrated_naive_diff.gml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing the differential networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the edges expressed in the differential network\n",
    "#with open('../Data/permutation_test_files_metabolomics/sig_edges.txt') as f:\n",
    "with open('../Data/permutation_test_files_proteomics/sig_edges.txt') as f:\n",
    "#with open('../Data/permutation_test_files_integrated/sig_edges.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "edges_remaining = []\n",
    "\n",
    "edges = lines[0].split(\",\")\n",
    "\n",
    "#Turn 'edges' into a tuple format to compare edges \n",
    "for index in range(0,len(edges),2):\n",
    "    list1 = edges[index],(edges[index+1][1:]) #becomes a tuple\n",
    "    edges_remaining.append(list1)\n",
    "\n",
    "#FOR THE EDGES MUST SORT OUT INTO TUPLES AS SOME TUPLES ARE THE SAME BUT ARE IN A DIFFERENT ORDER\n",
    "#i.e.('R-HSA-192456', 'R-HSA-112315') and ('R-HSA-112315', 'R-HSA-192456')\n",
    "edges_remaining =  [tuple(sorted(tuple1)) for tuple1 in edges_remaining]\n",
    "print(len(edges_remaining))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the directionality of the edges expressed in the differential network\n",
    "\n",
    "#with open('../Data/permutation_test_files_metabolomics/sigedge_direction.txt') as f:\n",
    "with open('../Data/permutation_test_files_proteomics/sigedge_direction.txt') as f:\n",
    "#with open('../Data/permutation_test_files_integrated/sigedge_direction.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    sigedge_direction = lines[0].split(\",\")\n",
    "\n",
    "print(len(sigedge_direction))\n",
    "print(sigedge_direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary where the edges are assigned the direction in which they are significantly expressed in\n",
    "\n",
    "condition_dict = {edges_remaining[i]:sigedge_direction[i] for i in range(0,len(sigedge_direction))}\n",
    "print(condition_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of all the mild and severe edges from differential network\n",
    "\n",
    "mild_diff_edges = []\n",
    "severe_diff_edges = []\n",
    "\n",
    "\n",
    "for key,value in condition_dict.items():\n",
    "    if value == \"mild\":\n",
    "        mild_diff_edges.append(key)\n",
    "    if value == \"severe\":\n",
    "        severe_diff_edges.append(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the differential network\n",
    "\n",
    "G=nx.from_edgelist(edges_remaining)\n",
    "print(len(G.edges()))\n",
    "nx.set_edge_attributes(G, condition_dict, \"Condition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code above in Section 1, that I used to construct the differential network for the condition-specific networks to add the node attributes, before running the cells underneath:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nx.write_gml(G,'../Cytoscape/metabolomic_differential.gml')\n",
    "#nx.write_gml(G,'../Cytoscape/proteomic_differential.gml')\n",
    "#nx.write_gml(G,'../Cytoscape/integrated_differential.gml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing the consensus network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even filtering at alpha < 1e-5 for the differential network, the proteomic and integrated network still leads to too many edges, so then I take the intersection of those edges with the ones from the condition-specific network to form the consensus network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load in the code from the first section to get the mild_naive and severe_naive list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the edges expressed in the differential network\n",
    "#with open('../Data/permutation_test_files_metabolomics/sig_edges.txt') as f:\n",
    "with open('../Data/permutation_test_files_proteomics/sig_edges.txt') as f:\n",
    "#with open('../Data/permutation_test_files_integrated/sig_edges.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "edges_remaining = []\n",
    "\n",
    "edges = lines[0].split(\",\")\n",
    "\n",
    "#Turn 'edges' into a tuple format to compare edges \n",
    "for index in range(0,len(edges),2):\n",
    "    list1 = edges[index],(edges[index+1][1:]) #becomes a tuple\n",
    "    edges_remaining.append(list1)\n",
    "\n",
    "#FOR THE EDGES MUST SORT OUT INTO TUPLES AS SOME TUPLES ARE THE SAME BUT ARE IN A DIFFERENT ORDER\n",
    "#i.e.('R-HSA-192456', 'R-HSA-112315') and ('R-HSA-112315', 'R-HSA-192456')\n",
    "edges_remaining =  [tuple(sorted(tuple1)) for tuple1 in edges_remaining]\n",
    "print(len(edges_remaining))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the directionality of the edges expressed in the differential network\n",
    "\n",
    "#with open('../Data/permutation_test_files_metabolomics/sigedge_direction.txt') as f:\n",
    "with open('../Data/permutation_test_files_proteomics/sigedge_direction.txt') as f:\n",
    "#with open('../Data/permutation_test_files_integrated/sigedge_direction.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    sigedge_direction = lines[0].split(\",\")\n",
    "\n",
    "print(len(sigedge_direction))\n",
    "print(sigedge_direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection1 = list(set(mild_diff_edges).intersection(list(set(mild_naive))))  \n",
    "len(intersection1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection2 = list(set(severe_diff_edges).intersection(list(set(severe_naive)))) \n",
    "len(intersection2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_for_consensus_network = intersection1 + intersection2\n",
    "\n",
    "mild_dict = {intersection1[i]:\"Mild\" for i in range(0,len(intersection1))}\n",
    "severe_dict = {intersection2[i]:\"Severe\" for i in range(0,len(intersection2))}\n",
    "\n",
    "condition_dict = mild_dict.copy()\n",
    "for key, value in severe_dict.items():\n",
    "    condition_dict[key] = value\n",
    "\n",
    "print(condition_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overlap of mild naive network and severe differential network (should be 0)\n",
    "intersection = list(set(severe_diff_edges).intersection(list(set(mild_naive))))  \n",
    "len(intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overlap of severe naive network and mild differential network (should be 0)\n",
    "intersection = list(set(mild_diff_edges).intersection(list(set(severe_naive))))  \n",
    "len(intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#edges_remaining = all edges in the differential network\n",
    "#Overlap of differential network edges and edges in both the mild and severe network (should be 0)\n",
    "\n",
    "intersection = list(set(edges_remaining).intersection(list(set(mild_severe_naive)))) \n",
    "len(intersection) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overlap of all differential network edges with all edges in the full correlation network\n",
    "intersection = list(set(edges_remaining).intersection(list(set(all_edges))))   \n",
    "len(intersection) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=nx.from_edgelist(edges_for_consensus_network)\n",
    "print(len(G.edges()))\n",
    "nx.set_edge_attributes(G, condition_dict, \"Condition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code above in Section 1, that I used to construct the differential network for the condition-specific networks to add the node attributes, before running the cells underneath:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No overlap between metabolomic and naive differential network,so don't need to re-do\n",
    "#nx.write_gml(G,'../Cytoscape/proteomic_differential_intersect.gml') \n",
    "#nx.write_gml(G,'../Cytoscape/integrated_differential_intersect.gml')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Imperial_Project2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
