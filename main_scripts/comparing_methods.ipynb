{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the difference in edges with other networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing condition-specific networks (mild vs severe) with the full correlation results and then constructing the naive difference network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sspa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mild_network = nx.read_gml(\"../Cytoscape/metabolomic_final_mildcases.gml\")\n",
    "mild_nodes = list(mild_network.nodes())\n",
    "\n",
    "severe_network = nx.read_gml(\"../Cytoscape/metabolomic_final_severecases.gml\")\n",
    "severe_nodes = list(severe_network.nodes())\n",
    "\n",
    "G = nx.read_gml(\"../Cytoscape/metabolomic_final_commoncases.gml\")\n",
    "all_edges = list(G.edges())\n",
    "all_nodes = list(G.nodes())\n",
    "len(all_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mild_network = nx.read_gml(\"../Cytoscape/proteomic_final_mildcases.gml\")\n",
    "mild_nodes = list(mild_network.nodes())\n",
    "\n",
    "severe_network = nx.read_gml(\"../Cytoscape/proteomic_final_severecases.gml\")\n",
    "severe_nodes = list(severe_network.nodes())\n",
    "\n",
    "G = nx.read_gml(\"../Cytoscape/proteomic_final_commoncases.gml\")\n",
    "all_edges = list(G.edges())\n",
    "all_nodes = list(G.nodes())\n",
    "len(all_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mild_network = nx.read_gml(\"../Cytoscape/integrated_final_mildcases.gml\")\n",
    "mild_nodes = list(mild_network.nodes())\n",
    "\n",
    "severe_network = nx.read_gml(\"../Cytoscape/integrated_final_severecases.gml\")\n",
    "severe_nodes = list(severe_network.nodes())\n",
    "\n",
    "G = nx.read_gml(\"../Cytoscape/integrated_final_commoncases.gml\")\n",
    "all_edges = list(G.edges())\n",
    "all_nodes = list(G.nodes())\n",
    "len(all_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm that the mild and severe nodes DO NOT have new nodes that the full network doesn't\n",
    "print(len(all_nodes))\n",
    "print(len(mild_nodes))\n",
    "print(len(severe_nodes))\n",
    "print(len(list(set(all_nodes).intersection(set(mild_nodes)))))\n",
    "print(len(list(set(all_nodes).intersection(set(severe_nodes)))))\n",
    "\n",
    "#Metabolomic severe network has 3 new nodes  #{'R-HSA-211859', 'R-HSA-5663205', 'R-HSA-9734207'}\n",
    "#Proteomic same nodes for all\n",
    "#Integrated mild network has 4 new nodes and severe network has 3 new nodes  #{'R-HSA-192105', 'R-HSA-193368', 'R-HSA-211976', 'R-HSA-5619084'} {'R-HSA-174824', 'R-HSA-83936', 'R-HSA-8956321'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find nodes which are present in mild/severe network not present in full network\n",
    "set((mild_nodes)).difference(set(all_nodes).intersection(set(mild_nodes)))\n",
    "set((severe_nodes)).difference(set(all_nodes).intersection(set(severe_nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mild_edges = list(mild_network.edges())\n",
    "print(len(mild_edges))\n",
    "severe_edges = list(severe_network.edges())\n",
    "print(len(severe_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example code from https://stackoverflow.com/questions/41125909/python-find-elements-in-one-list-that-are-not-in-the-other\n",
    "list_1=[\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
    "list_2=[\"a\", \"f\", \"c\", \"m\"]\n",
    "set(list_2) - set(list_1)\n",
    "\n",
    "#set(['m', 'f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Edges present in the mild network but not the severe network\n",
    "print(len(list(set(mild_edges) - set(severe_edges))))\n",
    "mild_naive = list(set(mild_edges) - set(severe_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Edges present in the severe network but not the mild network\n",
    "print(len(list(set(severe_edges) - set(mild_edges))))\n",
    "severe_naive = list(set(severe_edges) - set(mild_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Edges present in both mild and severe\n",
    "print(len(list(set(severe_edges) & set(mild_edges))))\n",
    "mild_severe_naive = list(set(severe_edges) & set(mild_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list(set(mild_naive) - set(all_edges)))) #Edges in the mild network (but not severe network) not in the full network\n",
    "\n",
    "print(len(list(set(severe_naive) - set(all_edges)))) #Edges in the severe network (but not mild network) not in the full network\n",
    "\n",
    "print(len(list(set(mild_severe_naive) - set(all_edges)))) #Edges in the mild network AND severe network not in the full network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mild_dict = {mild_naive[i]:\"Mild\" for i in range(0,len(mild))}\n",
    "severe_dict = {severe_naive[i]:\"Severe\" for i in range(0,len(severe))}\n",
    "\n",
    "condition_dict = mild_dict.copy()\n",
    "for key, value in severe_dict.items():\n",
    "    condition_dict[key] = value\n",
    "\n",
    "print(condition_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=nx.from_edgelist(mild_naive+severe_naive)\n",
    "len(G.edges())\n",
    "nx.set_edge_attributes(G, condition_dict, \"Condition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IF YOU DON'T REMOVE THE EDGES, DON'T RUN THIS CODE\n",
    "\n",
    "#Add the betweenness centrality as a node attribute\n",
    "betweenness= nx.betweenness_centrality(G, normalized=True) #output as dictionary\n",
    "#display(betweenness)\n",
    "nx.set_node_attributes(G, betweenness, \"betweenness\")\n",
    "\n",
    "#Add the betweenness centrality as a node attribute\n",
    "degree= nx.degree_centrality(G) #output as dictionary\n",
    "#display(degree)\n",
    "nx.set_node_attributes(G, degree, \"degrees\")\n",
    "\n",
    "\n",
    "#Check\n",
    "print(G.number_of_nodes()) \n",
    "#G.nodes['R-HSA-110331']#[\"betweenness\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Cecilia's code\n",
    "\n",
    "#Creating graph\n",
    "hierarchy = pd.read_csv('../Data/ReactomePathwaysRelation.txt', sep='\\t', header=None)\n",
    "\n",
    "#From the pathways, subset to Homo sapiens only\n",
    "hierarchy_hsa = hierarchy[hierarchy[0].str.contains('HSA')]\n",
    "\n",
    "#Return unique values in the first column that is not in the second column as a numpy array\n",
    "#These values are not child pathways in any instances\n",
    "hierarchy_hsa_parents = np.setdiff1d(hierarchy_hsa[0], hierarchy_hsa[1])\n",
    "\n",
    "#Add the unique values not in the second column as a second attached dataset to the bottom of the original data\n",
    "#The first column represents the parent column, the second column is the child column\n",
    "hierarchy_hsa_all = pd.concat([hierarchy_hsa, pd.DataFrame([hierarchy_hsa_parents, hierarchy_hsa_parents], index=[0, 1]).T])\n",
    "\n",
    "#DiGraph is a directed graph\n",
    "H = nx.from_pandas_edgelist(hierarchy_hsa, source=0, target=1, create_using=nx.DiGraph())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert pathway ID to name\n",
    "root_path = pd.read_excel('../Data/Root_pathways.xlsx', header=None)\n",
    "root_pathway_dict = {root_path[0][i]:root_path[1][i] for i in range(0,len(root_path))}\n",
    "\n",
    "#Using Cecilia's code\n",
    "\n",
    "#Find the root pathway\n",
    "\n",
    "def find_root(H,child):\n",
    "    #Find parent from child \n",
    "    parent = list(H.predecessors(child))\n",
    "\n",
    "    #Keep the loop going until the highest level is reached\n",
    "    if len(parent) == 0:\n",
    "        return child\n",
    "    else:  \n",
    "        return find_root(H, parent[0])\n",
    "\n",
    "hierarchy_hsa_all['Root'] = [find_root(H, i) for i in hierarchy_hsa_all[1]]\n",
    "\n",
    "hierarchy_hsa_all.columns = ['Parent', 'Child', 'Root']\n",
    "\n",
    "#There are instances of duplicates, however all the child duplicates have the same root (even though different parents) after checking\n",
    "\n",
    "root_pathways = {}\n",
    "for pathway in list(H.nodes):\n",
    "    index = hierarchy_hsa_all.Child[hierarchy_hsa_all.Child == pathway].index.tolist()[0]\n",
    "    root_pathway  = hierarchy_hsa_all.Root[index]\n",
    "    label = root_pathway_dict[root_pathway]\n",
    "    root_pathways[pathway] = label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Cecilia's code\n",
    " \n",
    "#Shows all the root pathways in Reactome\n",
    "set(hierarchy_hsa_all['Root'] )\n",
    "#Shows all the root pathways present in the original dataset\n",
    "set(root_pathways.values())\n",
    "\n",
    "nx.set_node_attributes(G, root_pathways, \"root_pathway\")\n",
    "\n",
    "print(G.number_of_nodes()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering with Louvain algorithm\n",
    "\n",
    "#For some reason, not sure if really clustering by weight since it works with a typo \n",
    "#I think it works though, since changing the name gives a diff num of clusters even with seed set\n",
    "#Resolution = 1 is the default, increasing resolution will yield more communities\n",
    "louvain_clusters = nx.community.louvain_communities(G, weight='Squared_corr',seed=100,resolution=1.2)\n",
    "print(len(louvain_clusters))\n",
    "\n",
    "louvain_dict = {}\n",
    "for index,grouping in enumerate(louvain_clusters):\n",
    "    for pathway in grouping:\n",
    "        louvain_dict[pathway] = index+1\n",
    "\n",
    "nx.set_node_attributes(G, louvain_dict, \"louvain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign pathway name to node\n",
    "\n",
    "#Metabolomic:\n",
    "#reactome_pathways = sspa.process_gmt(\"../Data/Reactome_Homo_sapiens_pathways_compounds_R84.gmt\") \n",
    "\n",
    "#Proteomic:\n",
    "#reactome_pathways = sspa.process_reactome('Homo sapiens', infile = '../Data/UniProt2Reactome_All_Levels_ver84.txt', download_latest = False, filepath = None)\n",
    "\n",
    "#Integrated:\n",
    "reactome_pathways = pd.read_csv(\"../Data/Reactome_multi_omics_ChEBI_Uniprot.csv\", index_col=0,dtype=\"str\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pathway_name_dict = {reactome_pathways.index[i]:reactome_pathways[\"Pathway_name\"][i] for i in range(0,len(reactome_pathways))}\n",
    "#pathway_name_dict['R-HSA-1483257']\n",
    "pathway_name_dict = {k:pathway_name_dict[k] for k in list(G.nodes)}\n",
    "\n",
    "nx.set_node_attributes(G, pathway_name_dict, \"pathway_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nx.write_gml(G,'../Cytoscape/metabolomic_condition_diff.gml')\n",
    "#nx.write_gml(G,'../Cytoscape/proteomic_condition_diff.gml')\n",
    "#nx.write_gml(G,'../Cytoscape/integrated_condition_diff.gml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a graph for the differential networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the edges expressed in the differential network\n",
    "#with open('../Data/permutation_test_files_metabolomics/sig_edges.txt') as f:\n",
    "#with open('../Data/permutation_test_files_proteomics/sig_edges.txt') as f:\n",
    "with open('../Data/permutation_test_files_integrated/sig_edges.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "edges_remaining = []\n",
    "\n",
    "edges = lines[0].split(\",\")\n",
    "\n",
    "for index in range(0,len(edges),2):\n",
    "    list1 = edges[index],(edges[index+1][1:]) #becomes a tuple\n",
    "    edges_remaining.append(list1)\n",
    "\n",
    "print(len(edges_remaining))\n",
    "#edges_remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the edges expressed in the differential network\n",
    "#with open('../Data/permutation_test_files_metabolomics/sigedge_direction.txt') as f:\n",
    "#with open('../Data/permutation_test_files_proteomics/sigedge_direction.txt') as f:\n",
    "with open('../Data/permutation_test_files_integrated/sigedge_direction.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    sigedge_direction = lines[0].split(\",\")\n",
    "\n",
    "print(len(sigedge_direction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_dict = {edges_remaining[i]:sigedge_direction[i] for i in range(0,len(sigedge_direction))}\n",
    "print(condition_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=nx.from_edgelist(edges_remaining)\n",
    "print(len(G.edges()))\n",
    "nx.set_edge_attributes(G, condition_dict, \"Condition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For intersectional network only\n",
    "#First load in the mild naive and severe naive edges at the top\n",
    "#Then go down to the below section and re-make the condition dict\n",
    "G=nx.from_edgelist(edges_for_intersection_network)\n",
    "print(len(G.edges()))\n",
    "nx.set_edge_attributes(G, condition_dict, \"Condition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code above that I used to construct the differential network for the condition-specific networks to add the node attributes, before running the cells underneath:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nx.write_gml(G,'../Cytoscape/metabolomic_differential.gml')\n",
    "#nx.write_gml(G,'../Cytoscape/proteomic_differential.gml')\n",
    "#nx.write_gml(G,'../Cytoscape/integrated_differential.gml')\n",
    "\n",
    "#No overlap between metabolomic and naive differential network,so don't need to re-do\n",
    "#nx.write_gml(G,'../Cytoscape/proteomic_differential_intersect.gml') #142 nodes, 185 edges\n",
    "#nx.write_gml(G,'../Cytoscape/integrated_differential_intersect.gml') #122 nodes,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if there are nodes in the differential network not in full correlation network\n",
    "diff_nodes = list(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#H = nx.read_gml(\"../Cytoscape/metabolomic_final_commoncases.gml\")\n",
    "#H = nx.read_gml(\"../Cytoscape/proteomic_final_commoncases.gml\")\n",
    "H = nx.read_gml(\"../Cytoscape/integrated_final_commoncases.gml\")\n",
    "all_nodes = list(H.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm that the mild and severe nodes DO NOT have new nodes that the full network doesn't\n",
    "print(len(all_nodes))\n",
    "print(len(diff_nodes))\n",
    "print(len(list(set(all_nodes).intersection(set(diff_nodes)))))\n",
    "\n",
    "#Metabolomic differential network has 4 new nodes  \n",
    "#Proteomic differential network has 1 new node \n",
    "#Integrated differential network has 11 new nodes\n",
    "\n",
    "#Proteomic differential intersectional network has 0 new nodes  \n",
    "#Integrated differential intersectional network has 1 new node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find nodes which are present in mild/severe network not present in full network\n",
    "list(set((diff_nodes)).difference(set(all_nodes).intersection(set(diff_nodes))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing edges in the condition-specific networks to the differential networks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Must load in the code from previous section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even filtering at alpha == 0 for the differential network, for the proteomic and integrated network this still leads to too many edges, so then I take the intersection of those edges with the ones from the condition-specific network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mild_diff_edges = []\n",
    "severe_diff_edges = []\n",
    "\n",
    "for key,value in condition_dict.items():\n",
    "    if value == \"mild\":\n",
    "        mild_diff_edges.append(key)\n",
    "    if value == \"severe\":\n",
    "        severe_diff_edges.append(key)\n",
    "\n",
    "print(len(mild_diff_edges))\n",
    "print(len(severe_diff_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection1 = list(set(mild_diff_edges).intersection(list(set(mild_naive))))  \n",
    "len(intersection1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection2 = list(set(severe_diff_edges).intersection(list(set(severe_naive)))) \n",
    "len(intersection2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR INTERSECTION NETWORK, remake condition dictionary since we are only interested in p-values of zero\n",
    "\n",
    "edges_for_intersection_network = intersection1 + intersection2\n",
    "\n",
    "mild_dict = {intersection1[i]:\"Mild\" for i in range(0,len(intersection1))}\n",
    "severe_dict = {intersection2[i]:\"Severe\" for i in range(0,len(intersection2))}\n",
    "\n",
    "condition_dict = mild_dict.copy()\n",
    "for key, value in severe_dict.items():\n",
    "    condition_dict[key] = value\n",
    "\n",
    "print(condition_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = list(set(severe_diff_edges).intersection(list(set(mild_naive))))  \n",
    "len(intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = list(set(mild_diff_edges).intersection(list(set(severe_naive))))  \n",
    "len(intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = list(set(edges_remaining).intersection(list(set(mild_severe_naive)))) \n",
    "len(intersection) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = list(set(edges_remaining).intersection(list(set(all_edges))))   #intersection of all differential edges with all edges in the full correlation network\n",
    "len(intersection) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing with the significant edges BETWEEN the differential networks for all omics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_num (omics):\n",
    "    with open('../Data/permutation_test_files_'+omics+'/sig_edges.txt') as f:\n",
    "        lines = f.readlines()\n",
    "    edges_remaining = []\n",
    "    edges = lines[0].split(\",\")\n",
    "\n",
    "    for index in range(0,len(edges),2):\n",
    "        list1 = edges[index],(edges[index+1][1:]) #becomes a tuple\n",
    "        edges_remaining.append(list1)\n",
    "\n",
    "    return edges_remaining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteomic_edges = edge_num('proteomics')\n",
    "integrated_edges = edge_num('integrated')\n",
    "metabolomic_edges = edge_num('metabolomics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(proteomic_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = list(set(metabolomic_edges).intersection(list(set(proteomic_edges))))  \n",
    "len(intersection) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = list(set(integrated_edges).intersection(list(set(metabolomic_edges))))  \n",
    "len(intersection) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = list(set(integrated_edges).intersection(list(set(proteomic_edges))))  \n",
    "len(intersection) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = (set(metabolomic_edges) & set(proteomic_edges) & set(integrated_edges))  \n",
    "len(intersection) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(set(integrated_edges) - (set(metabolomic_edges)|set(proteomic_edges)))) #Pathway pairs for integrated data not detected by either single omics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get number of common pathways between the three omics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sspa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabolomic_df = pd.read_csv('../Data/Su_COVID_metabolomics_processed_commoncases.csv', index_col=0)\n",
    "proteomic_df = pd.read_csv('../Data/Su_COVID_proteomics_processed_commoncases.csv', index_col=0)\n",
    "integrated_df = pd.read_csv(\"../Data/Su_integrated_data.csv\", index_col=0)\n",
    "\n",
    "#Remove root pathways\n",
    "#Convert pathway ID to name\n",
    "root_path = pd.read_excel('../Data/Root_pathways.xlsx', header=None)\n",
    "root_pathway_dict = {root_path[0][i]:root_path[1][i] for i in range(0,len(root_path))}\n",
    "root_pathway_names = list(root_pathway_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactome_pathways = sspa.process_gmt(\"../Data/Reactome_Homo_sapiens_pathways_compounds_R84.gmt\")\n",
    "kpca_scores = sspa.sspa_kpca(metabolomic_df.iloc[:,:-2], reactome_pathways)\n",
    "\n",
    "#Using Sara's code\n",
    "kpca_scores = kpca_scores.drop(columns = list(set(root_pathway_names) & set(kpca_scores.columns)))\n",
    "\n",
    "metabolomic_pathways = kpca_scores.columns\n",
    "metabolomic_pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in a file downloaded from https://reactome.org/download/current/UniProt2Reactome_All_Levels.txt\n",
    "reactome_pathways = sspa.process_reactome('Homo sapiens', infile = '../Data/UniProt2Reactome_All_Levels_ver84.txt', download_latest = False, filepath = None)\n",
    "kpca_scores = sspa.sspa_kpca(proteomic_df.iloc[:,:-2], reactome_pathways)\n",
    "\n",
    "#Using Sara's code\n",
    "kpca_scores = kpca_scores.drop(columns = list(set(root_pathway_names) & set(kpca_scores.columns)))\n",
    "\n",
    "proteomic_pathways = kpca_scores.columns\n",
    "proteomic_pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactome_pathways = pd.read_csv(\"../Data/Reactome_multi_omics_ChEBI_Uniprot.csv\", index_col=0,dtype=\"str\")\n",
    "kpca_scores = sspa.sspa_kpca(integrated_df.iloc[:,:-2], reactome_pathways)\n",
    "\n",
    "#Using Sara's code\n",
    "kpca_scores = kpca_scores.drop(columns = list(set(root_pathway_names) & set(kpca_scores.columns)))\n",
    "\n",
    "integrated_pathways = kpca_scores.columns\n",
    "integrated_pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = list(set(metabolomic_pathways).intersection(list(set(proteomic_pathways))))   #47 pathways\n",
    "intersection = (set(metabolomic_pathways) & set(proteomic_pathways) & set(integrated_pathways))  #47 pathways \n",
    "\n",
    "intersection = list(set(metabolomic_pathways).intersection(list(set(integrated_pathways))))  #144 pathways (same as number of metabolomic)\n",
    "intersection = list(set(proteomic_pathways).intersection(list(set(integrated_pathways))))  #578 pathways (same as number of proteomic)\n",
    "\n",
    "#710 pathways in integrated dataset\n",
    "#((144+578)-47+35)\n",
    "\n",
    "len(list(set(integrated_pathways) - (set(metabolomic_pathways)|set(proteomic_pathways)))) #35 pathways for integrated data not detected by either single omics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pathways = list(set(integrated_pathways) - (set(metabolomic_pathways)|set(proteomic_pathways)))\n",
    "new_pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get number of pathways that have been influenced\n",
    "\n",
    "df = pd.read_csv(\"../Data/Su_integrated_data.csv\", index_col=0)\n",
    "reactome_pathways = pd.read_csv(\"../Data/Reactome_multi_omics_ChEBI_Uniprot.csv\", index_col=0,dtype=\"str\")\n",
    "\n",
    "\n",
    "kpca_scores = sspa.sspa_kpca(integrated_df.iloc[:,:-2], reactome_pathways)\n",
    "\n",
    "#Using Sara's code\n",
    "kpca_scores = kpca_scores.drop(columns = list(set(root_pathway_names) & set(kpca_scores.columns)))\n",
    "\n",
    "#Obtain pathways and corresponding metabolites for all Reactome pathways, store as dictionary\n",
    "orig_dict = sspa.utils.pathwaydf_to_dict(reactome_pathways)\n",
    "\n",
    "#Filter out dictionary to retain only the pathways that remain after kPCA\n",
    "my_keys = kpca_scores.columns\n",
    "pathways_dict = {key: orig_dict[key] for key in my_keys}\n",
    "\n",
    "#Filter out the compounds in the pathways that are not present in the dataset\n",
    "\n",
    "#Obtain all unique values in dataset\n",
    "compounds_present = list(df.columns[:-2])\n",
    "filtered_dict = {} \n",
    "\n",
    "#My code adapted from Cecilia's\n",
    "#If the key values are not part of the compounds in dataset then remove\n",
    "for key,value in pathways_dict.items():\n",
    "    new_val = [item for item in value if item in compounds_present]\n",
    "    if len(new_val) >= 2: #at least two compounds in the pathway\n",
    "        filtered_dict[key] = new_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All 35 new pathways comprised of one metabolite and one protein\n",
    "\n",
    "proteomic_only_pathway = []\n",
    "proteomic_pathway_with_onemetabolite = []\n",
    "metabolomic_only_pathway = []\n",
    "metabolomic_pathway_with_oneprotein = []\n",
    "both_omic = []\n",
    "new_pathway = []\n",
    "\n",
    "for key,values in filtered_dict.items():\n",
    "    #if key in new_pathways:\n",
    "        #print(values)\n",
    "    #print(values)\n",
    "    proteomic=False\n",
    "    metabolomic=False\n",
    "    both=False\n",
    "\n",
    "\n",
    "    proteins = 0\n",
    "    metabolites = 0\n",
    "\n",
    "    for value in values:\n",
    "\n",
    "        if value[0].isalpha():\n",
    "            proteins += 1\n",
    "        else:\n",
    "            metabolites += 1\n",
    "\n",
    "    \n",
    "    if metabolites == 0:\n",
    "        proteomic_only_pathway.append(key)\n",
    "    if proteins > 1 and metabolites == 1:\n",
    "        proteomic_pathway_with_onemetabolite.append(key)\n",
    "    \n",
    "    if proteins == 0:\n",
    "        metabolomic_only_pathway.append(key)\n",
    "    if metabolites > 1 and proteins == 1:\n",
    "        metabolomic_pathway_with_oneprotein.append(key)\n",
    "\n",
    "    if metabolites > 1 and proteins > 1:\n",
    "        both_omic.append(key)\n",
    "    if proteins == 1 and metabolites == 1:\n",
    "        new_pathway.append(key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(proteomic_only_pathway))\n",
    "print(len(proteomic_pathway_with_onemetabolite))\n",
    "print(len(metabolomic_only_pathway))\n",
    "print(len(metabolomic_pathway_with_oneprotein))\n",
    "print(len(both_omic))\n",
    "print(len(new_pathway))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the initial test statistics of the three omics to see which edges were affected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the initial test statistics of the integrated data with the proteomic initial test statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "metabolomic = pd.read_csv('../Data/permutation_test_files_metabolomics/initial_tstats.csv', index_col=0)\n",
    "proteomic = pd.read_csv('../Data/permutation_test_files_proteomics/initial_tstats.csv', index_col=0)\n",
    "integrated = pd.read_csv('../Data/permutation_test_files_integrated/initial_tstats.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabolomic = metabolomic.rename(columns={'Initial_tstat': 'metabolomic_tstat'})\n",
    "proteomic = proteomic.rename(columns={'Initial_tstat': 'proteomic_tstat'})\n",
    "integrated = integrated.rename(columns={'Initial_tstat': 'integrated_tstat'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteomic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_tstat_comp = proteomic.join(integrated)\n",
    "initial_tstat_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of pathway pairs with initial test statistic that are the same\n",
    "\n",
    "proteomic_only_edge = []\n",
    "metabolomic_influence_edge = []\n",
    "counter = 0\n",
    "\n",
    "for edge in initial_tstat_comp.index:\n",
    "    if initial_tstat_comp.loc[edge].proteomic_tstat == initial_tstat_comp.loc[edge].integrated_tstat:\n",
    "        proteomic_only_edge.append(edge)\n",
    "        counter += 1\n",
    "    else:\n",
    "        metabolomic_influence_edge.append(edge)\n",
    "\n",
    "\n",
    "print(counter)\n",
    "\n",
    "#166,753 edges of the proteomic initial test statistic dataset are all included in the integrated initial test statistic data\n",
    "#117,381 edges out of 166,753 are identical\n",
    "#Therefore 49,372 edges were influenced by the metabolomic data\n",
    "\n",
    "len(metabolomic_influence_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to tuple format so you can compare with the significant edges\n",
    "\n",
    "metabolomic_influence_edge_tuple = []\n",
    "for i in range(len(metabolomic_influence_edge)):\n",
    "    edge = metabolomic_influence_edge[i].split(\",\")\n",
    "    edge = (edge[0],edge[1][1:])\n",
    "    #edge = tuple(sorted(edge))\n",
    "    metabolomic_influence_edge_tuple.append(edge)\n",
    "\n",
    "\n",
    "proteomic_only_edge_tuple  = []\n",
    "for i in range(len(proteomic_only_edge )):\n",
    "    edge = proteomic_only_edge [i].split(\",\")\n",
    "    edge = (edge[0],edge[1][1:])\n",
    "    #edge = tuple(sorted(edge))\n",
    "    proteomic_only_edge_tuple.append(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to see proportion of metabolomic-influenced edges that are significantly differentially expressed edges (from differential network) in the proteomic data vs the integrated data\n",
    "print(len(metabolomic_influence_edge))\n",
    "print(len(list(set(proteomic_edges).intersection(set(metabolomic_influence_edge_tuple))))) #680 edges significant\n",
    "print(len(list(set(integrated_edges).intersection(set(metabolomic_influence_edge_tuple))))) #After integrating with the metabolomic data, 765 significant\n",
    "\n",
    "\n",
    "#290 edges are the same between 680 edges and 765 edges\n",
    "list1 = list(set(proteomic_edges).intersection(set(metabolomic_influence_edge_tuple)))\n",
    "list2 = list(set(integrated_edges).intersection(set(metabolomic_influence_edge_tuple)))\n",
    "len(list(set(list1).intersection(set(list2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Showing that 'Metabolomic influenced' proteomic pathways that are significant in the differential network are instances where at least one pathway is a common pathway OR one pathway is influenced by one metabolite (not enough to be considered a pathway in the metabolomic set)\n",
    "\n",
    "list1 = list(set(proteomic_edges).intersection(set(metabolomic_influence_edge_tuple)))\n",
    "\n",
    "common_pathways = list(set(proteomic_pathways) & set(metabolomic_pathways))\n",
    "print(len(common_pathways))\n",
    "counter = 0 \n",
    "\n",
    "influenced_noncommon_pathway_pair = []\n",
    "for edges in list1:\n",
    "    pathway_pair = list(edges)\n",
    "    if (pathway_pair[0] in common_pathways) or (pathway_pair[1] in common_pathways):\n",
    "        #print(pathway_pair)\n",
    "        counter += 1\n",
    "    else:\n",
    "        influenced_noncommon_pathway_pair.append(edges)\n",
    "\n",
    "\n",
    "print(counter)\n",
    "#327 pathway pairs have one common pathway in them, out of the differentially expressed protein pathways in the network that are influenced by the metabolomics dataset\n",
    "#The other cases are where there is one metabolite added to one of the pathways that is not enough to be constituted as a pathway in the metabolomics dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can look at the pathways before and after integration to prove that for the non-common pathways that are influenced by the other omics, there is only one analyte from the other dataset added to it\n",
    "\n",
    "\n",
    "#df = pd.read_csv('../Data/Su_COVID_metabolomics_processed_commoncases.csv', index_col=0)\n",
    "#reactome_pathways = sspa.process_gmt(\"../Data/Reactome_Homo_sapiens_pathways_compounds_R84.gmt\")\n",
    "\n",
    "df = pd.read_csv(\"../Data/Su_integrated_data.csv\", index_col=0)\n",
    "reactome_pathways = pd.read_csv(\"../Data/Reactome_multi_omics_ChEBI_Uniprot.csv\", index_col=0,dtype=\"str\")\n",
    "\n",
    "\n",
    "kpca_scores = sspa.sspa_kpca(integrated_df.iloc[:,:-2], reactome_pathways)\n",
    "\n",
    "#Using Sara's code\n",
    "kpca_scores = kpca_scores.drop(columns = list(set(root_pathway_names) & set(kpca_scores.columns)))\n",
    "\n",
    "#Obtain pathways and corresponding metabolites for all Reactome pathways, store as dictionary\n",
    "orig_dict = sspa.utils.pathwaydf_to_dict(reactome_pathways)\n",
    "\n",
    "#Filter out dictionary to retain only the pathways that remain after kPCA\n",
    "my_keys = kpca_scores.columns\n",
    "pathways_dict = {key: orig_dict[key] for key in my_keys}\n",
    "\n",
    "#Filter out the compounds in the pathways that are not present in the dataset\n",
    "\n",
    "#Obtain all unique values in dataset\n",
    "compounds_present = list(df.columns[:-2])\n",
    "filtered_dict = {} \n",
    "\n",
    "#My code adapted from Cecilia's\n",
    "#If the key values are not part of the compounds in dataset then remove\n",
    "for key,value in pathways_dict.items():\n",
    "    new_val = [item for item in value if item in compounds_present]\n",
    "    if len(new_val) >= 2: #at least two compounds in the pathway\n",
    "        filtered_dict[key] = new_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(influenced_noncommon_pathway_pair)\n",
    "list(reactome_pathways.loc['R-HSA-422475'])  #All proteins, only one metabolite\n",
    "filtered_dict['R-HSA-422475']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the initial test statistics of the integrated data with the metabolomic initial test statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_tstat_comp = metabolomic.join(integrated)\n",
    "initial_tstat_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of pathway pairs with initial test statistic that are the same\n",
    "metabolomic_only_edge = []\n",
    "proteomic_influence_edge = []\n",
    "\n",
    "counter = 0\n",
    "for edge in initial_tstat_comp.index:\n",
    "    if initial_tstat_comp.loc[edge].metabolomic_tstat == initial_tstat_comp.loc[edge].integrated_tstat:\n",
    "        metabolomic_only_edge.append(edge)\n",
    "        counter += 1\n",
    "    else:\n",
    "        proteomic_influence_edge.append(edge)\n",
    "\n",
    "print(counter)\n",
    "\n",
    "#10,296 edges of the metabolomic initial test statistic dataset are all included in the integrated initial test statistic data\n",
    "#2,088 edges out of 10,296 are identical\n",
    "#Therefore 8,208 edges were influenced by the proteomic data\n",
    "\n",
    "proteomic_influence_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteomic_influence_edge_tuple = []\n",
    "for i in range(len(proteomic_influence_edge)):\n",
    "    edge = proteomic_influence_edge[i].split(\",\")\n",
    "    edge = (edge[0],edge[1][1:])\n",
    "    #edge = tuple(sorted(edge))\n",
    "    proteomic_influence_edge_tuple.append(edge)\n",
    "\n",
    "\n",
    "metabolomic_only_edge_tuple = []\n",
    "for i in range(len(metabolomic_only_edge)):\n",
    "    edge = metabolomic_only_edge[i].split(\",\")\n",
    "    edge = (edge[0],edge[1][1:])\n",
    "    #edge = tuple(sorted(edge))\n",
    "    metabolomic_only_edge_tuple.append(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to see proportion of proteomic-influenced edges that are significant edges in the metabolomic data vs the integrated data\n",
    "print(len(proteomic_influence_edge))\n",
    "print(len(list(set(metabolomic_edges).intersection(set(proteomic_influence_edge_tuple))))) #17 edges significant\n",
    "print(len(list(set(integrated_edges).intersection(set(proteomic_influence_edge_tuple))))) #After integrating with the proteomic data, 45 significant\n",
    "\n",
    "#2 edges are the same between 17 edges and 45 edges\n",
    "list1 = list(set(metabolomic_edges).intersection(set(proteomic_influence_edge_tuple)))\n",
    "list2 = list(set(integrated_edges).intersection(set(proteomic_influence_edge_tuple)))\n",
    "len(list(set(list1).intersection(set(list2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the integrated only pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated_only = list(set(integrated_edges) - (set(metabolomic_edges)|set(proteomic_edges)))\n",
    "len(integrated_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When alpha level < 0.005 for the q-values from differential network: <br>\n",
    "\n",
    "\n",
    "Common pathway | Any            =   857 - 61 = 796 (account for overlap with new pathway)   <br>\n",
    "\n",
    "New integrated pathways: <br>\n",
    "New pathway | (Any)   =   669  <br>\n",
    "\n",
    "\n",
    "Metabolomic-influenced metabolomic pathway | (Any)  =  26    <br>\n",
    "Proteomic-influenced metabolomic pathway | (Any)  =  272    <br>\n",
    "\n",
    "Pathway only in metabolomics | Pathway only in proteomics   =   676   <br>\n",
    "\n",
    "False positives: <br>\n",
    "Pathway only in metabolomics | Pathway only in metabolomics   =   1  <br>\n",
    "Pathway only in proteomics | Pathway only in proteomics   =   95  <br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(proteomic_only_pathway))\n",
    "print(len(proteomic_pathway_with_onemetabolite))\n",
    "print(len(metabolomic_only_pathway))\n",
    "print(len(metabolomic_pathway_with_oneprotein))\n",
    "print(len(both_omic))\n",
    "print(len(new_pathway))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pathways where one is a common pathway\n",
    "\n",
    "counter = 0 \n",
    "\n",
    "for edges in integrated_only:\n",
    "    pathway_pair = list(edges)\n",
    "    if (pathway_pair[0] in both_omic) or (pathway_pair[1] in both_omic):\n",
    "        #print(pathway_pair)\n",
    "        counter += 1\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pathways where one is a common pathway and one is a new pathway\n",
    " \n",
    "counter = 0 \n",
    "\n",
    "for edges in integrated_only:\n",
    "    pathway_pair = list(edges)\n",
    "    if (pathway_pair[0] in both_omic) and (pathway_pair[1] in new_pathway):\n",
    "        counter += 1\n",
    "    if (pathway_pair[1] in both_omic) and (pathway_pair[0] in new_pathway):\n",
    "        counter += 1\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pathways where one is a new pathway\n",
    "\n",
    "counter = 0 \n",
    "\n",
    "for edges in integrated_only:\n",
    "    pathway_pair = list(edges)\n",
    "    if (pathway_pair[0] in new_pathway) or (pathway_pair[1] in new_pathway):\n",
    "        counter += 1\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pathways where both are the same\n",
    "\n",
    "counter = 0 \n",
    "\n",
    "for edges in integrated_only:\n",
    "    pathway_pair = list(edges)\n",
    "    #if (pathway_pair[0] in metabolomic_only_pathway) and (pathway_pair[1] in metabolomic_only_pathway):\n",
    "    #   counter += 1\n",
    "    if (pathway_pair[0] in proteomic_only_pathway) and (pathway_pair[1] in proteomic_only_pathway):\n",
    "        counter += 1\n",
    "    #if (pathway_pair[0] in metabolomic_pathway_with_oneprotein) and (pathway_pair[1] in metabolomic_pathway_with_oneprotein):\n",
    "    #    counter += 1\n",
    "    #if (pathway_pair[0] in proteomic_pathway_with_onemetabolite) and (pathway_pair[1] in proteomic_pathway_with_onemetabolite):\n",
    "    #    counter += 1\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0 \n",
    "\n",
    "for edges in integrated_only:\n",
    "    pathway_pair = list(edges)\n",
    "    if (pathway_pair[0] in proteomic_pathway_with_onemetabolite) and (pathway_pair[1] in proteomic_only_pathway):\n",
    "        counter += 1\n",
    "    if (pathway_pair[1] in proteomic_pathway_with_onemetabolite) and (pathway_pair[0] in proteomic_only_pathway):\n",
    "        counter += 1\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "counter = 0 \n",
    "\n",
    "for edges in integrated_only:\n",
    "    pathway_pair = list(edges)\n",
    "    if (pathway_pair[0] in metabolomic_pathway_with_oneprotein) and (pathway_pair[1] in metabolomic_only_pathway):\n",
    "        counter += 1\n",
    "    if (pathway_pair[1] in metabolomic_pathway_with_oneprotein) and (pathway_pair[0] in metabolomic_only_pathway):\n",
    "        counter += 1\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "counter = 0 \n",
    "\n",
    "for edges in integrated_only:\n",
    "    pathway_pair = list(edges)\n",
    "    if (pathway_pair[0] in metabolomic_pathway_with_oneprotein) and (pathway_pair[1] in proteomic_only_pathway):\n",
    "        counter += 1\n",
    "    if (pathway_pair[1] in metabolomic_pathway_with_oneprotein) and (pathway_pair[0] in proteomic_only_pathway):\n",
    "        counter += 1\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "counter = 0 \n",
    "\n",
    "for edges in integrated_only:\n",
    "    pathway_pair = list(edges)\n",
    "    if (pathway_pair[0] in proteomic_pathway_with_onemetabolite) and (pathway_pair[1] in metabolomic_only_pathway):\n",
    "        counter += 1\n",
    "    if (pathway_pair[1] in proteomic_pathway_with_onemetabolite) and (pathway_pair[0] in metabolomic_only_pathway):\n",
    "        counter += 1\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0 \n",
    "\n",
    "for edges in integrated_only:\n",
    "    pathway_pair = list(edges)\n",
    "    if (pathway_pair[0] in proteomic_pathway_with_onemetabolite) and (pathway_pair[1] in metabolomic_pathway_with_oneprotein):\n",
    "        counter += 1\n",
    "    if (pathway_pair[1] in proteomic_pathway_with_onemetabolite) and (pathway_pair[0] in metabolomic_pathway_with_oneprotein):\n",
    "        counter += 1\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "counter = 0 \n",
    "\n",
    "for edges in integrated_only:\n",
    "    pathway_pair = list(edges)\n",
    "    if (pathway_pair[0] in proteomic_only_pathway) and (pathway_pair[1] in metabolomic_only_pathway):\n",
    "        #print(pathway_pair)\n",
    "        counter += 1\n",
    "    if (pathway_pair[0] in metabolomic_only_pathway) and (pathway_pair[1] in proteomic_only_pathway):\n",
    "        #print(pathway_pair)\n",
    "        counter += 1\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import statsmodels.stats.multitest\n",
    "from itertools import compress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probably false postives:  \n",
    "#Proteomic influenced only (i.e. pairs where both pathways are only in the proteomic dataset)\n",
    "print(len(list(set(proteomic_only_edge_tuple).intersection(set(integrated_only)))))\n",
    "#Metabolomic influenced only (i.e. pairs where both pathways are only in the metabolomic dataset)\n",
    "print(len(list(set(metabolomic_only_edge_tuple).intersection(set(integrated_only)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the significance of the 'false positives' IN THE INTEGRATED DATASET\n",
    "proteomic_false_pos = list(set(proteomic_only_edge_tuple).intersection(set(integrated_only)))\n",
    "metabolomic_false_pos = list(set(metabolomic_only_edge_tuple).intersection(set(integrated_only)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()[:-13] + '\\\\Data\\\\permutation_test_files_proteomics\\\\Values'\n",
    "\n",
    "val_array = []\n",
    "\n",
    "\n",
    "for filename in os.listdir(path): #also lists directories\n",
    "    with open(os.path.join(path, filename)) as file:    \n",
    "        lines = file.readlines()\n",
    "        vals = lines[0].split(';')\n",
    "        vals =  [int(x) for x in vals]\n",
    "        #print(vals)\n",
    "        if filename == 'vals1.txt':\n",
    "            val_array = np.array(vals)\n",
    "        else:\n",
    "            val_array = np.vstack([val_array, vals])\n",
    "\n",
    "val_array\n",
    "val_array2 = val_array.sum(axis=0) #add up the values by columns for each pathway pair\n",
    "pval_array = val_array2 / 100000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_edge_boolean,adjusted_pval = statsmodels.stats.multitest.fdrcorrection(pval_array, alpha=0, method='poscorr', is_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/permutation_test_files_proteomics/initial_tstats.csv', index_col=0)\n",
    "edgelist = df.index\n",
    "\n",
    "\n",
    "#sig_edges = list(compress(edgelist,sig_edge_boolean))\n",
    "\n",
    "\n",
    "#Zip p-values to edge names to form dictionary (so I can test significance of differentially expressed genes)\n",
    "edgelist_tuple = []\n",
    "for i in range(len(edgelist)):\n",
    "    edge = edgelist[i].split(\",\")\n",
    "    edge = (edge[0],edge[1][1:])\n",
    "    edgelist_tuple.append(edge)\n",
    "    \n",
    "#p_val_dict  = dict(zip(edgelist_tuple, adjusted_pval))\n",
    "p_val_dict  = dict(zip(edgelist_tuple, pval_array))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteomic_false_pos_pval = []\n",
    "metabolomic_false_pos_pval = []\n",
    "\n",
    "for edge in proteomic_false_pos:\n",
    "    if edge in list(p_val_dict.keys()):\n",
    "        proteomic_false_pos_pval.append(p_val_dict[edge])\n",
    "\n",
    "#for edge in metabolomic_false_pos:\n",
    "#    if edge in list(p_val_dict.keys()):\n",
    "#        metabolomic_false_pos_pval.append(p_val_dict[edge])\n",
    "\n",
    "proteomic_false_pos_pval[:100]\n",
    "#len(proteomic_false_pos_pval)\n",
    "\n",
    "#print(metabolomic_false_pos_pval)\n",
    "sum(proteomic_false_pos_pval)/len(proteomic_false_pos_pval)  \n",
    "\n",
    "#With alpha < 0.005: 95 proteomic-proteomic only edges\n",
    "#average = 0.00522  #close to p < 0.005 threshold\n",
    "\n",
    "#With alpha < 0.005: 586 proteomic-proteomic only edges\n",
    "#average = 0.00075  #more significant than p < 0.005 threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [i for i in proteomic_false_pos_pval if i >= 0.005]\n",
    "len(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteomic_false_pos_pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteomic_false_pos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Imperial_Project2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
