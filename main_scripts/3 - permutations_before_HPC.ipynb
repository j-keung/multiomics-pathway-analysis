{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script can be used to calculate the observed t-statistics prior to using the HPC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sspa\n",
    "import scipy\n",
    "import numpy as np "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make two different networks, one for the COVID cases 1-2 compared to COVID cases 3-7 <br>\n",
    "This is because there are only 18 samples in common between the metabolomic and proteomic datasets\n",
    "\n",
    "0       Common samples: 18           Metabolomic samples: 133        Proteomic samples: 123 <br>\n",
    "1-2       Common samples: 45          Metabolomic samples: 45        Proteomic samples: 48 <br>\n",
    "3-4       Common samples: 56          Metabolomic samples: 57        Proteomic samples: 59 <br>\n",
    "5-7       Common samples: 27          Metabolomic samples: 28        Proteomic samples: 28 <br>\n",
    "\n",
    "146 common samples overall,   128 cases (45 samples (WHO 1-2) vs 83 samples (WHO 3-7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/Su_COVID_metabolomics_processed_commoncases.csv', index_col=0)\n",
    "#df = pd.read_csv('../Data/Su_COVID_proteomics_processed_commoncases.csv', index_col=0)\n",
    "#df = pd.read_csv(\"../Data/Su_integrated_data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mild = (df[df[\"WHO_status\"] == '1-2']).iloc[:,:-2] #45 samples, remove the metadata\n",
    "df_severe = (df[(df[\"WHO_status\"] == '3-4') | (df[\"WHO_status\"] == '5-7')]).iloc[:,:-2] #83 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale data after subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mild = pd.DataFrame(StandardScaler().fit_transform(df_mild),columns=df_mild.columns, index=df_mild.index)\n",
    "df_severe = pd.DataFrame(StandardScaler().fit_transform(df_severe),columns=df_severe.columns, index=df_severe.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that data is centred at zero (mean=zero and standard deviation=1 for each molecule):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_centred(type):\n",
    "    print(type.max().max())\n",
    "    print(type.min().min())\n",
    "    print(type.mean(axis = 0)) #mean of 0\n",
    "    print(type.std(axis = 0)) #sd of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_centred(df_mild)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_centred(df_severe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the reactome pathways\n",
    "reactome_pathways = sspa.process_gmt(\"../Data/Reactome_Homo_sapiens_pathways_compounds_R84.gmt\")\n",
    "#reactome_pathways = sspa.process_reactome('Homo sapiens', infile = '../Data/UniProt2Reactome_all_Levels_ver84.txt', download_latest = False, filepath = None)\n",
    "#reactome_pathways = pd.read_csv(\"../Data/Reactome_multi_omics_ChEBI_Uniprot.csv\", index_col=0,dtype=\"str\") #Dtype warning because in some columns, some values are in string format whereas some are in integer format, that's why I specify dtype=\"str\"\n",
    "\n",
    "\n",
    "#Download the root pathways\n",
    "root_path = pd.read_excel('../Data/Root_pathways.xlsx', header=None)\n",
    "root_pathway_dict = {root_path[0][i]:root_path[1][i] for i in range(0,len(root_path))}\n",
    "root_pathway_names = list(root_pathway_dict.keys())\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Determine observed test-statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating observed test statistics at the pathway level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate the squared Spearman correlation matrix \n",
    "\n",
    "def squared_spearman_corr(data):\n",
    "    kpca_scores = sspa.sspa_kpca(data, reactome_pathways)   \n",
    "    kpca_scores = kpca_scores.drop(columns = list(set(root_pathway_names) & set(kpca_scores.columns))) #using Sara's code to drop root pathways\n",
    "\n",
    "    spearman_results = scipy.stats.spearmanr(kpca_scores)\n",
    "    squared_spearman_coef = np.square(spearman_results[0]) #correlation coefficients (spearman_results[1] gives the p-values)\n",
    "\n",
    "    return squared_spearman_coef,list(kpca_scores.columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Function to calculate the difference between two matrices \n",
    "\n",
    "def observed_tstat(data1,data2,edgelist):\n",
    "    #abs_squared = np.absolute(np.array(data1) - np.array(data2))\n",
    "    delta_squared = (np.array(data1) - np.array(data2))\n",
    "\n",
    "    #Mask the upper half of the dataframe (so I don't view the comparisons between the two same genes, and also the duplicate comparisons are removed)\n",
    "    mask = delta_squared.copy()\n",
    "    mask = np.triu(np.ones(mask.shape)).astype(bool)\n",
    "    mask = np.invert(mask) #invert true and false values so the diagonal is False as well\n",
    "    non_dup_delta_squared = pd.DataFrame(delta_squared, columns = edgelist, index = edgelist)\n",
    "    non_dup_delta_squared = pd.DataFrame(non_dup_delta_squared).where(mask) #Replace all false values with NaN using mask\n",
    "\n",
    "    squared_list = non_dup_delta_squared.stack().reset_index()\n",
    "    squared_list['level_0'] = squared_list[\"level_0\"].astype(str) + \", \" + squared_list['level_1'] #Join the pathway pairs together to form an edge\n",
    "    squared_list.columns = [\"Edges\",\"na\",\"Observed_tstat\"]\n",
    "    squared_list.index = squared_list[\"Edges\"]\n",
    "    squared_list = squared_list.drop(columns = [\"Edges\",\"na\"])\n",
    "\n",
    "    return(squared_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: For the delta squared correlation values for the unshuffled data (i.e. the real data) I keep the indices (pathway edges). Since I already have a record of the edges, there is no need to keep the edges for each permutation, since the order is the same each time.  </br>\n",
    "\n",
    "Note: I take the difference (and not absolute difference) between the mild and severe matrices because we care about the directionality of the association and also in case the distribution is skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_mild,edgelist = squared_spearman_corr(df_mild)\n",
    "spearman_severe,edgelist = squared_spearman_corr(df_severe)\n",
    "\n",
    "output = observed_tstat(spearman_mild,spearman_severe,edgelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: There are no values with a Spearman correlation value of zero. The reason why some of the observed test statistic values have a value of zero is because for both groups both values are one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(spearman_mild, columns = edgelist, index = edgelist)\n",
    "display(test_df.iloc[:25,:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output.to_csv(\"../Data/permutation_test_files_metabolomics/observed_tstats.csv\")\n",
    "#output.to_csv(\"../Data/permutation_test_files_proteomics/observed_tstats.csv\")\n",
    "#output.to_csv(\"../Data/permutation_test_files_integrated/observed_tstats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating observed test statistics at the molecular level without pathway analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate the squared Spearman correlation matrix \n",
    "\n",
    "def squared_spearman_corr(data):\n",
    "    spearman_results = scipy.stats.spearmanr(data)\n",
    "    squared_spearman_coef = np.square(spearman_results[0]) #correlation coefficients (spearman_results[1] gives the p-values)\n",
    "\n",
    "    return squared_spearman_coef,list(data.columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Function to calculate the difference between two matrices \n",
    "\n",
    "def observed_tstat(data1,data2,edgelist):\n",
    "    #abs_squared = np.absolute(np.array(data1) - np.array(data2))\n",
    "    delta_squared = (np.array(data1) - np.array(data2))\n",
    "\n",
    "    #Mask the upper half of the dataframe (so I don't view the comparisons between the two same genes, and also the duplicate comparisons are removed)\n",
    "    mask = delta_squared.copy()\n",
    "    mask = np.triu(np.ones(mask.shape)).astype(bool)\n",
    "    mask = np.invert(mask) #invert true and false values so the diagonal is False as well\n",
    "    non_dup_delta_squared = pd.DataFrame(delta_squared, columns = edgelist, index = edgelist)\n",
    "    non_dup_delta_squared = pd.DataFrame(non_dup_delta_squared).where(mask) #Replace all false values with NaN using mask\n",
    "\n",
    "    squared_list = non_dup_delta_squared.stack().reset_index()\n",
    "    squared_list['level_0'] = squared_list[\"level_0\"].astype(str) + \", \" + squared_list['level_1']\n",
    "    squared_list.columns = [\"Edges\",\"na\",\"Observed_tstat\"]\n",
    "    squared_list.index = squared_list[\"Edges\"]\n",
    "    squared_list = squared_list.drop(columns = [\"Edges\",\"na\"])\n",
    "\n",
    "    return(squared_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_mild,edgelist = squared_spearman_corr(df_mild)\n",
    "spearman_severe,edgelist = squared_spearman_corr(df_severe)\n",
    "\n",
    "output = observed_tstat(spearman_mild,spearman_severe,edgelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output.to_csv(\"../Data/permutation_test_files_integrated_withoutPA/observed_tstats.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Shuffle the labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample labels are shuffled, rather than assigning the samples to two different groups (since the sizes of the 1-2 class with the 3-7 class is not equal)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Read in the permutation files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the HPC, 10 files each store 10k permutations. 10 array jobs are carried out to read in all 10k values, and to output how many are above the observed test statistic. See permutation_distribution.ipynb for more info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also I take all the permutation values for some randomly selected pathways to check the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Compare the difference in edges with other networks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Imperial_Project2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
