{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script can be used to calculate the observed t-statistic files prior to using the HPC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sspa\n",
    "import scipy\n",
    "import numpy as np "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make two different networks, one for the COVID cases 1-2 compared to COVID cases 3-7 <br>\n",
    "This is because there are only 18 samples in common between the metabolomic and proteomic datasets\n",
    "\n",
    "0       Common samples: 18           Metabolomic samples: 133        Proteomic samples: 123 <br>\n",
    "1-2       Common samples: 45          Metabolomic samples: 45        Proteomic samples: 48 <br>\n",
    "3-4       Common samples: 56          Metabolomic samples: 57        Proteomic samples: 59 <br>\n",
    "5-7       Common samples: 27          Metabolomic samples: 28        Proteomic samples: 28 <br>\n",
    "\n",
    "146 common samples overall,   128 cases (45 samples (WHO 1-2) vs 83 samples (WHO 3-7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/Su_COVID_metabolomics_processed_commoncases.csv', index_col=0)\n",
    "#df = pd.read_csv('../Data/Su_COVID_proteomics_processed_commoncases.csv', index_col=0)\n",
    "#df = pd.read_csv(\"../Data/Su_integrated_data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mild = (df[df[\"WHO_status\"] == '1-2']).iloc[:,:-2] #45 samples, remove the metadata\n",
    "df_severe = (df[(df[\"WHO_status\"] == '3-4') | (df[\"WHO_status\"] == '5-7')]).iloc[:,:-2] #83 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale data after subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mild = pd.DataFrame(StandardScaler().fit_transform(df_mild),columns=df_mild.columns, index=df_mild.index)\n",
    "df_severe = pd.DataFrame(StandardScaler().fit_transform(df_severe),columns=df_severe.columns, index=df_severe.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that data is centred at zero (mean=zero and standard deviation=1 for each analyte):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_centred(type):\n",
    "    print(type.max().max())\n",
    "    print(type.min().min())\n",
    "    print(type.mean(axis = 0)) #mean of 0\n",
    "    print(type.std(axis = 0)) #sd of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_centred(df_mild)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_centred(df_severe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_severe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the reactome pathways\n",
    "#reactome_pathways = sspa.process_gmt(\"Data/Reactome_Homo_sapiens_pathways_compounds_R84.gmt\")\n",
    "#reactome_pathways = sspa.process_reactome('Homo sapiens', infile = 'Data/UniProt2Reactome_all_Levels_ver84.txt', download_latest = False, filepath = None)\n",
    "reactome_pathways = pd.read_csv(\"Data/Reactome_multi_omics_ChEBI_Uniprot.csv\", index_col=0,dtype=\"str\") #Dtype warning because in some columns, some values are in string format whereas some are in integer format, that's why I specify dtype=\"str\"\n",
    "\n",
    "\n",
    "#Download the root pathways\n",
    "root_path = pd.read_excel('Data/Root_pathways.xlsx', header=None)\n",
    "root_pathway_dict = {root_path[0][i]:root_path[1][i] for i in range(0,len(root_path))}\n",
    "root_pathway_names = list(root_pathway_dict.keys())\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Determine initial test-statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate the squared Spearman correlation matrix \n",
    "\n",
    "def squared_spearman_corr(data):\n",
    "    kpca_scores = sspa.sspa_kpca(data, reactome_pathways)   \n",
    "    kpca_scores = kpca_scores.drop(columns = list(set(root_pathway_names) & set(kpca_scores.columns))) #using Sara's code to drop root pathways\n",
    "\n",
    "    spearman_results = scipy.stats.spearmanr(kpca_scores)\n",
    "    squared_spearman_coef = np.square(spearman_results[0]) #correlation coefficients (spearman_results[1] gives the p-values)\n",
    "\n",
    "    return squared_spearman_coef,list(kpca_scores.columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Function to calculate the difference between two matrices \n",
    "\n",
    "def initial_tstat(data1,data2,edgelist):\n",
    "    #abs_rho_squared = np.absolute(np.array(data1) - np.array(data2))\n",
    "    delta_squared = (np.array(data1) - np.array(data2))\n",
    "\n",
    "    #Mask the upper half of the dataframe (so I don't view the comparisons between the two same genes, and also the duplicate comparisons are removed)\n",
    "    mask = delta_squared.copy()\n",
    "    mask = np.triu(np.ones(mask.shape)).astype(bool)\n",
    "    mask = np.invert(mask) #invert true and false values so the diagonal is False as well\n",
    "    non_dup_delta_squared = pd.DataFrame(delta_squared, columns = edgelist, index = edgelist)\n",
    "    non_dup_delta_squared = pd.DataFrame(non_dup_delta_squared).where(mask) #Replace all false values with NaN using mask\n",
    "\n",
    "    squared_list = non_dup_delta_squared.stack().reset_index()\n",
    "    squared_list['level_0'] = squared_list[\"level_0\"].astype(str) + \", \" + squared_list['level_1']\n",
    "    squared_list.columns = [\"Edges\",\"na\",\"Initial_tstat\"]\n",
    "    squared_list.index = squared_list[\"Edges\"]\n",
    "    squared_list = squared_list.drop(columns = [\"Edges\",\"na\"])\n",
    "\n",
    "    return(squared_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: For the delta squared correlation values for the unshuffled data (i.e. the real data) I keep the indices (pathway edges). Since I already have a record of the edges, there is no need to keep the edges for each permutation, since the order is the same each time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_mild,edgelist = squared_spearman_corr(df_mild)\n",
    "spearman_severe,edgelist = squared_spearman_corr(df_severe)\n",
    "\n",
    "output = initial_tstat(spearman_mild,spearman_severe,edgelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: There are no values with a Spearman correlation value of zero. The reason why some initial test statistics have a value of zero is because for both groups both values are one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(spearman_mild, columns = edgelist, index = edgelist)\n",
    "display(test_df.iloc[:25,:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output.to_csv(\"../Data/permutation_test_files_integrated/initial_tstats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating pathway scores without pathway analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate the squared Spearman correlation matrix \n",
    "\n",
    "def squared_spearman_corr(data):\n",
    "    spearman_results = scipy.stats.spearmanr(data)\n",
    "    squared_spearman_coef = np.square(spearman_results[0]) #correlation coefficients (spearman_results[1] gives the p-values)\n",
    "\n",
    "    return squared_spearman_coef,list(data.columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Function to calculate the difference between two matrices \n",
    "\n",
    "def initial_tstat(data1,data2,edgelist):\n",
    "    #abs_rho_squared = np.absolute(np.array(data1) - np.array(data2))\n",
    "    delta_squared = (np.array(data1) - np.array(data2))\n",
    "\n",
    "    #Mask the upper half of the dataframe (so I don't view the comparisons between the two same genes, and also the duplicate comparisons are removed)\n",
    "    mask = delta_squared.copy()\n",
    "    mask = np.triu(np.ones(mask.shape)).astype(bool)\n",
    "    mask = np.invert(mask) #invert true and false values so the diagonal is False as well\n",
    "    non_dup_delta_squared = pd.DataFrame(delta_squared, columns = edgelist, index = edgelist)\n",
    "    non_dup_delta_squared = pd.DataFrame(non_dup_delta_squared).where(mask) #Replace all false values with NaN using mask\n",
    "\n",
    "    squared_list = non_dup_delta_squared.stack().reset_index()\n",
    "    squared_list['level_0'] = squared_list[\"level_0\"].astype(str) + \", \" + squared_list['level_1']\n",
    "    squared_list.columns = [\"Edges\",\"na\",\"Initial_tstat\"]\n",
    "    squared_list.index = squared_list[\"Edges\"]\n",
    "    squared_list = squared_list.drop(columns = [\"Edges\",\"na\"])\n",
    "\n",
    "    return(squared_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_mild,edgelist = squared_spearman_corr(df_mild)\n",
    "spearman_severe,edgelist = squared_spearman_corr(df_severe)\n",
    "\n",
    "output = initial_tstat(spearman_mild,spearman_severe,edgelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Initial_tstat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edges</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16610, 1372</th>\n",
       "      <td>0.002318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72665, 1372</th>\n",
       "      <td>-0.071038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72665, 16610</th>\n",
       "      <td>-0.013511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27823, 1372</th>\n",
       "      <td>0.137964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27823, 16610</th>\n",
       "      <td>-0.178640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89188, 28036</th>\n",
       "      <td>0.007621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89188, 28238</th>\n",
       "      <td>-0.131566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89188, 76341</th>\n",
       "      <td>0.075066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89188, 89312</th>\n",
       "      <td>-0.028499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89188, 17861</th>\n",
       "      <td>0.072638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55278 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Initial_tstat\n",
       "Edges                      \n",
       "16610, 1372        0.002318\n",
       "72665, 1372       -0.071038\n",
       "72665, 16610      -0.013511\n",
       "27823, 1372        0.137964\n",
       "27823, 16610      -0.178640\n",
       "...                     ...\n",
       "89188, 28036       0.007621\n",
       "89188, 28238      -0.131566\n",
       "89188, 76341       0.075066\n",
       "89188, 89312      -0.028499\n",
       "89188, 17861       0.072638\n",
       "\n",
       "[55278 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output.to_csv(\"../Data/permutation_test_files_integrated_withoutPA/initial_tstats.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Shuffle the labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample labels are shuffled, rather than assigning the samples to two different groups (since the sizes of the 1-2 class with the 3-7 class is not equal). See HPC_permutation_script_metabolomic for more info."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Read in the permutation files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the HPC, 10 files each store 10k permutations. 10 array jobs are carried out to read in all 10k values, make them absolute and count how many are above the initial test statistic. See permutation_distribution.ipynb for more info."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.jwilber.me/permutationtest/# <br>\n",
    "We take the absolute value for the absolute difference between the two groups to compute the initial test statistic. Each permutation calculates a new test statistic calculated from the ABSOLUTE difference between the two test groups. It makes no difference whether I take the absolute difference or regular difference between the two, since either way it's a two-tailed p-value distribution, just that with the absolute difference the negative values have been mapped to the positive side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR you can take a one-sided test if you are interested in the directionality of the association and also in case the distribution is skewed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also I take all the permutation values for some randomly selected pathways to check the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Compare the difference in edges with other networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing with the naive networks (mild vs severe) to see if they agree with the differential network results:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Imperial_Project2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
