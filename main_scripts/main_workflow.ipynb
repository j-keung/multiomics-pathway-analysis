{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "692b1069",
   "metadata": {},
   "source": [
    "This script is the main script to construct the final and condition-specific correlation networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a17959a-e57d-4b6a-bf35-ebb68ac0e07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import statsmodels.stats.multitest\n",
    "import sspa\n",
    "import scipy \n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180e7d8b-b2ef-419f-ac87-fa9862328a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the whole dataset (both cases and controls)\n",
    "\n",
    "#Metabolomics: \n",
    "#df = pd.read_csv('Data/Su_COVID_metabolomics_processed.csv', index_col=0)\n",
    "#df.index= df.index.str.rstrip('-BL')\n",
    "#print(df.iloc[:10,-2:])    #show subset of control data (first 10 rows, last two columns)\n",
    "\n",
    "#Proteomics:\n",
    "#df = pd.read_csv('Data/Su_COVID_proteomics_processed.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799b6e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the common cases dataset (cases that are present in both datasets)\n",
    "\n",
    "#Metabolomics:\n",
    "df = pd.read_csv('../Data/Su_COVID_metabolomics_processed_commoncases.csv', index_col=0)\n",
    "\n",
    "#Proteomics:\n",
    "#df = pd.read_csv('../Data/Su_COVID_proteomics_processed_commoncases.csv', index_col=0)\n",
    "\n",
    "#Integrated data:\n",
    "#df = pd.read_csv(\"../Data/Su_integrated_data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04db5459",
   "metadata": {},
   "source": [
    "### Subset the data to common samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdbf3ad",
   "metadata": {},
   "source": [
    "Two different networks are constructed: one for the COVID WHO cases 1-2 compared to COVID WHO cases 3-7 <br>\n",
    "This is because there are only 18 samples in common between the metabolomic and proteomic datasets\n",
    "\n",
    "0       Common samples: 18           Metabolomic samples: 133        Proteomic samples: 123 <br>\n",
    "1-2       Common samples: 45          Metabolomic samples: 45        Proteomic samples: 48 <br>\n",
    "3-4       Common samples: 56          Metabolomic samples: 57        Proteomic samples: 59 <br>\n",
    "5-7       Common samples: 27          Metabolomic samples: 28        Proteomic samples: 28 <br>\n",
    "\n",
    "146 common samples overall,   128 cases, composed of (45 samples (WHO 1-2) vs 83 samples (WHO 3-7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5654b3ff",
   "metadata": {},
   "source": [
    "Subsetting the METABOLOMICS dataset to common samples and THEN CENTERING THE DATA ONCE MORE (no need to log2 transform):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef65428",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only need to run the code once to obtain the dataset\n",
    "\n",
    "#df2 = pd.read_csv('Data/Su_COVID_proteomics_processed.csv', index_col=0)\n",
    "\n",
    "#list1 = list(df.index)\n",
    "#list2 = list(df2.index)\n",
    "\n",
    "#Obtain common samples and subset accordingly\n",
    "#intersection = list(set(df.index.tolist()) & set(df2.index.tolist())) #set removes duplicates\n",
    "#intersection = [sample for sample in intersection if sample.startswith(\"INCOV\")]\n",
    "#df = df[df.index.isin(intersection)]\n",
    "\n",
    "#df_num  = df.iloc[:,:-2] #all rows, all columns apart from last two (remove metadata)\n",
    "#df_norm = pd.DataFrame(StandardScaler().fit_transform(df_num),columns=df_num.columns, index=df_num.index)  #must scale since many samples were removed \n",
    "\n",
    "#Add metadata to the end of the df\n",
    "#df_final = pd.concat([df_norm, df.iloc[:,-2:]],axis=1) \n",
    "#df_final.to_csv('Data/Su_COVID_metabolomics_processed_commoncases.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77998f5b",
   "metadata": {},
   "source": [
    "Subsetting the PROTEOMICS dataset to common samples and THEN CENTERING THE DATA ONCE MORE (no need to log2 transform):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ffa57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only need to run the code once to obtain the dataset\n",
    "\n",
    "#df2 = pd.read_csv('Data/Su_COVID_metabolomics_processed.csv', index_col=0)\n",
    "#df2.index= df2.index.str.rstrip('-BL')  #remove 'BL' label from the cases (so I can match to proteomic data)\n",
    "\n",
    "#list1 = list(df.index)\n",
    "#list2 = list(df2.index)\n",
    "\n",
    "#Obtain common samples and subset accordingly\n",
    "#intersection = list(set(df.index.tolist()) & set(df2.index.tolist())) #set removes duplicates\n",
    "#intersection = [sample for sample in intersection if sample.startswith(\"INCOV\")]\n",
    "#df = df[df.index.isin(intersection)]\n",
    "\n",
    "#df_num  = df.iloc[:,:-2] #all rows, all columns apart from last two (remove metadata)\n",
    "#df_norm = pd.DataFrame(StandardScaler().fit_transform(df_num),columns=df_num.columns, index=df_num.index) #must scale since many samples were removed \n",
    "\n",
    "#Add metadata to the end of the df\n",
    "#df_final = pd.concat([df_norm, df.iloc[:,-2:]],axis=1) \n",
    "#df_final.to_csv('Data/Su_COVID_proteomics_processed_commoncases.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819876bf",
   "metadata": {},
   "source": [
    "### Subsetting the dataframe into two groups and SCALING:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06a8aa3",
   "metadata": {},
   "source": [
    "The two groups are scaled because we are comparing the WITHIN group correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf58960",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mild = (df[df[\"WHO_status\"] == '1-2']).iloc[:,:-2] #45 samples, remove the metadata\n",
    "df_severe = (df[(df[\"WHO_status\"] == '3-4') | (df[\"WHO_status\"] == '5-7')]).iloc[:,:-2] #83 samples, remove the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bfc438",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mild = pd.DataFrame(StandardScaler().fit_transform(df_mild),columns=df_mild.columns, index=df_mild.index)\n",
    "df_severe = pd.DataFrame(StandardScaler().fit_transform(df_severe),columns=df_severe.columns, index=df_severe.index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b5e73a1",
   "metadata": {},
   "source": [
    "### Data exploration - Individual omics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cd462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of molecules:\", len(df. columns[:-2]) )  #'Compounds' for metabolites only, 'Molecules' and 'Analytes' can be used for both proteins and metabolites\n",
    "print(\"Number of samples:\", len(df. index))\n",
    "\n",
    "print(df['WHO_status'].value_counts()) \n",
    "print(df['Group'].value_counts())\n",
    "\n",
    "#Return non-integer columns\n",
    "df.dtypes[df.dtypes != 'int64'][df.dtypes != 'float64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484157e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to check whether the dataset is centered\n",
    "\n",
    "def check_centred(type):\n",
    "    print(type.max().max())\n",
    "    print(type.min().min())\n",
    "    print(type.mean(axis = 0)) #should have mean of around 0\n",
    "    print(type.std(axis = 0)) #should have sd of around 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba5eec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_centred(df.iloc[:,:-2]) #metadata has not been removed for the whole dataset yet\n",
    "\n",
    "#check_centred(df_mild)\n",
    "#check_centred(df_severe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d5d5de-1091-4c7c-97fc-f8a1e8b5505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram of mean molecule abundance (idea from Sara's thesis)\n",
    "#Shows that all molecules have a mean of around 0\n",
    "\n",
    "df_num  = df.iloc[:,:-2] #all rows, all columns apart from last two\n",
    "df_hist = df_num.mean(axis = 0) #axis = 0 by column\n",
    "sns.histplot(df_hist, bins = 30,color='#B8CDF8',edgecolor=\"k\") #B8CDF8 default colour,  #79C99E also nice\n",
    "\n",
    "#The mean value for each metabolite has been plotted\n",
    "plt.title('Mean metabolite distribution',fontsize=16)\n",
    "plt.xlabel('Metabolite abundance (e-15)',fontsize=13) # USE METABOLITE ABUNDANCE INSTEAD OF METABOLITE EXPRESSION\n",
    "plt.ylabel('Count',fontsize=13) ;\n",
    "\n",
    "#plt.savefig( '../Figures/mean_metabolite_distribution.png' , dpi=300,bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ce2df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram of all molecule abundance (idea from Sara's thesis)\n",
    "\n",
    "df_num  = df.iloc[:,:-2] #all rows, all columns apart from last two\n",
    "df_num_np = df_num.to_numpy()\n",
    "df_hist = df_num_np.flatten()\n",
    "sns.histplot(df_hist, bins = 30,color='#B8CDF8',edgecolor=\"k\") \n",
    "\n",
    "plt.title('Metabolite distribution',fontsize=16)\n",
    "plt.xlabel('Metabolite abundance',fontsize=13)\n",
    "plt.ylabel('Count',fontsize=13) ;\n",
    "\n",
    "#plt.savefig( '../Figures/metabolite_distribution.png', dpi=300,bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e7de45-98ef-47f2-8a5f-2d635aa261fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap of molecule abundance according to WHO status (idea from Sara's thesis)\n",
    "\n",
    "df_heatmap = df.groupby('WHO_status').mean(numeric_only=True)\n",
    "\n",
    "g = sns.clustermap(\n",
    "    df_heatmap,\n",
    "    metric='euclidean', \n",
    "    method =\"ward\",\n",
    "    row_cluster=False, \n",
    "    xticklabels=False,\n",
    "    cmap='RdBu_r',\n",
    "    figsize=(9,3),\n",
    "    dendrogram_ratio=0.2, \n",
    "    vmin=-2, \n",
    "    vmax=2) \n",
    "\n",
    "g2 = g.ax_heatmap\n",
    "g2.set_xlabel(\"Metabolites\", fontsize = 15,labelpad=10) #labelpad increases the distance between the axis label and the heatmap\n",
    "g2.set_ylabel(\"WHO status\", fontsize = 15, labelpad=12) \n",
    "g2.set_yticklabels(g2.get_yticklabels(), rotation=0, fontsize=10)  #rotate the y-axis labels so that they are horizontal\n",
    "\n",
    "x0, _y0, _w, _h = g.cbar_pos\n",
    "g.ax_cbar.set_position([1.15, 0.28, 0.03, 0.35])\n",
    "g.cax.set_title(\"Metabolite abundance\",pad=10, size=13) #pad: increase spacing slightly\n",
    "g.cax.tick_params(labelsize=10) #change font size of colourbar labels; \n",
    "\n",
    "#plt.savefig( '../Figures/metabolite_heatmap.png', dpi=300,bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85501273",
   "metadata": {},
   "source": [
    "### Data exploration - Comparing mild and severe cases "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84000d5",
   "metadata": {},
   "source": [
    "Carry out independent t-test for group means on the UNSCALED dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a11f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mild_np = df_mild.to_numpy()#[:,12]\n",
    "df_severe_np = df_severe.to_numpy()#[:,12]\n",
    "#If you scale the dataset, none of the analytes will become significant\n",
    "\n",
    "t_test = scipy.stats.ttest_ind(df_mild_np, df_severe_np, axis=0, equal_var= False) \n",
    "t_test_pval = t_test.pvalue\n",
    "\n",
    "print(len(t_test_pval))\n",
    "\n",
    "# Correct for multiple testing\n",
    "#t_test_pval_corrected = statsmodels.stats.multitest.fdrcorrection(t_test_pval, alpha=0.005, method='indep', is_sorted=False)\n",
    "#sig_molecules = t_test_pval_corrected[0] \n",
    "#sum(sig_molecules)\n",
    "\n",
    "#When doing with scaled datasets and pathways, all p-vals 1\n",
    "#154 out of 333 metabolites significant with t-test\n",
    "#260 out of 454 proteins significant with t-test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c235ca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53895c4a-4085-4b4c-92cf-ce6e7c95cd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA at molecular level\n",
    "\n",
    "features = df.columns[:-2]\n",
    "x = df.loc[:, features].values\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(x)\n",
    "df2 = pd.DataFrame(data = principal_components, columns = ['PC1', 'PC2'])\n",
    "\n",
    "#Restore original index to sample names instead of numbers\n",
    "df2 = df2.set_index(df.index)\n",
    "\n",
    "#Concatenate WHO information\n",
    "df3 = pd.concat([df2, df[['WHO_status']]], axis = 1)\n",
    "display(df3)\n",
    "\n",
    "\n",
    "sns.set(font_scale = 1.7)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "sns.lmplot(\n",
    "    x='PC1', \n",
    "    y='PC2', \n",
    "    data=df3, \n",
    "    hue='WHO_status', \n",
    "    hue_order = ['1-2', '3-4','5-7'],\n",
    "    fit_reg=False, #don't draw line of best fit\n",
    "    legend=False,\n",
    "    palette=[ '#F4C441','#ff6d00', '#a30000'] , \n",
    "   scatter_kws={'edgecolor':'white',\"s\": 120, 'alpha': 0.7} #point size\n",
    "    )\n",
    "#Note: I don't use the seaborn legend (I use plt to add a legend) but check it matches with the seaborn legend\n",
    "\n",
    "#sns.despine(right=False,top=False) #Add a line to the top and right of grid\n",
    "\n",
    "plt.xlabel('PC1 (' + str(round(pca.explained_variance_ratio_[0]*100,2)) + '%)',fontsize=24)\n",
    "plt.ylabel('PC2 (' + str(round(pca.explained_variance_ratio_[1]*100,2)) + '%)',fontsize=24)\n",
    "\n",
    "#This adds a large legend so that I can crop the legend out for the whole panelled figure\n",
    "#legend_labels = [\"1-2 \\n'Mild'\", \"3-4 \\n'Severe'\", \"5-7 \\n'Severe'\"]\n",
    "#plt.legend(framealpha=1, frameon = 'True', title=\"WHO status\",title_fontsize='large', prop={'size': 25}, bbox_to_anchor=(1.8, 0.7),markerscale=2,labels = legend_labels)\n",
    "#This has more information on the bbox_to_anchor coordinates: https://stackoverflow.com/questions/4700614/how-to-put-the-legend-outside-the-plot\n",
    "\n",
    "plt.grid()  #add gridlines\n",
    "\n",
    "#plt.savefig('../Figures/integrated_PCA.png', dpi=600, bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1d441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display parameters for seaborn themes\n",
    "\n",
    "display(sns.axes_style(\"white\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bc43d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain hex codes for sns colour palette\n",
    "\n",
    "#https://www.practicalpythonfordatascience.com/ap_seaborn_palette\n",
    "print(sns.color_palette(\"spring\").as_hex()[:])\n",
    "sns.color_palette(\"spring\")\n",
    "\n",
    "#print(sns.color_palette(\"gist_heat\").as_hex()[:])\n",
    "#sns.color_palette(\"gist_heat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ac0f0f",
   "metadata": {},
   "source": [
    "### Data exploration - Comparing omics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfe647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in sequentially to form a density plot of the three different omics, repeat with loading all three datasets at the beginning\n",
    "metabolomic_distribution  #= df.iloc[:,:-2] #all rows, all columns apart from last two\n",
    "proteomic_distribution # = df.iloc[:,:-2] \n",
    "integrated_distribution  = df.iloc[:,:-2] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdaf59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Density plot\n",
    "\n",
    "sns.set(font_scale = 1.5)\n",
    "sns.set_style(\"ticks\") # same as \"white\" but with ticks\n",
    "\n",
    "metabolomic_list = metabolomic_distribution.stack().reset_index()\n",
    "metabolomic_list.columns.values[2] = \"Metabolomic\"\n",
    "\n",
    "proteomic_list = proteomic_distribution.stack().reset_index()\n",
    "proteomic_list.columns.values[2] = \"Proteomic\"\n",
    "\n",
    "integrated_list = integrated_distribution.stack().reset_index()\n",
    "integrated_list.columns.values[2] = \"Integrated\"\n",
    "\n",
    "\n",
    "omics_df = pd.concat([metabolomic_list.Metabolomic, proteomic_list.Proteomic,integrated_list.Integrated], axis=1)\n",
    "\n",
    "#Change because I want metabolomics to be orange, proteomics to be blue\n",
    "palette = ['tab:orange', 'tab:blue', 'tab:green']\n",
    "\n",
    "sns.kdeplot(data=omics_df, palette=palette, linewidth=2)\n",
    "\n",
    "plt.title('Data distribution for each omics',  fontsize=23, pad = 10)\n",
    "plt.xlabel('Molecule abundance',fontsize=20, labelpad=8)\n",
    "plt.ylabel('Count Normalised Density',fontsize=20, labelpad=12) ;   #see seaborn histogram documentation on explanation of probability as to why the y axis is called this\n",
    "\n",
    "#plt.savefig( '../Figures/omics_molecular_distribution.png' , dpi=300,bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf95f2bc",
   "metadata": {},
   "source": [
    "Make a PCA plot for the integrated data showing the separation of metabolomic and proteomic clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b01738",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,333]  #First three columns are metabolites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495a7aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated_df =  (df.iloc[:,:-2]).transpose()\n",
    "integrated_df = pd.DataFrame(StandardScaler().fit_transform(integrated_df),columns=integrated_df.columns, index=integrated_df.index)\n",
    "\n",
    "molecule_list = []\n",
    "for i in range(len(integrated_df)):\n",
    "    if i < 333:\n",
    "        molecule_list.append(\"Metabolite\")\n",
    "    if i >= 333:\n",
    "        molecule_list.append(\"Protein\")\n",
    "\n",
    "len(molecule_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e4e7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA at molecular level\n",
    "features = integrated_df.columns\n",
    "x = integrated_df .loc[:, features].values\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(x)\n",
    "df2 = pd.DataFrame(data = principal_components, columns = ['PC1', 'PC2'])\n",
    "\n",
    "#Restore original index\n",
    "df2 = df2.set_index(integrated_df.index)\n",
    "display(df2)\n",
    "\n",
    "#Concatenate WHO information\n",
    "df2['Omics'] = molecule_list_list\n",
    "\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6243047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale = 1.5)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "sns.lmplot(\n",
    "    x='PC1', \n",
    "    y='PC2', \n",
    "    data=df2, \n",
    "    hue='Omics', \n",
    "    hue_order = ['Metabolite', 'Protein','Both'],\n",
    "    fit_reg=False, #don't draw line of best fit\n",
    "    legend=False,\n",
    "    palette=[ '#ff7f0e','#1f77b4','#2ca02c']\n",
    "   # scatter_kws={\"s\": 20} #point size\n",
    "    )\n",
    "#Note: I don't use the seaborn legend but check it matches with the seaborn legend\n",
    "\n",
    "sns.despine(right=False,top=False) #Add a line to the top and right of grid\n",
    "\n",
    "\n",
    "#plt.title('Metabolomic dataset',fontsize=20,loc='center',y=1.08)\n",
    "#plt.title('Metabolite abundance',fontsize=22, loc='left',pad=15)\n",
    "\n",
    "plt.xlabel('PC1 (' + str(round(pca.explained_variance_ratio_[0]*100,2)) + '%)',fontsize=24)\n",
    "plt.ylabel('PC2 (' + str(round(pca.explained_variance_ratio_[1]*100,2)) + '%)',fontsize=24)\n",
    "\n",
    "plt.legend(framealpha=1, frameon = 'True', title=\"Omics\",title_fontsize='large', prop={'size': 16}, bbox_to_anchor=(1.6, 0.7))  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d47e96e",
   "metadata": {},
   "source": [
    "### Single sample pathway analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99a6bfd",
   "metadata": {},
   "source": [
    "If you're analysing the METABOLOMIC data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a37f36-2918-48ec-814c-a262553d1c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in the Reactome pathways for METABOLOMIC dataset\n",
    "\n",
    "#reactome_pathways = sspa.process_reactome(\"Homo sapiens\", download_latest=True, filepath=\".\")\n",
    "reactome_pathways = sspa.process_gmt(\"../Data/Reactome_Homo_sapiens_pathways_compounds_R84.gmt\")\n",
    "#display(reactome_pathways)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c283a0e9",
   "metadata": {},
   "source": [
    "If you're analysing the PROTEOMIC data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570c2ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in a file downloaded from https://reactome.org/download/current/UniProt2Reactome_All_Levels.txt\n",
    "reactome_pathways = sspa.process_reactome('Homo sapiens', infile = '../Data/UniProt2Reactome_All_Levels_ver84.txt', download_latest = False, filepath = None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2526d368",
   "metadata": {},
   "source": [
    "If you're analysing the INTEGRATED data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaa299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenated the pathways in a separate script\n",
    "reactome_pathways = pd.read_csv(\"../Data/Reactome_multi_omics_ChEBI_Uniprot.csv\", index_col=0,dtype=\"str\") #Dtype warning because in some columns, some values are in string format whereas some are in integer format, that's why I specify dtype=\"str\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318a9b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca_scores = sspa.sspa_kpca(df.iloc[:,:-2], reactome_pathways)\n",
    "#kpca_scores = sspa.sspa_kpca(df_mild, reactome_pathways)     \n",
    "#kpca_scores = sspa.sspa_kpca(df_severe, reactome_pathways)     \n",
    "kpca_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b475747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert pathway ID to name\n",
    "root_path = pd.read_excel('../Data/Root_pathways.xlsx', header=None)\n",
    "root_pathway_dict = {root_path[0][i]:root_path[1][i] for i in range(0,len(root_path))}\n",
    "\n",
    "root_pathway_names = list(root_pathway_dict.keys())\n",
    "#Using Sara's code, remove root pathways\n",
    "kpca_scores = kpca_scores.drop(columns = list(set(root_pathway_names) & set(kpca_scores.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53de96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing to see if duplicate pathways have the same pathway scores (E.g. This set are all dups (see the overlap coefficient section) : {'R-HSA-193368', 'R-HSA-194068', 'R-HSA-159418', 'R-HSA-192105'})\n",
    "kpca_scores[['R-HSA-193368','R-HSA-194068','R-HSA-159418','R-HSA-192105']]  \n",
    "#Remove the metabolites not in the Su dataset, some pathways become duplicates and have the same pathway scores "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef082299",
   "metadata": {},
   "source": [
    "### Pathway data exploration - Individual omics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ef866f",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_centred(kpca_scores) #kpca centers the scores around zero (range is not 1 though)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b1b60c-5123-4635-b01e-d72e11786585",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram of the pathway scores (idea from Sara's thesis)\n",
    "\n",
    "kpca_hist = kpca_scores.to_numpy()\n",
    "kpca_hist = kpca_hist.flatten()\n",
    "sns.histplot(kpca_hist, bins = 40,color='#79C99E',edgecolor=\"k\") \n",
    "\n",
    "plt.title('Metabolite pathway score distribution',fontsize=16)\n",
    "plt.xlabel('Pathway score',fontsize=13, labelpad=5)\n",
    "plt.ylabel('Count',fontsize=13, labelpad=10) ;\n",
    "\n",
    "#plt.savefig( '../Figures/metabolite_pathway_distribution.png', dpi=300, bbox_inches = 'tight', pad_inches = 0.2, facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189b7e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap of pathway scores according to WHO status (idea from Sara's thesis)\n",
    "kpca_scores_meta = pd.concat([kpca_scores, df[['WHO_status']]], axis = 1)\n",
    "df_heatmap = kpca_scores_meta.groupby('WHO_status').mean(numeric_only=True)\n",
    "\n",
    "g = sns.clustermap(\n",
    "    df_heatmap,\n",
    "    metric='euclidean', \n",
    "    method =\"ward\",\n",
    "    row_cluster=False, \n",
    "    xticklabels=False,\n",
    "    cmap='RdBu_r',\n",
    "    figsize=(9,3),\n",
    "    dendrogram_ratio=0.2, \n",
    "    vmin=-1,  \n",
    "    vmax=1)  \n",
    "\n",
    "g2 = g.ax_heatmap\n",
    "g2.set_xlabel(\"Metabolite pathway scores\", fontsize = 15,labelpad=10) #labelpad increases the distance between the axis label and the heatmap\n",
    "g2.set_ylabel(\"WHO status\", fontsize = 15, labelpad=12) \n",
    "g2.set_yticklabels(g2.get_yticklabels(), rotation=0, fontsize=10)  #rotate the y-axis labels so that they are horizontal\n",
    "\n",
    "x0, _y0, _w, _h = g.cbar_pos\n",
    "g.ax_cbar.set_position([1.15, 0.28, 0.03, 0.35])\n",
    "g.cax.set_title(\"Metabolite pathway scores\",pad=10, size=13) #pad: increase spacing slightly\n",
    "g.cax.tick_params(labelsize=10) #change font size of colourbar labels; \n",
    "\n",
    "#plt.savefig( '../Figures/metabolite_pathway_heatmap.png', dpi=300,bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75707b4c",
   "metadata": {},
   "source": [
    "### Pathway data exploration - Comparing mild and severe cases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4490f11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca_scores_meta = pd.concat([kpca_scores, df[['WHO_status']]], axis = 1)\n",
    "kpca_scores_meta_mild = (kpca_scores_meta[kpca_scores_meta[\"WHO_status\"] == '1-2']).iloc[:,:-1] #45 samples, remove the metadata\n",
    "kpca_scores_meta_severe = (kpca_scores_meta[(kpca_scores_meta[\"WHO_status\"] == '3-4') | (kpca_scores_meta[\"WHO_status\"] == '5-7')]).iloc[:,:-1] #83 samples, remove the metadata\n",
    "#If you scale the dataset, none of the pathways will become significant\n",
    "\n",
    "df_mild_np = kpca_scores_meta_mild.to_numpy()#[:,12]\n",
    "df_severe_np = kpca_scores_meta_severe.to_numpy()#[:,12]\n",
    "\n",
    "t_test = scipy.stats.ttest_ind(df_mild_np, df_severe_np, axis=0, equal_var= False) \n",
    "t_test_pval = t_test.pvalue\n",
    "\n",
    "print(len(t_test_pval))\n",
    "\n",
    "# Correct for multiple testing\n",
    "t_test_pval_corrected = statsmodels.stats.multitest.fdrcorrection(t_test_pval, alpha=0.005, method='indep', is_sorted=False)\n",
    "sig_molecules = t_test_pval_corrected[0] \n",
    "sum(sig_molecules)\n",
    "\n",
    "#When doing with scaled datasets and pathways, all p-vals 1\n",
    "#99 out of 144 metabolomic pathways significant with t-test\n",
    "#468 out of 578 proteomic pathways significant with t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12472e54-00d9-4197-a1b3-ca43c80e569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA of pathway scores\n",
    "\n",
    "features = kpca_scores.columns\n",
    "x = kpca_scores.loc[:, features].values\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(x)\n",
    "df2 = pd.DataFrame(data = principal_components, columns = ['PC1', 'PC2'])\n",
    "\n",
    "#Restore original index\n",
    "df2 = df2.set_index(df.index)\n",
    "\n",
    "#Concatenate WHO information\n",
    "df3 = pd.concat([df2, df[['WHO_status']]], axis = 1)\n",
    "#display(df3)\n",
    "\n",
    "sns.set(font_scale = 1.7)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "\n",
    "\n",
    "sns.lmplot(\n",
    "    x='PC1', \n",
    "    y='PC2', \n",
    "    data=df3, \n",
    "    hue='WHO_status', \n",
    "    hue_order = ['1-2', '3-4','5-7'],\n",
    "    fit_reg=False, #don't draw line of best fit\n",
    "    legend=False,\n",
    "    palette=[ '#F4C441','#ff6d00', '#a30000'] ,  \n",
    "   scatter_kws={'edgecolor':'white',\"s\": 120, 'alpha': 0.7} #point size  \n",
    "    )\n",
    "#Note: I don't use the seaborn legend but check it matches with the seaborn legend\n",
    "\n",
    "#sns.despine(right=False,top=False) #Add a line to the top and right of grid\n",
    "\n",
    "\n",
    "#plt.title('Pathway scores',fontsize=16, loc='left', pad=10)\n",
    "\n",
    "plt.xlabel('PC1 (' + str(round(pca.explained_variance_ratio_[0]*100,2)) + '%)',fontsize=24)\n",
    "plt.ylabel('PC2 (' + str(round(pca.explained_variance_ratio_[1]*100,2)) + '%)',fontsize=24, labelpad=0)\n",
    "\n",
    "#This adds a large legend so that I can crop the legend out for the whole panelled figure\n",
    "legend_labels = [\"1-2 \\n'Mild'\", \"3-4 \\n'Severe'\", \"5-7 \\n'Severe'\"]\n",
    "plt.legend(framealpha=1, frameon = 'True', title=\"WHO status\",title_fontsize='large', prop={'size': 25}, bbox_to_anchor=(1.8, 0.7),markerscale=2,labels = legend_labels)\n",
    "#This has more information on the bbox_to_anchor coordinates: https://stackoverflow.com/questions/4700614/how-to-put-the-legend-outside-the-plot\n",
    "\n",
    "plt.grid() \n",
    "\n",
    "#plt.savefig( '../Figures/proteomic_kPCA_PCA.png' , dpi=600,bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')\n",
    "#plt.savefig( '../Figures/legend.png' , dpi=600,bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6d2ded",
   "metadata": {},
   "source": [
    "### Pathway data exploration - Comparing omics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6fa6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in sequentially to form a density plot of the three different omics\n",
    "#metabolomic_distribution  = kpca_scores #all rows, all columns apart from last two\n",
    "#proteomic_distribution  = kpca_scores\n",
    "integrated_distribution  = kpca_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7832678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in sequentially to form a density plot of the three different omics\n",
    "\n",
    "sns.set(font_scale = 1.5)\n",
    "sns.set_style(\"ticks\") # same as \"white\" but with ticks\n",
    "\n",
    "metabolomic_list = metabolomic_distribution.stack().reset_index()\n",
    "metabolomic_list.columns.values[2] = \"Metabolomic\"\n",
    "\n",
    "proteomic_list = proteomic_distribution.stack().reset_index()\n",
    "proteomic_list.columns.values[2] = \"Proteomic\"\n",
    "\n",
    "integrated_list = integrated_distribution.stack().reset_index()\n",
    "integrated_list.columns.values[2] = \"Integrated\"\n",
    "\n",
    "omics_df = pd.concat([metabolomic_list.Metabolomic, proteomic_list.Proteomic,integrated_list.Integrated], axis=1)\n",
    "\n",
    "#Change because I want metabolomics to be orange, proteomics to be blue\n",
    "palette = ['tab:orange', 'tab:blue', 'tab:green']\n",
    "\n",
    "sns.kdeplot(data=omics_df, palette=palette, linewidth=2)\n",
    "plt.title('Pathway score distribution for each omics',  fontsize=23, pad = 10)\n",
    "plt.xlabel('Pathway score',fontsize=20, labelpad=8)\n",
    "plt.ylabel('Count Normalised Density',fontsize=20, labelpad=12) ;\n",
    "\n",
    "#plt.savefig( '../Figures/omics_pathway_distribution.png' , dpi=300,bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c1e739",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family']\n",
    "from matplotlib.font_manager import findfont, FontProperties\n",
    "font = findfont(FontProperties(family=['sans-serif']))\n",
    "font"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c61c4d",
   "metadata": {},
   "source": [
    "Make a PCA plot on the integrated data showing separation of metabolomic and proteomic pathways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654d9002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in omics pathway sequentially\n",
    "#First read in metabolomic pathways, then proteomic pathways, then read in the integrated df\n",
    "\n",
    "metabolomic_pathways# = kpca_scores.columns\n",
    "#proteomic_pathways = kpca_scores.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6233419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated_df =  (kpca_scores).transpose()\n",
    "integrated_df = pd.DataFrame(StandardScaler().fit_transform(integrated_df),columns=integrated_df.columns, index=integrated_df.index)\n",
    "\n",
    "molecule_list = []\n",
    "counter = 0\n",
    "for i in integrated_df.index:\n",
    "    #print(i)\n",
    "    if i in metabolomic_pathways and i not in proteomic_pathways:\n",
    "        molecule_list.append(\"Metabolite\")\n",
    "        \n",
    "    if i in proteomic_pathways and i not in metabolomic_pathways:\n",
    "        molecule_list.append(\"Protein\")\n",
    "        counter += 1\n",
    "\n",
    "    if (i in proteomic_pathways and i in metabolomic_pathways) or (i not in proteomic_pathways and i not in metabolomic_pathways):\n",
    "        molecule_list.append(\"Both\")\n",
    "\n",
    "len(molecule_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d62e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(metabolomic_pathways).intersection(set(proteomic_pathways)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660aa3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060550e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA at molecular level\n",
    "features = integrated_df.columns\n",
    "x = integrated_df .loc[:, features].values\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(x)\n",
    "df2 = pd.DataFrame(data = principal_components, columns = ['PC1', 'PC2'])\n",
    "\n",
    "#Restore original index\n",
    "df2 = df2.set_index(integrated_df.index)\n",
    "display(df2)\n",
    "\n",
    "#Concatenate WHO information\n",
    "\n",
    "df2['Omics'] = molecule_liste_list\n",
    "\n",
    "display(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0062eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set(font_scale = 1.5)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "sns.lmplot(\n",
    "    x='PC1', \n",
    "    y='PC2', \n",
    "    data=df2, \n",
    "    hue='Omics', \n",
    "    hue_order = ['Metabolite', 'Protein','Both'],\n",
    "    fit_reg=False, #don't draw line of best fit\n",
    "    legend=False,\n",
    "    palette=[ '#ff7f0e','#1f77b4','#2ca02c']\n",
    "   # scatter_kws={\"s\": 20} #point size\n",
    "    )\n",
    "#Note: I don't use the seaborn legend but check it matches with the seaborn legend\n",
    "\n",
    "sns.despine(right=False,top=False) #Add a line to the top and right of grid\n",
    "\n",
    "\n",
    "#plt.title('Metabolomic dataset',fontsize=20,loc='center',y=1.08)\n",
    "#plt.title('Metabolite abundance',fontsize=22, loc='left',pad=15)\n",
    "\n",
    "plt.xlabel('PC1 (' + str(round(pca.explained_variance_ratio_[0]*100,2)) + '%)',fontsize=24)\n",
    "plt.ylabel('PC2 (' + str(round(pca.explained_variance_ratio_[1]*100,2)) + '%)',fontsize=24)\n",
    "\n",
    "plt.legend(framealpha=1, frameon = 'True', title=\"Omics\",title_fontsize='large', prop={'size': 16}, bbox_to_anchor=(1.6, 0.7))  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2e9f366",
   "metadata": {},
   "source": [
    "### Spearman correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3a0aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3334a95d-3a72-42a1-ae4c-8b174ce228fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spearman correlation coefficient results are the same whether or not the kPCA pathway scores are normalised\n",
    "\n",
    "spearman_results = scipy.stats.spearmanr(kpca_scores)\n",
    "\n",
    "spearman_coef = spearman_results[0] #correlation coefficients\n",
    "spearman_pvals = spearman_results[1] #p-values\n",
    "\n",
    "\n",
    "#Using Sara's code (rather than having separate dataframes for each analysis, add all together in long format)\n",
    "squared_spearman_coef_df = pd.DataFrame(spearman_coef,columns = kpca_scores.columns, index=kpca_scores.columns)\n",
    "squared_spearman_coef_list = squared_spearman_coef_df.stack().reset_index()\n",
    "squared_spearman_coef_list.columns = [\"Pathway1\", \"Pathway2\", \"Spearman_corr\"]\n",
    "squared_spearman_coef_list[\"Squared_corr\"]  = np.square(squared_spearman_coef_list.Spearman_corr)\n",
    "\n",
    "spearman_pvals_df = pd.DataFrame(spearman_pvals,columns = kpca_scores.columns, index=kpca_scores.columns)\n",
    "spearman_pvals_list = spearman_pvals_df.stack().reset_index()\n",
    "spearman_pvals_list.columns = [\"Pathway1\", \"Pathway2\", \"pval\"]\n",
    "\n",
    "#Multiple testing correction for the p-values to prepare the corrected p-values for the final correlation network\n",
    "#Multiplies by the correct number of tests (i.e. not including the duplicates or self-comparisons)\n",
    "#Does not remove the diagonals or the duplicates themselves\n",
    "# E.g. For 160 pathways: ((160x160)-160)  / 2   \n",
    "\n",
    "num_of_tests = (len(kpca_scores.columns)**2 - len(kpca_scores.columns))/2\n",
    "print(num_of_tests)\n",
    "corrected_spearman_pvals = spearman_pvals_list.pval*num_of_tests\n",
    "#If the p-val goes beyond 1 (max number for a p-value, change to 1)\n",
    "corrected_spearman_pvals = np.where(corrected_spearman_pvals < 1, corrected_spearman_pvals, 1)\n",
    "spearman_pvals_list[\"pval_adj\"]  = corrected_spearman_pvals\n",
    "\n",
    "spearman_df = squared_spearman_coef_list.merge(spearman_pvals_list,on=[\"Pathway1\",\"Pathway2\"])\n",
    "\n",
    "display(spearman_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb4d8f94",
   "metadata": {},
   "source": [
    "Bonferroni: https://avast.github.io/ep-stats/stats/multiple.html\n",
    "\n",
    "Method 1: The alpha value (0.05) is divided by the number of tests (e.g. 225 pathways x 225 pathways = 50,625) and then the original p-vals are compared to the adjusted alpha value\n",
    "\n",
    "Method 2: The alpha value remains unchanged and the individual p-values are adjusted (i.e. original p-value x number of tests) to increase them, and then compared to see if they cross the 0.05 significance level\n",
    "\n",
    "After adjustment, some corrected p-values go up to 1 (the maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b693f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate number of significant values\n",
    "\n",
    "#All self-comparisons are significant with a p-value of 0, so we can subtract those from the number of significant values before dividing by 2\n",
    "sig_vals = (sum(i < 0.005 for i in spearman_df.pval_adj)-len(kpca_scores.columns))   /2\n",
    "non_sig_vals = sum(i >= 0.005 for i in spearman_df.pval_adj)/2\n",
    "\n",
    "print(\"Number of significant values:\", sig_vals)\n",
    "print(\"Number of non-significant values:\", non_sig_vals)\n",
    "(sig_vals/(sig_vals+non_sig_vals)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff933af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function takes in a dataframe as input, and masks one half and the diagonal to remove duplicates to prepare for a histogram plot\n",
    "\n",
    "def duplicate_removal(df):\n",
    "    #Mask the upper half of the dataframe (so I don't view the comparisons between the two same genes, and also the duplicate comparisons are removed)\n",
    "    mask =  df.copy()\n",
    "    mask = np.triu(np.ones(mask.shape)).astype(bool)\n",
    "    mask = np.invert(mask) #invert true and false values so the diagonal is False as well\n",
    "    non_dup_df = pd.DataFrame(df)\n",
    "    non_dup_df = non_dup_df.where(mask) #replace all false values with NaN using mask\n",
    "\n",
    "    spearman_hist = non_dup_df.to_numpy().flatten()\n",
    "    spearman_hist = spearman_hist[~np.isnan(spearman_hist)] #remove nan values\n",
    "\n",
    "    return spearman_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85921c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot histogram of the squared Spearman correlation\n",
    "\n",
    "squared_spearman_coef = np.square(spearman_coef)\n",
    "#abs_spearman_coef = np.abs(spearman_coef)\n",
    "\n",
    "spearman_hist = duplicate_removal(squared_spearman_coef) \n",
    "\n",
    "print(len(spearman_hist))\n",
    "\n",
    "#https://cambiocteach.com/accessibility/colourchoice/   for colour palette\n",
    "#orange #e69f00     sky blue #56b4e9    blue-green #009e73   \n",
    "sns.histplot(spearman_hist, bins = 50,color='#e69f00',edgecolor=\"k\")  \n",
    "\n",
    "#plt.title('Spearman correlation coefficient distribution',fontsize=16)\n",
    "plt.xlabel('Squared Spearman correlation',fontsize=16, labelpad=5)\n",
    "plt.ylabel('Count',fontsize=16, labelpad=10) ;\n",
    "\n",
    "#plt.savefig('../Figures/metabolomic_spearman_correlation_distribution_squared_non_dup.png', dpi=300, bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e6c717-2b84-4c48-8864-bc32bc5a2b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot heatmap of the squared Spearman correlation (idea from Sara's thesis)\n",
    "\n",
    "#The reason for plotting as absolute or squared is that kPCA does not determine the directionality of effect\n",
    "#Therefore the direction specified here is arbitrary i.e. negative pathway score does not mean downregulation of pathway\n",
    "\n",
    "g = sns.clustermap(\n",
    "    squared_spearman_coef,\n",
    "    metric='euclidean', \n",
    "    method =\"ward\",\n",
    "    cmap=\"OrRd\",    #Spectral_r for normal,  OrRd for the other two\n",
    "    xticklabels=False,\n",
    "    yticklabels=False,\n",
    "    figsize=(6,6),\n",
    "    dendrogram_ratio=0.15, \n",
    "    vmin=0, \n",
    "    vmax=1) \n",
    "\n",
    "g2 = g.ax_heatmap\n",
    "g2.set_xlabel(\"Pathways\", fontsize = 17, labelpad=10) #labelpad increases the distance between the axis label and the heatmap\n",
    "g2.set_ylabel(\"Pathways\", fontsize = 17, labelpad=10) \n",
    "\n",
    "x0, _y0, _w, _h = g.cbar_pos\n",
    "g.ax_cbar.set_position([1.15, 0.25, 0.03, 0.35])\n",
    "g.cax.set_title(\"Correlation score\",pad=13,size=13) #pad: increase spacing slightly  \n",
    "g.cax.tick_params(labelsize=12) #change font size of colourbar labels; \n",
    "\n",
    "#plt.savefig( 'Figures/squared_metabolite_spearman.png' , dpi=300,bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a256e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the log of the spearman p-values after correcting for multiple testing\n",
    "np.seterr(divide = 'ignore')   \n",
    "corrected_pvals = np.array(spearman_pvals) * num_of_tests\n",
    "#print(corrected_pvals)\n",
    "print(num_of_tests)\n",
    "log_spearman_pvals = -np.log10(corrected_pvals)\n",
    "print(log_spearman_pvals)\n",
    "np.seterr(divide = 'warn') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cee5cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot histogram of the Spearman p-values (AFTER MULTIPLE TESTING)\n",
    "\n",
    "spearman_pval_hist = duplicate_removal(log_spearman_pvals)  #p-values of 0 become infinite values that are not plotted (too far along axis)\n",
    "print(len(spearman_pval_hist))\n",
    "sns.histplot(spearman_pval_hist, bins = 50,color='#56b4e9',edgecolor=\"k\") \n",
    "\n",
    "#plt.title('Spearman p-value distribution',fontsize=16)\n",
    "plt.xlabel('Spearman correlation p-values (-log10)',fontsize=16, labelpad=5)\n",
    "plt.ylabel('Count',fontsize=16, labelpad=10) ;\n",
    "\n",
    "#plt.savefig('../Figures/metabolomic_spearman_pval_distribution_non_dup.png' , dpi=300,bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e52b3128",
   "metadata": {},
   "source": [
    "### Overlap coefficient"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc3e5db1",
   "metadata": {},
   "source": [
    "sspa kPCA automatically filters out all pathways that have less than 2 molecules in them (since the pathway with the minimum number of metabolites is 2 molecules). When I filter out the molecules that are not in the dataset, I only include them into the new dictionary if the values have more than 1 molecule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30745c3-7ed5-440a-b24b-d6bce9d0e65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain pathways and corresponding molecules for all Reactome pathways, store as dictionary\n",
    "orig_dict = sspa.utils.pathwaydf_to_dict(reactome_pathways)\n",
    "\n",
    "#Filter out dictionary to retain only the pathways that remain after kPCA i.e. pathways where 2 or more molecules are present in the dataset\n",
    "my_keys = kpca_scores.columns\n",
    "pathways_dict = {key: orig_dict[key] for key in my_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f085493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out the molcules in the pathways that are not present in the dataset\n",
    "\n",
    "#Obtain all unique values in dataset\n",
    "molecules_present = list(df.columns[:-2])\n",
    "filtered_dict = {} \n",
    "\n",
    "#My code adapted from Cecilia's\n",
    "#If the key values are not part of the molecules in dataset then remove\n",
    "for key,value in pathways_dict.items():\n",
    "    new_val = [item for item in value if item in molecules_present]\n",
    "    if len(new_val) >= 2: #at least two molecules in the pathway\n",
    "        filtered_dict[key] = new_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c53a4ec-046f-4cc1-b4d5-b02c9a7b4b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifying all duplicate pathways from the Reactome pathway dictionary AFTER MOLECULES NOT IN PATHWAY REMOVED (the exact same metabolites, not subsets)\n",
    "\n",
    "metabolites = list(filtered_dict.values())\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "c = Counter(map(tuple,metabolites))\n",
    "dups = [k for k,v in c.items() if v>1]\n",
    "result = [list(dup) for dup in dups]\n",
    "\n",
    "for j in result:\n",
    "    value = {i for i in filtered_dict if filtered_dict[i]==j}\n",
    "    print(value)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec4aa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the pathways with the minimum and maximum number of metabolites in pathways AFTER MOLECULES NOT IN PATHWAY REMOVED\n",
    "\n",
    "max_len = max(metabolites, key=len)\n",
    "print(len(max_len))\n",
    "\n",
    "min_len = min(metabolites, key=len)\n",
    "print(len(min_len))\n",
    "\n",
    "#Search which pathways have a length of 4 metabolites, for example\n",
    "for index in range(0,len(metabolites)):\n",
    "    length = 4\n",
    "    value = {key for key in filtered_dict if len(filtered_dict[key])==length}\n",
    "print(value)\n",
    "\n",
    "#len(filtered_dict['R-HSA-1430728'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d5c35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking Overlap coefficient code for the cell below\n",
    "\n",
    "list1 = ['A','B','C','D','E','F','G']\n",
    "list2 = ['A','B','C','J','K','L','M','N']\n",
    "intersection = list(set(list1).intersection(list(set(list2))))  #set removes duplicates\n",
    "numerator = len(intersection)\n",
    "\n",
    "smaller_set = []\n",
    "smaller_set.append(len(list1))\n",
    "smaller_set.append(len(list2))\n",
    "denominator = min(smaller_set)\n",
    "\n",
    "val = (numerator/denominator)\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c80e27a-1aa9-43b5-9aa6-f172f599ec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Difference between Jaccard similarity metric and S-S Overlap Coefficient\n",
    "#https://developer.nvidia.com/blog/similarity-in-graphs-jaccard-versus-the-overlap-coefficient/\n",
    "\n",
    "#Using Overlap Coefficient formula \n",
    "\n",
    "#Adapted from Cecilia's code\n",
    "oc_matrix = np.zeros((len(my_keys),len(my_keys)))    \n",
    "\n",
    "for i in range(0,len(my_keys)):   \n",
    "    list1 = filtered_dict[my_keys[i]]\n",
    "    \n",
    "    for j in range(0,len(my_keys)):\n",
    "        list2 = filtered_dict[my_keys[j]]\n",
    "\n",
    "        #SzymkiewiczSimpson coefficient\n",
    "        #Find intersection between two lists and divide by the smaller pathway size\n",
    "        intersection = len(list(set(list1).intersection(list(set(list2)))))\n",
    "        smaller_set = min(len(list1), len(list2))\n",
    "\n",
    "        val = intersection/smaller_set\n",
    "        oc_matrix[i][j] = val \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8282403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add overlap coefficient scores for each pathway pair \n",
    "\n",
    "oc_df = pd.DataFrame(oc_matrix, index=filtered_dict.keys(), columns=filtered_dict.keys())\n",
    "\n",
    "oc_list = oc_df.stack().reset_index()\n",
    "oc_list.columns = [\"Pathway1\", \"Pathway2\", \"Overlap_coef\"]\n",
    "spearman_df = spearman_df.merge(oc_list,on=[\"Pathway1\",\"Pathway2\"])\n",
    "\n",
    "display(spearman_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f93a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate number of edges with overlap coefficient values under 0.5\n",
    "\n",
    "#If looking at whole matrix (not accounting for self comparisons or duplicates)\n",
    "#print(np.count_nonzero(oc_matrix < 0.5)/(len(my_keys)*len(my_keys)))\n",
    "\n",
    "#Subtract by number of self-comparisons divided by 2\n",
    "high_overlap = (np.count_nonzero(oc_matrix < 0.5) - len(my_keys)) / 2\n",
    "unique_edges =  ((len(my_keys)*len(my_keys)) - len(my_keys)) / 2\n",
    "\n",
    "print((high_overlap  /  unique_edges) * 100, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3898459-ba00-4ac2-9a6e-c09bcf9fb1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot heatmap for the overlap coefficient (idea from Sara's thesis)\n",
    "\n",
    "g = sns.clustermap(oc_matrix,\n",
    "metric='euclidean', \n",
    "method =\"ward\",\n",
    "cmap = \"OrRd\", \n",
    "xticklabels=False, \n",
    "yticklabels=False, \n",
    "figsize=(6,6),\n",
    "dendrogram_ratio=0.2, \n",
    "vmin=-0, \n",
    "vmax=1) \n",
    "\n",
    "g2 = g.ax_heatmap\n",
    "g2.set_xlabel(\"Pathways\", fontsize = 17, labelpad=10) #labelpad increases the distance between the axis label and the heatmap\n",
    "g2.set_ylabel(\"Pathways\", fontsize = 17, labelpad=10) \n",
    "\n",
    "x0, _y0, _w, _h = g.cbar_pos\n",
    "g.ax_cbar.set_position([1.15, 0.25, 0.03, 0.35])\n",
    "g.cax.set_title(\"Overlap Coefficient\",pad=13,size=13) #pad: increase spacing slightly  \n",
    "g.cax.tick_params(labelsize=12) #change font size of colourbar labels; \n",
    "\n",
    "#plt.savefig( '../Figures/metabolite_overlap_coef.png' , dpi=300,bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b89411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot histogram for the overlap coefficient\n",
    "\n",
    "oc_hist = duplicate_removal(oc_matrix)\n",
    "print(len(oc_hist))\n",
    "sns.histplot(oc_hist, bins = 50,color='#009e73',edgecolor=\"k\")   \n",
    "\n",
    "#plt.title('Overlap coefficient distribution',fontsize=16)\n",
    "plt.xlabel('Overlap coefficient',fontsize=16, labelpad=5)\n",
    "plt.ylabel('Count',fontsize=16, labelpad=10) ;\n",
    "\n",
    "#plt.savefig('../Figures/metabolomic_overlap_coef_distribution_non_dup.png' , dpi=300,bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363120c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot figure showing data for Spearman correlation, Spearman p-value and for the overlap coefficient\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "points = ax.scatter(x=oc_hist, y=spearman_pval_hist,c=spearman_hist, s=6, cmap=\"viridis\",alpha=0.3)\n",
    "\n",
    "#Normal settings\n",
    "cb = plt.colorbar(points, ticks=[0,0.2,0.4,0.6,0.8,1],shrink=0.5)   #shrink is redundant if you decide to set the position and size on next line\n",
    "cb.ax.set_position([0.9, 0.28, 0.03, 0.35])\n",
    "cb.ax.set_title('Spearman correlation',pad=10, size=10) #pad means the height of title away from colourbar\n",
    "\n",
    "#Settings for legend only \n",
    "#cb = plt.colorbar(points, ticks=[0,0.2,0.4,0.6,0.8,1])#,shrink=1)\n",
    "#cb.ax.set_position([1.1, 0.28, 0.5, 0.7])\n",
    "#cb.ax.set_title('Spearman correlation',pad=10, size=17) #pad means the height of title away from colourbar\n",
    "#cb.ax.tick_params(labelsize=15) \n",
    "\n",
    "plt.xlabel(\"Overlap coefficient\",fontsize=15, labelpad=5)\n",
    "plt.ylabel(\"Spearman p-values (-log10)\",fontsize=15, labelpad=5)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "#Showing the cutoff:\n",
    "plt.axvline(x=0.5, color='r', linewidth=1, linestyle='--', dashes=(15, 4))\n",
    "plt.axhline(y=-np.log10(0.005), color='r', linewidth=1, linestyle='--', dashes=(15, 4)) \n",
    "\n",
    "#plt.savefig('../Figures/metabolomic_scatterplot.png', dpi=300, bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')\n",
    "#plt.savefig('../Figures/scatterplot_legend.png' ,dpi=300,bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22dbd969",
   "metadata": {},
   "source": [
    "### Overlap coefficient network graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878433ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Practice code\n",
    "#Even for an edge going between two pathways, it's a single line here and in Cytoscape as well\n",
    "#If you wanted to draw multiple edges going between the same two nodes, you would need to draw a multigraph\n",
    "G = nx.Graph()\n",
    "\n",
    "practice_df = {'Pathway1': ['A', 'B', 'C', 'D','D'], 'Pathway2': ['B','A','D','C','D'], 'weight': [1,1,2,5,3]}\n",
    "pd.DataFrame(data=practice_df, index=[0, 1, 2, 3,4])\n",
    "\n",
    "G = nx.from_pandas_edgelist(df=practice_df, source='Pathway1', target='Pathway2', edge_attr='weight')\n",
    "\n",
    "nx.draw(G, with_labels = True)\n",
    "\n",
    "#nx.write_gml(G, \"test.gml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283ff6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove self-correlations\n",
    "#Duplicate edges are not removed so they are removed during the NetworkX graph construction\n",
    "spearman_df = spearman_df [spearman_df.Pathway1 != spearman_df.Pathway2]\n",
    "spearman_df = spearman_df.reset_index(drop=True)\n",
    "spearman_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eda382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the overlap coefficient network, I DON'T FILTER OUT ANY EDGES HERE: I FILTER IN CYTOSCAPE\n",
    "G = nx.from_pandas_edgelist(df=spearman_df, source='Pathway1', target='Pathway2', edge_attr='Overlap_coef')\n",
    "\n",
    "nx.draw(G, with_labels = True)\n",
    "print(G.number_of_edges())\n",
    "print(G.number_of_nodes())\n",
    "#nx.write_gml(G, \"Cytoscape/metabolomic_oc.gml\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6989a09e",
   "metadata": {},
   "source": [
    "### Final correlation network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e063c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a pre-filtered network with all the edges\n",
    "\n",
    "G = nx.Graph()\n",
    "G = nx.from_pandas_edgelist(df=spearman_df, source='Pathway1', target='Pathway2', edge_attr='Squared_corr')\n",
    "\n",
    "nx.draw(G, with_labels = True)\n",
    "print(G.number_of_nodes())\n",
    "print(G.number_of_edges())\n",
    "\n",
    "\n",
    "#Add edge attributes\n",
    "spearman_pval_dict = {}\n",
    "overlap_coef_dict = {}\n",
    "for i in range(0,len(spearman_df)):\n",
    "    spearman_pval_dict[(spearman_df.Pathway1[i],spearman_df.Pathway2[i])] = spearman_df.pval_adj[i] #Remember to take the CORRECTED Spearman p-values\n",
    "    overlap_coef_dict[(spearman_df.Pathway1[i],spearman_df.Pathway2[i])] = spearman_df.Overlap_coef[i]\n",
    "\n",
    "nx.set_edge_attributes(G, spearman_pval_dict, \"Spearman_pval\")\n",
    "nx.set_edge_attributes(G, overlap_coef_dict, \"Overlap_coef\")\n",
    "\n",
    "#Check one edge to see the edge attributes\n",
    "G.edges[\"R-HSA-110331\",\"R-HSA-112310\"]#[\"Spearman_pval\"]\n",
    "\n",
    "#nx.write_gml(G,'Cytoscape/metabolomic_prefiltered_commoncases.gml')\n",
    "#nx.write_gml(G,'Cytoscape/metabolomic_prefiltered_mildcases.gml')\n",
    "#nx.write_gml(G,'Cytoscape/metabolomic_prefiltered_severecases.gml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be76d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an edge attribute table to filter out unneeded edges\n",
    "\n",
    "final_df = spearman_df[spearman_df[\"pval_adj\"] < 0.005]  \n",
    "final_df = final_df[final_df[\"Overlap_coef\"] < 0.5]\n",
    "\n",
    "print(\"Total correlation network: \",( (len(final_df)/2) / (len(spearman_df)/2))   * 100, \"% of original\")\n",
    "final_df = final_df.reset_index(drop=True) \n",
    "display(final_df) #the duplicate edges have not been removed yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca63676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Spearman correlation histogram to show edges AFTER filtering (optional)\n",
    " \n",
    "#Remove duplicates in the edge list\n",
    "final_df_copy = final_df.copy()\n",
    "\n",
    "#Remove duplicate pathways\n",
    "for i in range(0,len(final_df)):\n",
    "    val1 = final_df.Pathway1[i]\n",
    "    val2 = final_df.Pathway2[i]\n",
    "    #print(val1,val2)\n",
    "    #print(max(val1,val2))\n",
    "    final_df_copy.Pathway1[i] = min(val1,val2)\n",
    "    final_df_copy.Pathway2[i] = max(val1,val2)\n",
    "\n",
    "print(len(final_df_copy))\n",
    "spearman_hist = list(final_df_copy.Squared_corr)\n",
    "sns.histplot(spearman_hist, bins = 50,color='#FFD580',edgecolor=\"k\") \n",
    "\n",
    "plt.title('Spearman correlation coefficient distribution',fontsize=16)\n",
    "plt.xlabel('Correlation score',fontsize=16, labelpad=5)\n",
    "plt.ylabel('Count',fontsize=16, labelpad=10) ;\n",
    "\n",
    "#plt.savefig('Figures/metabolite_spearman_correlation_distribution_squared_afterfiltering_commoncases.png', dpi=300, bbox_inches = 'tight', pad_inches = 0.2, facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050718e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify isolated nodes (optional)\n",
    "\n",
    "pathways_with_edges = set(final_df.Pathway1)\n",
    "isolated_nodes = set(spearman_df.Pathway1) - set(pathways_with_edges) \n",
    "isolated_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07f55e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw network graph with new edges\n",
    "\n",
    "G = nx.Graph()\n",
    "G = nx.from_pandas_edgelist(df=final_df, source='Pathway1', target='Pathway2', edge_attr='Squared_corr')\n",
    "#G.add_nodes_from(isolated_nodes) #Add the isolated nodes (optional)\n",
    "nx.draw(G, with_labels = True)\n",
    "print(G.number_of_nodes())\n",
    "print(G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5bbcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add edge attributes\n",
    "spearman_pval_dict = {}\n",
    "overlap_coef_dict = {}\n",
    "for i in range(0,len(final_df)):\n",
    "    spearman_pval_dict[(final_df.Pathway1[i],final_df.Pathway2[i])] = final_df.pval_adj[i]\n",
    "    overlap_coef_dict[(final_df.Pathway1[i],final_df.Pathway2[i])] = final_df.Overlap_coef[i]\n",
    "    \n",
    "nx.set_edge_attributes(G, spearman_pval_dict, \"Spearman_pval\")\n",
    "nx.set_edge_attributes(G, overlap_coef_dict, \"Overlap_coef\")\n",
    "\n",
    "#Check one edge to see the edge attributes\n",
    "#G.edges[\"R-HSA-110331\",\"R-HSA-112310\"]#[\"Spearman_pval\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab94625d",
   "metadata": {},
   "source": [
    "### Setting node attributes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4cb53d6",
   "metadata": {},
   "source": [
    "The betweenness centrality scores are the same whether or not the duplicates have been removed since the duplicate edges form the same edge when a graph is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d880c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Must filter out some of the edges first\n",
    "\n",
    "#Add the betweenness centrality as a node attribute\n",
    "betweenness= nx.betweenness_centrality(G, normalized=True) #output as dictionary\n",
    "#display(betweenness)\n",
    "nx.set_node_attributes(G, betweenness, \"betweenness\")\n",
    "\n",
    "#Add the degree centrality as a node attribute\n",
    "degree= nx.degree_centrality(G) #output as dictionary\n",
    "#display(degree)\n",
    "nx.set_node_attributes(G, degree, \"degrees\")\n",
    "\n",
    "print(G.number_of_nodes()) \n",
    "#Check one node to see the node attributes\n",
    "#G.nodes['R-HSA-110331']#[\"betweenness\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6f1749e",
   "metadata": {},
   "source": [
    "Setting the highest level of the pathway hierarchy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a412bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Cecilia's code\n",
    "\n",
    "#Creating graph\n",
    "hierarchy = pd.read_csv('../Data/ReactomePathwaysRelation.txt', sep='\\t', header=None)\n",
    "\n",
    "#From the pathways, subset to Homo sapiens only\n",
    "hierarchy_hsa = hierarchy[hierarchy[0].str.contains('HSA')]\n",
    "\n",
    "#Return unique values in the first column that is not in the second column as a numpy array\n",
    "#These values are not child pathways in any instances\n",
    "hierarchy_hsa_parents = np.setdiff1d(hierarchy_hsa[0], hierarchy_hsa[1])\n",
    "\n",
    "#Add the unique values not in the second column as a second attached dataset to the bottom of the original data\n",
    "#The first column represents the parent column, the second column is the child column\n",
    "hierarchy_hsa_all = pd.concat([hierarchy_hsa, pd.DataFrame([hierarchy_hsa_parents, hierarchy_hsa_parents], index=[0, 1]).T])\n",
    "\n",
    "#DiGraph is a directed graph\n",
    "H = nx.from_pandas_edgelist(hierarchy_hsa, source=0, target=1, create_using=nx.DiGraph())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69b9d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Cecilia's code\n",
    "\n",
    "#Find the root pathway\n",
    "\n",
    "def find_root(H,child):\n",
    "    #Find parent from child \n",
    "    parent = list(H.predecessors(child))\n",
    "\n",
    "    #Keep the loop going until the highest level is reached\n",
    "    if len(parent) == 0:\n",
    "        return child\n",
    "    else:  \n",
    "        return find_root(H, parent[0])\n",
    "\n",
    "hierarchy_hsa_all['Root'] = [find_root(H, i) for i in hierarchy_hsa_all[1]]\n",
    "\n",
    "hierarchy_hsa_all.columns = ['Parent', 'Child', 'Root']\n",
    "\n",
    "#There are 83 instances of child duplicates, however all the child duplicates have the same root (even though different parents) after checking\n",
    "\n",
    "root_pathways = {}\n",
    "for pathway in list(H.nodes):\n",
    "    index = hierarchy_hsa_all.Child[hierarchy_hsa_all.Child == pathway].index.tolist()[0]\n",
    "    root_pathway  = hierarchy_hsa_all.Root[index]\n",
    "    label = root_pathway_dict[root_pathway]\n",
    "    root_pathways[pathway] = label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbae7a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Cecilia's code\n",
    " \n",
    "#Shows all the root pathways in Reactome\n",
    "set(hierarchy_hsa_all['Root'] )\n",
    "#Shows all the root pathways present in the original dataset\n",
    "set(root_pathways.values())\n",
    "\n",
    "nx.set_node_attributes(G, root_pathways, \"root_pathway\")\n",
    "\n",
    "print(G.number_of_nodes()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289364bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering with Louvain algorithm\n",
    "\n",
    "#For some reason, not sure if really clustering by weight since it works with a typo \n",
    "#I think it works though, since changing the name gives a diff num of clusters even with seed set\n",
    "#Resolution = 1 is the default, increasing resolution will yield more communities\n",
    "louvain_clusters = nx.community.louvain_communities(G, weight='Squared_corr',seed=100,resolution=1.2)\n",
    "print(len(louvain_clusters))\n",
    "\n",
    "louvain_dict = {}\n",
    "for index,grouping in enumerate(louvain_clusters):\n",
    "    for pathway in grouping:\n",
    "        louvain_dict[pathway] = index+1\n",
    "\n",
    "nx.set_node_attributes(G, louvain_dict, \"louvain\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5f1a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign pathway name to node\n",
    "\n",
    "pathway_name_dict = {reactome_pathways.index[i]:reactome_pathways[\"Pathway_name\"][i] for i in range(0,len(reactome_pathways))}\n",
    "#Filter dictionary to the pathways in the dataset only\n",
    "pathway_name_dict = {k:pathway_name_dict[k] for k in list(G.nodes)}\n",
    "\n",
    "nx.set_node_attributes(G, pathway_name_dict, \"pathway_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d896c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check data before saving as network\n",
    "\n",
    "print(G.number_of_nodes())\n",
    "print(G.number_of_edges())\n",
    "\n",
    "#print(G.nodes['R-HSA-110331'])#[\"betweenness\"]\n",
    "#print(G.edges[\"R-HSA-110331\", \"R-HSA-112310\"])#[\"Spearman_pval\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dae2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nx.write_gml(G,'Cytoscape/metabolomic_final_commoncases.gml')\n",
    "#nx.write_gml(G,'Cytoscape/metabolomic_final_mildcases.gml')\n",
    "#nx.write_gml(G,'Cytoscape/metabolomic_final_severecases.gml')\n",
    "\n",
    "#nx.write_gml(G,'Cytoscape/proteomic_final_commoncases.gml')\n",
    "#nx.write_gml(G,'Cytoscape/proteomic_final_mildcases.gml')\n",
    "#nx.write_gml(G,'Cytoscape/proteomic_final_severecases.gml')\n",
    "\n",
    "#nx.write_gml(G,'Cytoscape/integrated_final_commoncases.gml')\n",
    "#nx.write_gml(G,'Cytoscape/integrated_final_mildcases.gml')\n",
    "#nx.write_gml(G,'Cytoscape/integrated_final_severecases.gml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635329ca",
   "metadata": {},
   "source": [
    "Metabolomic: <br>\n",
    "All common cases: 117 nodes, 724 edges <br>\n",
    "Mild cases: 36 nodes, 132 edges <br>\n",
    "Severe cases: 68 nodes, 198 edges <br>\n",
    "\n",
    "\n",
    "Proteomic: <br>\n",
    "All common cases: 563 nodes, 80,969 edges <br>\n",
    "Mild cases: 405 nodes, 7,333 edges <br>\n",
    "Severe cases: 522 nodes, 71,172 edges <br>\n",
    "\n",
    "\n",
    "Integrated: <br>\n",
    "All common cases: 666 nodes, 90,096 edges <br>\n",
    "Mild cases: 424 nodes, 6,421 edges <br>\n",
    "Severe cases: 589 nodes, 78,106 edges <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
