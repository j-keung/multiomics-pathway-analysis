{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a17959a-e57d-4b6a-bf35-ebb68ac0e07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries \n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import sspa\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy \n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "180e7d8b-b2ef-419f-ac87-fa9862328a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the whole dataset\n",
    "#df = pd.read_csv('Data/Su_COVID_metabolomics_processed.csv', index_col=0)\n",
    "#df.index= df.index.str.rstrip('-BL')\n",
    "#print(df.iloc[:10,-2:])    #show subset of control data (first 10 rows, last two columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "799b6e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the common cases dataset\n",
    "df = pd.read_csv('Data/Su_COVID_metabolomics_processed_commoncases.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32e4aeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function takes in dataframe, and masks one half and the diagonal to remove duplicates to prepare for a histogram plot\n",
    "def duplicate_removal(df):\n",
    "    #Mask the upper half of the dataframe (so I don't view the comparisons between the two same genes, and also the duplicate comparisons are removed)\n",
    "    mask =  df.copy()\n",
    "    mask = np.triu(np.ones(mask.shape)).astype(bool)\n",
    "    mask = np.invert(mask) #invert true and false values so the diagonal is False as well\n",
    "    non_dup_df = pd.DataFrame(df)\n",
    "    non_dup_df = non_dup_df.where(mask) #Replace all false values with NaN using mask\n",
    "\n",
    "    spearman_hist = non_dup_df.to_numpy().flatten()\n",
    "    spearman_hist = spearman_hist[~np.isnan(spearman_hist)] #remove nan values\n",
    "\n",
    "    return spearman_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04db5459",
   "metadata": {},
   "source": [
    "### FOR DATA INTEGRATION STEP OR IF COMPARING BY CASE SEVERITY\n",
    "### Subset the data to common samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdbf3ad",
   "metadata": {},
   "source": [
    "We make two different networks, one for the COVID cases 1-2 compared to COVID cases 3-7 <br>\n",
    "This is because there are only 18 samples in common between the metabolomic and proteomic datasets\n",
    "\n",
    "0       Common samples: 18           Metabolomic samples: 133        Proteomic samples: 123 <br>\n",
    "1-2       Common samples: 45          Metabolomic samples: 45        Proteomic samples: 48 <br>\n",
    "3-4       Common samples: 56          Metabolomic samples: 57        Proteomic samples: 59 <br>\n",
    "5-7       Common samples: 27          Metabolomic samples: 28        Proteomic samples: 28 <br>\n",
    "\n",
    "146 common samples overall,   128 cases, composed of (45 samples (WHO 1-2) vs 83 samples (WHO 3-7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5654b3ff",
   "metadata": {},
   "source": [
    "Subsetting the dataset to common samples and THEN CENTERING THE DATA ONCE MORE (no need to log2 transform):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ef65428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "#df2 = pd.read_csv('Data/Su_COVID_proteomics_processed.csv', index_col=0)\n",
    "#list1 = list(df.index)\n",
    "#list2 = list(df2.index)\n",
    "\n",
    "#Obtain common samples and subset accordingly\n",
    "#intersection = list(set(df.index.tolist()) & set(df2.index.tolist())) #set removes duplicates\n",
    "#intersection = [sample for sample in intersection if sample.startswith(\"INCOV\")]\n",
    "#df = df[df.index.isin(intersection)]\n",
    "\n",
    "#print(len(df))\n",
    "#df_num  = df.iloc[:,:-2] #all rows, all columns apart from last two\n",
    "#df_norm = pd.DataFrame(StandardScaler().fit_transform(df_num),columns=df_num.columns, index=df_num.index)\n",
    "\n",
    "#Add metadata to the end of the df\n",
    "#df_final = pd.concat([df_norm, df.iloc[:,-2:]],axis=1) \n",
    "#df_final.to_csv('Data/Su_COVID_metabolomics_processed_commoncases.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819876bf",
   "metadata": {},
   "source": [
    "Subsetting the dataframe into two groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf58960",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mild = (df[df[\"WHO_status\"] == '1-2']) #45 samples, no need to remove the metadata, since I do that in a later step\n",
    "df_severe = (df[(df[\"WHO_status\"] == '3-4') | (df[\"WHO_status\"] == '5-7')]) #83 samples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b5e73a1",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9cd462e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of metabolites: 333\n",
      "Number of samples: 128\n",
      "3-4    56\n",
      "1-2    45\n",
      "5-7    27\n",
      "Name: WHO_status, dtype: int64\n",
      "COVID19     128\n",
      "Name: Group, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WHO_status    object\n",
       "Group         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of metabolites:\", len(df. columns[:-2]) )\n",
    "print(\"Number of samples:\", len(df. index))\n",
    "\n",
    "print(df['WHO_status'].value_counts()) \n",
    "print(df['Group'].value_counts())\n",
    "\n",
    "#return non-integer columns\n",
    "df.dtypes[df.dtypes != 'int64'][df.dtypes != 'float64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8001c6a-c137-4013-8f87-743622833502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.947848832735254\n",
      "-5.091869731580215\n",
      "1372    -6.938894e-18\n",
      "16610   -4.163336e-17\n",
      "72665    4.163336e-17\n",
      "27823    0.000000e+00\n",
      "30915   -4.163336e-17\n",
      "             ...     \n",
      "28238   -3.816392e-17\n",
      "76341    3.122502e-17\n",
      "89312    2.428613e-17\n",
      "17861    2.081668e-17\n",
      "89188    6.938894e-17\n",
      "Length: 333, dtype: float64\n",
      "1372     1.003929\n",
      "16610    1.003929\n",
      "72665    1.003929\n",
      "27823    1.003929\n",
      "30915    1.003929\n",
      "           ...   \n",
      "28238    1.003929\n",
      "76341    1.003929\n",
      "89312    1.003929\n",
      "17861    1.003929\n",
      "89188    1.003929\n",
      "Length: 333, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Check data is standardised \n",
    "\n",
    "df_num  = df.iloc[:,:-2] #all rows, all columns apart from last two\n",
    "print(df_num.max().max())\n",
    "print(df_num.min().min())\n",
    "print(df_num.mean(axis = 0)) #mean of 0\n",
    "print(df_num.std(axis = 0)) #sd of 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d5d5de-1091-4c7c-97fc-f8a1e8b5505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist = df_num.mean(axis = 0) #axis = 0 by column\n",
    "sns.histplot(df_hist, bins = 30,color='#79C99E',edgecolor=\"k\") \n",
    "\n",
    "#The mean value for each metabolite has been plotted\n",
    "plt.title('Mean metabolite distribution',fontsize=16)\n",
    "plt.xlabel('Metabolite expression (e-15)',fontsize=13)\n",
    "plt.ylabel('Count',fontsize=13) ;\n",
    "\n",
    "#plt.savefig( 'Figures/mean_metabolite_distribution.png' , dpi=200,bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ce2df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = df_num.to_numpy()\n",
    "\n",
    "df_hist = df_num.flatten()\n",
    "sns.histplot(df_hist, bins = 30,color='#79C99E',edgecolor=\"k\") \n",
    "\n",
    "plt.title('Metabolite distribution',fontsize=16)\n",
    "plt.xlabel('Metabolite expression',fontsize=13)\n",
    "plt.ylabel('Count',fontsize=13) ;\n",
    "\n",
    "#plt.savefig( 'Figures/metabolite_distribution.png' , dpi=200,bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e7de45-98ef-47f2-8a5f-2d635aa261fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df.iloc[:,-5:])\n",
    "df_heatmap = df.groupby('WHO_status').mean(numeric_only=True)\n",
    "#print(df_heatmap.iloc[:,-5:])\n",
    "\n",
    "g = sns.clustermap(\n",
    "    df_heatmap,\n",
    "    metric='euclidean', \n",
    "    method =\"ward\",\n",
    "    row_cluster=False,\n",
    "    xticklabels=False,\n",
    "    cmap='RdBu_r',\n",
    "    figsize=(9,3),\n",
    "    dendrogram_ratio=0.2, \n",
    "    vmin=-2, \n",
    "    vmax=2) \n",
    "\n",
    "g2 = g.ax_heatmap\n",
    "g2.set_xlabel(\"Metabolites\", fontsize = 15,labelpad=10) #labelpad increases the distance between the axis label and the heatmap\n",
    "g2.set_ylabel(\"WHO status\", fontsize = 15, labelpad=12) \n",
    "g2.set_yticklabels(g2.get_yticklabels(), rotation=0, fontsize=10)  #rotate the y-axis labels so that they are horizontal\n",
    "\n",
    "x0, _y0, _w, _h = g.cbar_pos\n",
    "g.ax_cbar.set_position([1.15, 0.28, 0.03, 0.35])\n",
    "g.cax.set_title(\"Metabolite expression\",pad=10, size=13) #pad: increase spacing slightly  \n",
    "g.cax.tick_params(labelsize=10) #change font size of colourbar labels; \n",
    "\n",
    "#plt.savefig( 'Figures/metabolite_heatmap.png' , dpi=200,bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53895c4a-4085-4b4c-92cf-ce6e7c95cd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carry out PCA\n",
    "\n",
    "#from sklearn.decomposition import PCA\n",
    "\n",
    "features = df.columns[:-2]\n",
    "x = df.loc[:, features].values\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(x)\n",
    "df2 = pd.DataFrame(data = principal_components, columns = ['PC1', 'PC2'])\n",
    "\n",
    "#Restore original index\n",
    "df2 = df2.set_index(df.index)\n",
    "\n",
    "#Concatenate WHO information\n",
    "df3 = pd.concat([df2, df[['WHO_status']]], axis = 1)\n",
    "\n",
    "display(df3)\n",
    "\n",
    "\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "\n",
    "sns.lmplot(\n",
    "    x='PC1', \n",
    "    y='PC2', \n",
    "    data=df3, \n",
    "    hue='WHO_status', \n",
    "    hue_order = ['0', '1-2', '3-4','5-7'],\n",
    "    fit_reg=False, #don't draw line of best fit\n",
    "    legend=False,\n",
    "    scatter_kws={\"s\": 20}\n",
    "    )\n",
    "#Note: I don't use the seaborn legend but check it matches with the seaborn legend\n",
    "\n",
    "\n",
    "plt.title('PCA for metabolites',fontsize=20)\n",
    "plt.xlabel('PC1 (' + str(round(pca.explained_variance_ratio_[0]*100,2)) + '%)',fontsize=15,)\n",
    "plt.ylabel('PC2 (' + str(round(pca.explained_variance_ratio_[1]*100,2)) + '%)',fontsize=15)\n",
    "plt.legend(framealpha=1, frameon = 'True', title=\"WHO status\",title_fontsize='large', prop={'size': 14}, bbox_to_anchor=(1.04, 0.7)) \n",
    "#This has more information on the bbox_to_anchor coordinates: https://stackoverflow.com/questions/4700614/how-to-put-the-legend-outside-the-plot\n",
    "\n",
    "#plt.savefig( 'Figures/metabolite_PCA.png' , dpi=200,bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d47e96e",
   "metadata": {},
   "source": [
    "### Single sample pathway analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a37f36-2918-48ec-814c-a262553d1c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying to download latest version of Reactome (version 84)\n",
    "\n",
    "\n",
    "#reactome_pathways = sspa.process_reactome(\"Homo sapiens\", download_latest=True, filepath=\".\")\n",
    "reactome_pathways = sspa.process_gmt(\"Data/Reactome_Homo_sapiens_pathways_compounds_R84.gmt\")\n",
    "#View name of pathway IDs\n",
    "reactome_pathways\n",
    "\n",
    "kpca_scores = sspa.sspa_kpca(df.iloc[:,:-2], reactome_pathways)\n",
    "#We have 160 pathways present, although the previous report had 165 pathways\n",
    "\n",
    "#print(kpca_scores.iloc[-10:,-2:])\n",
    "#print(kpca_scores)\n",
    "#won't work with the metabolite dataset with names\n",
    "kpca_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b475747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove root pathways\n",
    "#Convert pathway ID to name\n",
    "root_path = pd.read_excel('Data/Root_pathways.xlsx', header=None)\n",
    "root_pathway_dict = {root_path[0][i]:root_path[1][i] for i in range(0,len(root_path))}\n",
    "\n",
    "root_pathway_names = list(root_pathway_dict.keys())\n",
    "#Using Sara's code\n",
    "kpca_scores = kpca_scores.drop(columns = list(set(root_pathway_names) & set(kpca_scores.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293796c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca_scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef082299",
   "metadata": {},
   "source": [
    "### kPCA figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b1b60c-5123-4635-b01e-d72e11786585",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kpca_hist = kpca_scores.to_numpy()\n",
    "kpca_hist = kpca_hist.flatten()\n",
    "sns.histplot(kpca_hist, bins = 40,color='#F7C3B1',edgecolor=\"k\") \n",
    "\n",
    "plt.title('Metabolite pathway score distribution',fontsize=16)\n",
    "plt.xlabel('Pathway score',fontsize=13, labelpad=5)\n",
    "plt.ylabel('Count',fontsize=13, labelpad=10) ;\n",
    "\n",
    "#plt.savefig( 'Figures/metabolite_pathway_distribution.png' , dpi=200,bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12472e54-00d9-4197-a1b3-ca43c80e569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carry out PCA\n",
    "\n",
    "#from sklearn.decomposition import PCA\n",
    "\n",
    "features = kpca_scores.columns\n",
    "x = kpca_scores.loc[:, features].values\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(x)\n",
    "df2 = pd.DataFrame(data = principal_components, columns = ['PC1', 'PC2'])\n",
    "\n",
    "#Restore original index\n",
    "df2 = df2.set_index(df.index)\n",
    "\n",
    "#Concatenate WHO information\n",
    "df3 = pd.concat([df2, df[['WHO_status']]], axis = 1)\n",
    "\n",
    "#display(df3)\n",
    "\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "\n",
    "sns.lmplot(\n",
    "    x='PC1', \n",
    "    y='PC2', \n",
    "    data=df3, \n",
    "    hue='WHO_status', \n",
    "    hue_order = ['0', '1-2', '3-4','5-7'],\n",
    "    fit_reg=False, \n",
    "    legend=False,\n",
    "    scatter_kws={\"s\": 20}\n",
    "    )\n",
    "#Note: I don't use the seaborn legend but check it matches with the seaborn legend\n",
    "\n",
    "\n",
    "plt.title('PCA kPCA metabolite scores',fontsize=20)\n",
    "plt.xlabel('PC1 (' + str(round(pca.explained_variance_ratio_[0]*100,2)) + '%)',fontsize=15)\n",
    "plt.ylabel('PC2 (' + str(round(pca.explained_variance_ratio_[1]*100,2)) + '%)',fontsize=15)\n",
    "plt.legend(framealpha=1, frameon = 'True', title=\"WHO status\",title_fontsize='large', prop={'size': 14}, bbox_to_anchor=(1.04, 0.7))\n",
    "#This has more information on the bbox_to_anchor coordinates: https://stackoverflow.com/questions/4700614/how-to-put-the-legend-outside-the-plot\n",
    "#plt.savefig( 'Figures/metabolite_kPCA_PCA.png' , dpi=200,bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b24a9a4-cc49-4a66-a436-d509e836bfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalise pathway scores : https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "\n",
    "#StandardScaler() normalises by column i.e. each pathway is normalised across all patients\n",
    "#mean of the observed values becomes 0 and the standard deviation is 1\n",
    "\n",
    "#After meeting: Normalising doesn't seem to have a large effect\n",
    "#Whether or not you normalise won't make a huge difference\n",
    "kpca_scores_norm = pd.DataFrame(StandardScaler().fit_transform(kpca_scores),columns=kpca_scores.columns, index=kpca_scores.index)\n",
    "\n",
    "#print(kpca_scores_norm.max().max())\n",
    "#print(kpca_scores_norm.min().min())\n",
    "#print(kpca_scores_norm.mean(axis = 0)) #mean of 0  \n",
    "#print(kpca_scores_norm.std(axis = 0)) #sd of 1\n",
    "\n",
    "\n",
    "\n",
    "kpca_hist = kpca_scores_norm.to_numpy()\n",
    "kpca_hist = kpca_hist.flatten()\n",
    "sns.histplot(kpca_hist, bins = 40,color='#F7C3B1',edgecolor=\"k\") \n",
    "\n",
    "plt.title('Normalised metabolite pathway score distribution',fontsize=16)\n",
    "plt.xlabel('Pathway score',fontsize=13, labelpad=5)\n",
    "plt.ylabel('Count',fontsize=13, labelpad=10) ;\n",
    "\n",
    "#plt.savefig( 'Figures/normalised_metabolite_pathway_distribution.png' , dpi=200,bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557d9605-96ee-46cc-8067-e56eb3982b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carry out PCA on NORMALISED values\n",
    "\n",
    "#from sklearn.decomposition import PCA\n",
    "\n",
    "features = kpca_scores_norm.columns\n",
    "x = kpca_scores_norm.loc[:, features].values\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(x)\n",
    "df2 = pd.DataFrame(data = principal_components, columns = ['PC1', 'PC2'])\n",
    "\n",
    "#Restore original index\n",
    "df2 = df2.set_index(df.index)\n",
    "\n",
    "#Concatenate WHO information\n",
    "df3 = pd.concat([df2, df[['WHO_status']]], axis = 1)\n",
    "\n",
    "#display(df3)\n",
    "\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "\n",
    "sns.lmplot(\n",
    "    x='PC1', \n",
    "    y='PC2', \n",
    "    data=df3, \n",
    "    hue='WHO_status', \n",
    "    hue_order = ['0', '1-2', '3-4','5-7'],\n",
    "    fit_reg=False, \n",
    "    legend=False,\n",
    "    scatter_kws={\"s\": 20}\n",
    "    )\n",
    "#Note: I don't use the seaborn legend but check it matches with the seaborn legend\n",
    "\n",
    "\n",
    "plt.title('PCA kPCA normalised metabolite scores',fontsize=20)\n",
    "plt.xlabel('PC1 (' + str(round(pca.explained_variance_ratio_[0]*100,2)) + '%)',fontsize=15)\n",
    "plt.ylabel('PC2 (' + str(round(pca.explained_variance_ratio_[1]*100,2)) + '%)',fontsize=15)\n",
    "plt.legend(framealpha=1, frameon = 'True', title=\"WHO status\",title_fontsize='large', prop={'size': 14}, bbox_to_anchor=(1.04, 0.7))\n",
    "#This has more information on the bbox_to_anchor coordinates: https://stackoverflow.com/questions/4700614/how-to-put-the-legend-outside-the-plot\n",
    "#plt.savefig( 'Figures/normalised_metabolite_kPCA_PCA.png' , dpi=200,bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2e9f366",
   "metadata": {},
   "source": [
    "### Spearman correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3a0aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3334a95d-3a72-42a1-ae4c-8b174ce228fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: Spearman correlation coefficient results are the same whether or not the kPCA scores are normalised\n",
    "\n",
    "#\"If axis=0 (default), then each column represents a variable, with observations in the rows\"\n",
    "spearman_results = scipy.stats.spearmanr(kpca_scores)\n",
    "\n",
    "spearman_coef = spearman_results[0] #correlation coefficients\n",
    "spearman_pvals = spearman_results[1] #p-values\n",
    "\n",
    "\n",
    "#Using Sara's code (rather than having separate dataframes for each analysis, add all together in long format)\n",
    "squared_spearman_coef_df = pd.DataFrame(spearman_coef,columns = kpca_scores.columns, index=kpca_scores.columns)\n",
    "squared_spearman_coef_list = squared_spearman_coef_df.stack().reset_index()\n",
    "squared_spearman_coef_list.columns = [\"Pathway1\", \"Pathway2\", \"Spearman_corr\"]\n",
    "squared_spearman_coef_list[\"Squared_corr\"]  = np.square(squared_spearman_coef_list.Spearman_corr)\n",
    "\n",
    "spearman_pvals_df = pd.DataFrame(spearman_pvals,columns = kpca_scores.columns, index=kpca_scores.columns)\n",
    "spearman_pvals_list = spearman_pvals_df.stack().reset_index()\n",
    "spearman_pvals_list.columns = [\"Pathway1\", \"Pathway2\", \"pval\"]\n",
    "\n",
    "#Multiple testing correction for the p-values to prepare the corrected p-values for the final correlation network\n",
    "#Multiplies by the correct number of tests (i.e. not including the duplicates or self-comparisons)\n",
    "#Does not remove the diagonals or the duplicates themselves\n",
    "#  ((160x160)-160)  / 2\n",
    "num_of_tests = (len(kpca_scores.columns)**2 - len(kpca_scores.columns))/2\n",
    "print(num_of_tests)\n",
    "corrected_spearman_pvals = spearman_pvals_list.pval*num_of_tests\n",
    "#If the p-val goes beyond 1 (max number for a p-value, change to 1)\n",
    "corrected_spearman_pvals = np.where(corrected_spearman_pvals < 1, corrected_spearman_pvals, 1)\n",
    "spearman_pvals_list[\"pval_adj\"]  = corrected_spearman_pvals\n",
    "\n",
    "spearman_df = squared_spearman_coef_list.merge(spearman_pvals_list,on=[\"Pathway1\",\"Pathway2\"])\n",
    "\n",
    "display(spearman_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb4d8f94",
   "metadata": {},
   "source": [
    "Bonferroni: https://avast.github.io/ep-stats/stats/multiple.html\n",
    "\n",
    "Method 1: The alpha value (0.05) is divided by the number of tests (e.g. 225 pathways x 225 pathways = 50,625) and then the original p-vals are compared to the adjusted alpha value\n",
    "\n",
    "Method 2: The alpha value remains unchanged and the individual p-values are adjusted (i.e. original p-value x number of tests) to increase them, and then compared to see if they cross the 0.05 significance level\n",
    "\n",
    "After adjustment, some corrected p-values go up to 1 (the maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b693f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform multiple testing correlation on p-values after the duplicates are removed\n",
    "\n",
    "#All self-comparisons are significant with a p-value of 0, so we can subtract those from the number of significant values before we divide by 2\n",
    "sig_vals = (sum(i < 0.005 for i in spearman_df.pval_adj)-len(kpca_scores.columns))   /2\n",
    "non_sig_vals = sum(i >= 0.005 for i in spearman_df.pval_adj)/2\n",
    "\n",
    "print(\"Number of significant values:\", sig_vals)\n",
    "print(\"Number of non-significant values:\", non_sig_vals)\n",
    "(sig_vals/(sig_vals+non_sig_vals)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85921c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_spearman_coef = np.square(spearman_coef)\n",
    "abs_spearman_coef = np.abs(spearman_coef)\n",
    "spearman_hist = duplicate_removal(squared_spearman_coef)  #using a function I defined in the intro section\n",
    "\n",
    "print(len(spearman_hist))\n",
    "sns.histplot(spearman_hist, bins = 50,color='#FFD580',edgecolor=\"k\") \n",
    "\n",
    "plt.title('Spearman correlation coefficient distribution',fontsize=16)\n",
    "plt.xlabel('Correlation score',fontsize=16, labelpad=5)\n",
    "plt.ylabel('Count',fontsize=16, labelpad=10) ;\n",
    "\n",
    "#plt.savefig('Figures/metabolite_spearman_correlation_distribution_squared_non_dup.png' , dpi=200,bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e6c717-2b84-4c48-8864-bc32bc5a2b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#The reason for plotting as absolute or squared is that kPCA does not determine the directionality of effect\n",
    "#Therefore the direction specified here is arbitrary i.e. negative pathway score does not mean downregulation of pathway\n",
    "\n",
    "\n",
    "g = sns.clustermap(\n",
    "    squared_spearman_coef,\n",
    "    metric='euclidean', \n",
    "    method =\"ward\",\n",
    "    cmap=\"OrRd\",    #Spectral_r for normal,  OrRd for the other two\n",
    "    xticklabels=False,\n",
    "    yticklabels=False,\n",
    "    figsize=(6,6),\n",
    "    dendrogram_ratio=0.15, \n",
    "    vmin=0, \n",
    "    vmax=1) \n",
    "\n",
    "g2 = g.ax_heatmap\n",
    "g2.set_xlabel(\"Pathways\", fontsize = 17, labelpad=10) #labelpad increases the distance between the axis label and the heatmap\n",
    "g2.set_ylabel(\"Pathways\", fontsize = 17, labelpad=10) \n",
    "\n",
    "x0, _y0, _w, _h = g.cbar_pos\n",
    "g.ax_cbar.set_position([1.1, 0.25, 0.03, 0.35])\n",
    "g.cax.set_title(\"Correlation score\",pad=13,size=13) #pad: increase spacing slightly  \n",
    "g.cax.tick_params(labelsize=12) #change font size of colourbar labels; \n",
    "\n",
    "#plt.savefig( 'Figures/squared_metabolite_spearman.png' , dpi=200,bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cee5cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the Spearman p-values\n",
    "np.seterr(divide = 'ignore')    \n",
    "log_spearman_pvals = -np.log10(spearman_pvals)\n",
    "np.seterr(divide = 'warn') \n",
    "\n",
    "spearman_pval_hist = duplicate_removal(log_spearman_pvals)  #Some inf values that are not plotted (too far along axis)\n",
    "print(len(spearman_pval_hist))\n",
    "sns.histplot(spearman_pval_hist, bins = 50,color='#FFD580',edgecolor=\"k\") \n",
    "\n",
    "plt.title('Spearman p-value distribution',fontsize=16)\n",
    "plt.xlabel('Spearman p-values (-log10)',fontsize=16, labelpad=5)\n",
    "plt.ylabel('Count',fontsize=16, labelpad=10) ;\n",
    "\n",
    "#plt.savefig('Figures/metabolite_spearman_pval_distribution_non_dup.png' , dpi=200,bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e52b3128",
   "metadata": {},
   "source": [
    "### Overlap coefficients"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc3e5db1",
   "metadata": {},
   "source": [
    "I believe that sspa kPCA automatically filters out all pathways that have less than 2 compounds in them (confirmed since the pathway with the minimum number of metabolites had 2 compounds). When I filter out the compounds that are not in the dataset, I only include them into the new dictionary if the values have more than 1 compound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30745c3-7ed5-440a-b24b-d6bce9d0e65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain pathways and corresponding metabolites for all Reactome pathways, store as dictionary\n",
    "orig_dict = sspa.utils.pathwaydf_to_dict(reactome_pathways)\n",
    "\n",
    "#Filter out dictionary to retain only the pathways that remain after kPCA\n",
    "my_keys = kpca_scores.columns\n",
    "pathways_dict = {key: orig_dict[key] for key in my_keys}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f085493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out the compounds in the pathways that are not present in the dataset\n",
    "\n",
    "#Obtain all unique values in dataset\n",
    "compounds_present = list(df.columns[:-2])\n",
    "filtered_dict = {} \n",
    "\n",
    "#My code adapted from Cecilia's\n",
    "#If the key values are not part of the compounds in dataset then remove\n",
    "for key,value in pathways_dict.items():\n",
    "    new_val = [item for item in value if item in compounds_present]\n",
    "    if len(new_val) >= 2: #at least two compounds in the pathway\n",
    "        filtered_dict[key] = new_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c53a4ec-046f-4cc1-b4d5-b02c9a7b4b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifying all duplicate pathways from the Reactome pathway dictionary AFTER COMPOUNDS NOT IN PATHWAY REMOVED (the exact same metabolites, not subsets)\n",
    "\n",
    "metabolites = list(filtered_dict.values())\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "c = Counter(map(tuple,metabolites))\n",
    "dups = [k for k,v in c.items() if v>1]\n",
    "result = [list(t) for t in dups]\n",
    "\n",
    "for j in result:\n",
    "    value = {i for i in filtered_dict if filtered_dict[i]==j}\n",
    "    print(value)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec4aa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the pathways with the minimum and maximum number of metabolites in pathways AFTER COMPOUNDS NOT IN PATHWAY REMOVED\n",
    "\n",
    "max_len = max(metabolites, key=len)\n",
    "print(len(max_len))\n",
    "\n",
    "min_len = min(metabolites, key=len)\n",
    "print(len(min_len))\n",
    "\n",
    "\n",
    "for index in range(0,len(metabolites)):\n",
    "    length = 33\n",
    "    value = {key for key in filtered_dict if len(filtered_dict[key])==length}\n",
    "print(value)\n",
    "\n",
    "#len(filtered_dict['R-HSA-1430728'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d5c35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking Overlap coefficient code for the cell below\n",
    "\n",
    "list1 = ['A','B','C','D','E','F','G']\n",
    "list2 = ['A','B','C','J','K','L','M','N']\n",
    "intersection = list(set(list1).intersection(list(set(list2))))  #set removes duplicates\n",
    "numerator = len(intersection)\n",
    "\n",
    "smaller_set = []\n",
    "smaller_set.append(len(list1))\n",
    "smaller_set.append(len(list2))\n",
    "denominator = min(smaller_set)\n",
    "\n",
    "val = (numerator/denominator)\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c80e27a-1aa9-43b5-9aa6-f172f599ec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Difference between Jaccard similarity metric and S-S Overlap Coefficient\n",
    "#https://developer.nvidia.com/blog/similarity-in-graphs-jaccard-versus-the-overlap-coefficient/\n",
    "\n",
    "#Using Overlap Coefficient formula \n",
    "#My original code is in 'Overlap_coefficient_ver83.ipynb'\n",
    "#I adapted by code by looking at Cecilia's comments\n",
    "oc_matrix = np.zeros((len(my_keys),len(my_keys)))    \n",
    "\n",
    "for i in range(0,len(my_keys)):   \n",
    "    list1 = filtered_dict[my_keys[i]]\n",
    "    \n",
    "    for j in range(0,len(my_keys)):\n",
    "        list2 = filtered_dict[my_keys[j]]\n",
    "\n",
    "        # Szymkiewicz–Simpson coefficient\n",
    "        #Find intersection between two lists\n",
    "        intersection = len(list(set(list1).intersection(list(set(list2)))))\n",
    "        smaller_set = min(len(list1), len(list2))\n",
    "\n",
    "        val = intersection/smaller_set\n",
    "        oc_matrix[i][j] = val \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f93a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "oc_df = pd.DataFrame(oc_matrix, index=filtered_dict.keys(), columns=filtered_dict.keys())\n",
    "#Calculate number of edges with values above or equal to 0.5\n",
    "\n",
    "#If looking at whole matrix (not accounting for self comparisons or duplicates)\n",
    "#print(np.count_nonzero(oc_matrix >= 0.5)/(len(my_keys)*len(my_keys)))\n",
    "\n",
    "#Subtract by number of self-comparisons divided by 2\n",
    "high_overlap = (np.count_nonzero(oc_matrix >= 0.5) - len(my_keys)) / 2\n",
    "unique_edges =  ((len(my_keys)*len(my_keys)) - len(my_keys)) / 2\n",
    "\n",
    "print(high_overlap  /  unique_edges) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8282403",
   "metadata": {},
   "outputs": [],
   "source": [
    "oc_list = oc_df.stack().reset_index()\n",
    "oc_list.columns = [\"Pathway1\", \"Pathway2\", \"Overlap_coef\"]\n",
    "spearman_df = spearman_df.merge(oc_list,on=[\"Pathway1\",\"Pathway2\"])\n",
    "\n",
    "display(spearman_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3898459-ba00-4ac2-9a6e-c09bcf9fb1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.clustermap(oc_matrix,\n",
    "metric='euclidean', \n",
    "method =\"ward\",\n",
    "cmap = \"OrRd\", \n",
    "xticklabels=False, \n",
    "yticklabels=False, \n",
    "figsize=(6,6),\n",
    "dendrogram_ratio=0.2, \n",
    "vmin=-0, \n",
    "vmax=1) \n",
    "\n",
    "g2 = g.ax_heatmap\n",
    "g2.set_xlabel(\"Pathways\", fontsize = 17, labelpad=10) #labelpad increases the distance between the axis label and the heatmap\n",
    "g2.set_ylabel(\"Pathways\", fontsize = 17, labelpad=10) \n",
    "g2.set(yticklabels=[])  #remove tick labels\n",
    "g2.tick_params(right=False) #remove ticks\n",
    "\n",
    "x0, _y0, _w, _h = g.cbar_pos\n",
    "g.ax_cbar.set_position([1.15, 0.25, 0.03, 0.35])\n",
    "g.cax.set_title(\"Overlap Coefficient\",pad=13,size=13) #pad: increase spacing slightly  \n",
    "g.cax.tick_params(labelsize=12) #change font size of colourbar labels; \n",
    "\n",
    "#plt.savefig( 'Figures/metabolite_overlap_coef.png' , dpi=200,bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b89411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the overlap coefficient\n",
    "\n",
    "oc_hist = duplicate_removal(oc_matrix)\n",
    "print(len(oc_hist))\n",
    "sns.histplot(oc_hist, bins = 50,color='#FFD580',edgecolor=\"k\") \n",
    "\n",
    "plt.title('Overlap coefficient distribution',fontsize=16)\n",
    "plt.xlabel('Overlap coefficient',fontsize=16, labelpad=5)\n",
    "plt.ylabel('Count',fontsize=16, labelpad=10) ;\n",
    "\n",
    "#plt.savefig('Figures/metabolite_overlap_coef_distribution_non_dup.png' , dpi=200,bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363120c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f, ax = plt.subplots()\n",
    "points = ax.scatter(x=oc_hist, y=spearman_pval_hist,c=spearman_hist, s=4, cmap=\"viridis\",alpha=0.3)\n",
    "\n",
    "cb = plt.colorbar(points, ticks=[0,0.2,0.4,0.6,0.8,1],shrink=0.5)\n",
    "cb.ax.set_position([0.9, 0.28, 0.03, 0.35])\n",
    "cb.ax.set_title('Spearman correlation',pad=10, size=10) #pad means the height of title away from colourbar\n",
    "\n",
    "\n",
    "plt.xlabel(\"Overlap coefficient\",fontsize=13, labelpad=5)\n",
    "plt.ylabel(\"Spearman p-values (-l0g10)\",fontsize=13, labelpad=10) \n",
    "\n",
    "plt.axvline(x=0.5, color='r', linewidth=0.3, linestyle='-')\n",
    "plt.axhline(y=-np.log10(0.005), color='r', linewidth=0.3, linestyle='-') ;\n",
    "\n",
    "#plt.savefig('Figures/metabolite_scatterplot.png' ,dpi=200,bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22dbd969",
   "metadata": {},
   "source": [
    "### Constructing overlap coefficient network graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878433ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Practice code\n",
    "#Even for an edge going between two pathways, it's a single line here and in Cytoscape as well\n",
    "#If you wanted to draw multiple edges going between the same two nodes, you would need to draw a multigraph\n",
    "G = nx.Graph()\n",
    "\n",
    "practice_df = {'Pathway1': ['A', 'B', 'C', 'D','D'], 'Pathway2': ['B','A','D','C','D'], 'weight': [1,1,2,5,3]}\n",
    "pd.DataFrame(data=practice_df, index=[0, 1, 2, 3,4])\n",
    "\n",
    "G = nx.from_pandas_edgelist(df=practice_df, source='Pathway1', target='Pathway2', edge_attr='weight')\n",
    "\n",
    "nx.draw(G, with_labels = True)\n",
    "\n",
    "#nx.write_gml(G, \"test.gml\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c2ad143",
   "metadata": {},
   "source": [
    "Using Cecilia's code\n",
    "\n",
    "Note: I don't remove the duplicate edges for the overlap coefficient graph, they seemed to be removed during NetworkX graph construction.\n",
    "I do remove the diagonals though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283ff6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove self-correlations\n",
    "spearman_df = spearman_df [spearman_df.Pathway1 != spearman_df.Pathway2]\n",
    "spearman_df = spearman_df.reset_index(drop=True)\n",
    "spearman_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eda382",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Add the nodes\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(oc_df.columns)\n",
    "\n",
    "#does not deal with duplicates i.e.  Pathway 1 to Pathway 2 and vice versa\n",
    "#but it's ok, because it shows up as one edge on the network in Cytoscape\n",
    "\n",
    "G = nx.from_pandas_edgelist(df=spearman_df, source='Pathway1', target='Pathway2', edge_attr='Overlap_coef')\n",
    "\n",
    "nx.draw(G, with_labels = True)\n",
    "print(G.number_of_edges())\n",
    "print(G.number_of_nodes())\n",
    "#nx.write_gml(G, \"Cytoscape/metabolomic_oc.gml\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6989a09e",
   "metadata": {},
   "source": [
    "### Final correlation network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1eb0a31",
   "metadata": {},
   "source": [
    "Remember to take the corrected Spearman p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71983133",
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_df\n",
    "\n",
    "#spearman_df.to_csv(\"Data/metabolomic_edgelist_df_all.csv\")\n",
    "#spearman_df.to_csv(\"Data/metabolomic_edgelist_df_commoncases.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e063c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAKE A GRAPH WITH ALL THE EDGES FOR THE INTEGRATION STAGE\n",
    "\n",
    "G = nx.Graph()\n",
    "G = nx.from_pandas_edgelist(df=spearman_df, source='Pathway1', target='Pathway2', edge_attr='Squared_corr')\n",
    "#G.add_nodes_from(isolated_nodes)\n",
    "nx.draw(G, with_labels = True)\n",
    "print(G.number_of_nodes())\n",
    "print(G.number_of_edges())\n",
    "\n",
    "\n",
    "#Add edge attributes\n",
    "spearman_pval_dict = {}\n",
    "overlap_coef_dict = {}\n",
    "for i in range(0,len(spearman_df)):\n",
    "    spearman_pval_dict[(spearman_df.Pathway1[i],spearman_df.Pathway2[i])] = spearman_df.pval_adj[i]\n",
    "    overlap_coef_dict[(spearman_df.Pathway1[i],spearman_df.Pathway2[i])] = spearman_df.Overlap_coef[i]\n",
    "\n",
    "\n",
    "nx.set_edge_attributes(G, spearman_pval_dict, \"Spearman_pval\")\n",
    "nx.set_edge_attributes(G, overlap_coef_dict, \"Overlap_coef\")\n",
    "\n",
    "G.edges[\"R-HSA-110331\",\"R-HSA-112310\"]#[\"Spearman_pval\"]\n",
    "\n",
    "#nx.write_gml(G,'Cytoscape/metabolomic_prefiltered.gml')\n",
    "#nx.write_gml(G,'Cytoscape/metabolomic_prefiltered_severecases.gml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be76d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create EDGE ATTRIBUTES table to filter out unneeded edges\n",
    "\n",
    "final_df = spearman_df[spearman_df[\"pval_adj\"] < 0.005]  \n",
    "final_df = final_df[final_df[\"Overlap_coef\"] < 0.5]\n",
    "final_df = final_df.reset_index(drop=True) \n",
    "display(final_df) #the duplicate edges have not been removed yet\n",
    "\n",
    "#In some instances, I have nodes which have no edges, and the results are different to Sara's\n",
    "#Can check the pathways prior to Overlap Coefficient filtering here\n",
    "#final_df[final_df[\"Pathway1\"] == \"R-HSA-196854\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "148b11aa",
   "metadata": {},
   "source": [
    "Plot spearman correlation histogram to show edges AFTER filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fda1e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplicates in the edge list\n",
    "\n",
    "final_df_copy = final_df.copy()\n",
    "\n",
    "#Remove duplicate pathways\n",
    "for i in range(0,len(final_df)):\n",
    "    val1 = final_df.Pathway1[i]\n",
    "    val2 = final_df.Pathway2[i]\n",
    "    #print(val1,val2)\n",
    "    #print(max(val1,val2))\n",
    "    final_df_copy.Pathway1[i] = min(val1,val2)\n",
    "    final_df_copy.Pathway2[i] = max(val1,val2)\n",
    "\n",
    "final_df_copy = final_df_copy.sort_values(['Pathway1','Pathway2'], ascending=True)\n",
    "final_df_copy = final_df_copy[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe4cd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(final_df_copy))\n",
    "spearman_hist = list(final_df_copy.Squared_corr)\n",
    "sns.histplot(spearman_hist, bins = 50,color='#FFD580',edgecolor=\"k\") \n",
    "\n",
    "plt.title('Spearman correlation coefficient distribution',fontsize=16)\n",
    "plt.xlabel('Correlation score',fontsize=16, labelpad=5)\n",
    "plt.ylabel('Count',fontsize=16, labelpad=10) ;\n",
    "\n",
    "#plt.savefig('Figures/metabolite_spearman_correlation_distribution_squared_afterfiltering.png' , dpi=200,bbox_inches = 'tight' , pad_inches = 0.2 , facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050718e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathways_with_edges = set(final_df.Pathway1)\n",
    "isolated_nodes = set(spearman_df.Pathway1) - set(pathways_with_edges) \n",
    "isolated_nodes\n",
    "#len(pathways_with_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07f55e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw network graph with new edges\n",
    "G = nx.Graph()\n",
    "G = nx.from_pandas_edgelist(df=final_df, source='Pathway1', target='Pathway2', edge_attr='Squared_corr')\n",
    "#G.add_nodes_from(isolated_nodes)\n",
    "nx.draw(G, with_labels = True)\n",
    "print(G.number_of_nodes())\n",
    "print(G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5bbcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Add edge attributes\n",
    "spearman_pval_dict = {}\n",
    "overlap_coef_dict = {}\n",
    "for i in range(0,len(final_df)):\n",
    "    spearman_pval_dict[(final_df.Pathway1[i],final_df.Pathway2[i])] = final_df.pval_adj[i]\n",
    "    overlap_coef_dict[(final_df.Pathway1[i],final_df.Pathway2[i])] = final_df.Overlap_coef[i]\n",
    "    \n",
    "nx.set_edge_attributes(G, spearman_pval_dict, \"Spearman_pval\")\n",
    "nx.set_edge_attributes(G, overlap_coef_dict, \"Overlap_coef\")\n",
    "\n",
    "#G.edges[\"R-HSA-110331\",\"R-HSA-112310\"]#[\"Spearman_pval\"]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "acbe3833",
   "metadata": {},
   "source": [
    "### Optional: Read in the metabolomic network to display the differential network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025379db",
   "metadata": {},
   "source": [
    "For the differential network, we aren't trying to remove the edges based off of overlap or Spearman p-value, but it's interesting to see which edges are significant in the differential network which were filtered out in the original naive networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d245a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gml(\"Cytoscape/metabolomic_prefiltered_commoncases.gml\")\n",
    "with open('Data/permutation_test_files_metabolomics/not_sig_edges.txt') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef40a025",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_to_remove = []\n",
    "\n",
    "edges = lines[0].split(\",\")\n",
    "edges\n",
    "\n",
    "for index in range(0,len(edges),2):\n",
    "    list1 = edges[index],(edges[index+1][1:])\n",
    "    edges_to_remove.append(tuple(list1))\n",
    "\n",
    "len(edges_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f75cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.remove_edges_from(edges_to_remove)\n",
    "print(G.number_of_nodes())\n",
    "print(G.number_of_edges())  \n",
    "G.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae51534",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_to_remove_pval = [(u,v) for u,v,e in G.edges(data=True) if (e['Spearman_pval'] >= 0.005)]\n",
    "print(len(edges_to_remove_pval))\n",
    "edges_to_remove_pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2253cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_to_remove_oc = [(u,v) for u,v,e in G.edges(data=True) if (e['Overlap_coef'] >= 0.5)]\n",
    "print(len(edges_to_remove_oc))\n",
    "edges_to_remove_oc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f48dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(set(edges_to_remove_pval).intersection(set(edges_to_remove_oc)))) #After filtering out the nonsignificant edges from the permutations, 6 of the edges from the metabolomic common case dataset have Spearman p-val >= 0.005 and OC >= 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61134518",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_to_remove = [(u,v) for u,v,e in G.edges(data=True) if (e['Spearman_pval'] >= 0.005 or e['Overlap_coef'] >= 0.5)]\n",
    "G.remove_edges_from(edges_to_remove)\n",
    "print(G.number_of_nodes())\n",
    "print(G.number_of_edges())\n",
    "G.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42beb5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_to_remove = list(nx.isolates(G))\n",
    "G.remove_nodes_from(nodes_to_remove)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab94625d",
   "metadata": {},
   "source": [
    "### Setting node attributes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4cb53d6",
   "metadata": {},
   "source": [
    "The betweenness centrality scores are the same whether or not the duplicates have been removed since the duplicate edges form the same edge when a graph is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d880c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IF YOU DON'T REMOVE THE EDGES, DON'T RUN THIS CODE\n",
    "\n",
    "#Add the betweenness centrality as a node attribute\n",
    "betweenness= nx.betweenness_centrality(G, normalized=True) #output as dictionary\n",
    "#display(betweenness)\n",
    "nx.set_node_attributes(G, betweenness, \"betweenness\")\n",
    "\n",
    "#Add the betweenness centrality as a node attribute\n",
    "degree= nx.degree_centrality(G) #output as dictionary\n",
    "#display(degree)\n",
    "nx.set_node_attributes(G, degree, \"degrees\")\n",
    "\n",
    "\n",
    "#Check\n",
    "print(G.number_of_nodes()) \n",
    "#G.nodes['R-HSA-110331']#[\"betweenness\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6f1749e",
   "metadata": {},
   "source": [
    "Setting the highest level of the pathway hierarchy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a412bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Cecilia's code\n",
    "\n",
    "#Creating graph\n",
    "hierarchy = pd.read_csv('Data/ReactomePathwaysRelation.txt', sep='\\t', header=None)\n",
    "\n",
    "#From the pathways, subset to Homo sapiens only\n",
    "hierarchy_hsa = hierarchy[hierarchy[0].str.contains('HSA')]\n",
    "\n",
    "#Return unique values in the first column that is not in the second column as a numpy array\n",
    "#These values are not child pathways in any instances\n",
    "hierarchy_hsa_parents = np.setdiff1d(hierarchy_hsa[0], hierarchy_hsa[1])\n",
    "\n",
    "#Add the unique values not in the second column as a second attached dataset to the bottom of the original data\n",
    "#The first column represents the parent column, the second column is the child column\n",
    "hierarchy_hsa_all = pd.concat([hierarchy_hsa, pd.DataFrame([hierarchy_hsa_parents, hierarchy_hsa_parents], index=[0, 1]).T])\n",
    "\n",
    "#DiGraph is a directed graph\n",
    "H = nx.from_pandas_edgelist(hierarchy_hsa, source=0, target=1, create_using=nx.DiGraph())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69b9d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the root pathway\n",
    "\n",
    "def find_root(H,child):\n",
    "    #Find parent from child \n",
    "    parent = list(H.predecessors(child))\n",
    "\n",
    "    #Keep the loop going until the highest level is reached\n",
    "    if len(parent) == 0:\n",
    "        return child\n",
    "    else:  \n",
    "        return find_root(H, parent[0])\n",
    "\n",
    "hierarchy_hsa_all['Root'] = [find_root(H, i) for i in hierarchy_hsa_all[1]]\n",
    "\n",
    "hierarchy_hsa_all.columns = ['Parent', 'Child', 'Root']\n",
    "\n",
    "#There are 83 instances of duplicates, however all the child duplicates have the same root (even though different parents) after checking\n",
    "\n",
    "root_pathways = {}\n",
    "for pathway in list(H.nodes):\n",
    "    index = hierarchy_hsa_all.Child[hierarchy_hsa_all.Child == pathway].index.tolist()[0]\n",
    "    root_pathway  = hierarchy_hsa_all.Root[index]\n",
    "    label = root_pathway_dict[root_pathway]\n",
    "    root_pathways[pathway] = label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbae7a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shows all the root pathways in Reactome\n",
    "set(hierarchy_hsa_all['Root'] )\n",
    "#Shows all the root pathways present in the original dataset\n",
    "set(root_pathways.values())\n",
    "\n",
    "nx.set_node_attributes(G, root_pathways, \"root_pathway\")\n",
    "\n",
    "print(G.number_of_nodes()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289364bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for some reason, not sure if really clustering by weight since it works with a typo \n",
    "#i think it works though, since changing the name gives a diff num of clusters even with seed set\n",
    "#Resolution = 1 is the default, increasing resolution will yield more communities\n",
    "louvain_clusters = nx.community.louvain_communities(G, weight='Squared_corr',seed=100,resolution=1.2)\n",
    "print(len(louvain_clusters))\n",
    "\n",
    "louvain_dict = {}\n",
    "for index,grouping in enumerate(louvain_clusters):\n",
    "    for pathway in grouping:\n",
    "        louvain_dict[pathway] = index+1\n",
    "\n",
    "nx.set_node_attributes(G, louvain_dict, \"louvain\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5f1a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reactome_pathways = sspa.process_gmt(\"Data/Reactome_Homo_sapiens_pathways_compounds_R84.gmt\")\n",
    "\n",
    "pathway_name_dict = {reactome_pathways.index[i]:reactome_pathways[\"Pathway_name\"][i] for i in range(0,len(reactome_pathways))}\n",
    "pathway_name_dict['R-HSA-1483257']\n",
    "pathway_name_dict = {k:pathway_name_dict[k] for k in list(G.nodes)}\n",
    "\n",
    "nx.set_node_attributes(G, pathway_name_dict, \"pathway_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d896c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(G.number_of_nodes())\n",
    "print(G.number_of_edges())\n",
    "\n",
    "print(G.nodes['R-HSA-110331'])#[\"betweenness\"]\n",
    "print(G.edges[\"R-HSA-110331\", \"R-HSA-112310\"])#[\"Spearman_pval\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dae2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nx.write_gml(G,'Cytoscape/metabolomic_final.gml')\n",
    "#nx.write_gml(G,'Cytoscape/metabolomic_final_severecases.gml')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
