{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spearman correlation coefficient p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spearman correlation coefficient\n",
    "\n",
    "#OUTPUT IS A DATAFRAME\n",
    "#SEE CELL BELOW FOR OUTPUT AS NUMPY ARRAY\n",
    "\n",
    "#Mask the upper half of the dataframe\n",
    "mask =  spearman_pvals\n",
    "mask = np.triu(np.ones(mask.shape)).astype(bool)\n",
    "mask = np.invert(mask) #invert true and false values so the diagonal is False as well\n",
    "#display(pd.DataFrame(mask[:8,:8]))\n",
    "\n",
    "\n",
    "non_dup_spearman_pvals = pd.DataFrame(spearman_pvals)\n",
    "non_dup_spearman_pvals = non_dup_spearman_pvals.where(mask) #Replace all false values with NaN using mask\n",
    "#Uncorrected p-values in dataframe format\n",
    "#display(non_dup_spearman_pvals)\n",
    "\n",
    "\n",
    "#Corrected p-values in dataframe format\n",
    "corrected_non_dup_spearman_pvals = non_dup_spearman_pvals*12720 \n",
    "#12720 values = ((160*160) - 160 (e.g.Gene 1 compared to Gene 1)) divided by 2\n",
    "corrected_non_dup_spearman_pvals = pd.DataFrame(data=corrected_non_dup_spearman_pvals.values, columns=kpca_scores.columns,index=kpca_scores.columns)\n",
    "display(corrected_non_dup_spearman_pvals)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final correlation network - Removing duplicates in the edge list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplicates in the edge list\n",
    "\n",
    "edgelist_copy = edgelist.copy()\n",
    "\n",
    "#Remove duplicate pathways\n",
    "for i in range(0,len(edgelist)):\n",
    "    val1 = edgelist.Pathway1[i]\n",
    "    val2 = edgelist.Pathway2[i]\n",
    "    #print(val1,val2)\n",
    "    #print(max(val1,val2))\n",
    "    edgelist_copy.Pathway1[i] = min(val1,val2)\n",
    "    edgelist_copy.Pathway2[i] = max(val1,val2)\n",
    "\n",
    "\n",
    "edgelist_copy = edgelist_copy.sort_values(['Pathway1','Pathway2'], ascending=True)\n",
    "\n",
    "edgelist_copy = edgelist_copy[::2]\n",
    "display(edgelist_copy[:20])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating percentage of significant values when I use the full number of test (n x n) rather than multiplying by the number if independent tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform multiple testing correction on p-values without the duplicates being removed (just to check how much accounting for duplicates affects the number of metabolites retained)\n",
    "\n",
    "#Work out how many values are significant or not significant before multiple testing correction \n",
    "#Note: This is to check percentage of significant values BEFORE DUPLICATES ARE REMOVED\n",
    "print(\"Number of significant values before correction and before duplicate removal:\",(spearman_pvals < 0.005).sum() )\n",
    "print(\"Number of non-significant values before correction and before duplicate removal:\",(spearman_pvals >= 0.005).sum())\n",
    "\n",
    "\n",
    "#Using statsmodels package to do multiple testing correction\n",
    "#Remember to flatten dataframe into one-dimensional array\n",
    "corrected_pvals = statsmodels.stats.multitest.multipletests(spearman_pvals.flatten(), alpha=0.05, method='bonferroni')\n",
    "sig_vals = corrected_pvals[1]  #[0] is boolean, [1] are p-values\n",
    "#display(sig_vals)\n",
    "\n",
    "print(\"Number of significant values:\",(sig_vals < 0.005).sum())\n",
    "print(\"Number of non-significant values:\", (sig_vals >= 0.005).sum())\n",
    "\n",
    "#----------------------------------------------------------------\n",
    "\n",
    "\n",
    "#Perform multiple testing correlation on p-values after the duplicates are removed\n",
    "\n",
    "#Checking how many values are significant after multiple testing correction\n",
    "\n",
    "#Mask the upper half of the dataframe\n",
    "mask =  spearman_pvals\n",
    "mask = np.triu(np.ones(mask.shape)).astype(bool)\n",
    "mask = np.invert(mask)\n",
    "\n",
    "#Calculates the corrected p-values as a one-dimensional numpy array\n",
    "non_dup_spearman_pvals = spearman_pvals[mask]\n",
    "\n",
    "#https://tedboy.github.io/statsmodels_doc/generated/statsmodels.stats.multitest.multipletests.html#statsmodels.stats.multitest.multipletests\n",
    "print(\"Number of significant values before correction and after duplicate removal:\",sum(i < 0.005 for i in non_dup_spearman_pvals))\n",
    "print(\"Number of non-significant values before correction and after duplicate removal:\",sum(i >= 0.005 for i in non_dup_spearman_pvals))\n",
    "#print(non_dup_spearman_pvals)\n",
    "\n",
    "#Using statsmodels package\n",
    "corrected_non_dup_pvals = statsmodels.stats.multitest.multipletests(non_dup_spearman_pvals, method='bonferroni')\n",
    "sig_vals = corrected_non_dup_pvals[1]\n",
    "#display(sig_vals)\n",
    "\n",
    "print(\"Number of significant values:\",(sig_vals < 0.005).sum())\n",
    "print(\"Number of non-significant values:\", (sig_vals >= 0.005).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking how many values are significant after multiple testing correction\n",
    "\n",
    "#Mask the upper half of the dataframe\n",
    "mask =  spearman_pvals\n",
    "mask = np.triu(np.ones(mask.shape)).astype(bool)\n",
    "mask = np.invert(mask)\n",
    "\n",
    "#Calculates the corrected p-values as a one-dimensional numpy array\n",
    "non_dup_spearman_pvals = spearman_pvals[mask]\n",
    "\n",
    "#https://tedboy.github.io/statsmodels_doc/generated/statsmodels.stats.multitest.multipletests.html#statsmodels.stats.multitest.multipletests\n",
    "print(\"Number of significant values before correction:\",sum(i < 0.005 for i in non_dup_spearman_pvals))\n",
    "print(\"Number of non-significant values before correction:\",sum(i >= 0.005 for i in non_dup_spearman_pvals))\n",
    "#print(non_dup_spearman_pvals)\n",
    "\n",
    "#Using statsmodels package\n",
    "corrected_non_dup_pvals = statsmodels.stats.multitest.multipletests(non_dup_spearman_pvals, method='bonferroni')\n",
    "sig_vals = corrected_non_dup_pvals[1]\n",
    "#display(sig_vals)\n",
    "\n",
    "print(\"Number of significant values:\",(sig_vals < 0.005).sum())\n",
    "print(\"Number of non-significant values:\", (sig_vals >= 0.005).sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making an edgelist for NetworkX from a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Add the nodes\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(oc_df.columns)\n",
    "\n",
    "#Cecilia's code\n",
    "\n",
    "#does not deal with duplicates i.e.  Pathway 1 to Pathway 2 and vice versa\n",
    "#but it's ok, because it shows up as one edge on the network in Cytoscape\n",
    "\n",
    "np.fill_diagonal(oc_df.values, np.nan) #Make values on the diagonal NaN \n",
    "edgelist_oc = oc_df.stack().reset_index()\n",
    "edgelist_oc.columns = ['Pathway1', 'Pathway2', 'Weight'] \n",
    "G = nx.from_pandas_edgelist(df=edgelist_oc, source='Pathway1', target='Pathway2', edge_attr='Weight')\n",
    "\n",
    "nx.draw(G, with_labels = True)\n",
    "#nx.write_gml(G, \"metabolomic_oc.gml\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for reading in the permutation files and calculating p-values for each pathway pair"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permutation distribution from files that have been 'pickled' (using pickle package):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "#Download the initial test statistics\n",
    "df = pd.read_csv('metabolomics/Data/initial_tstats.csv', index_col=0)\n",
    "\n",
    "path = os.getcwd() + '/metabolomics/Results'\n",
    "\n",
    "final_list = []\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    if filename != 'initial_tstats.csv':\n",
    "        with open(os.path.join(path, filename), 'rb') as file: # open in readonly mode\n",
    "            list1 = pickle.load(file)\n",
    "        final_list.append(list1)\n",
    "\n",
    "\n",
    "\n",
    "sig_edges = []\n",
    "edgelist = df.index\n",
    "\n",
    "for index,pathway_pair in enumerate(edgelist):   #test all pathways\n",
    "    comparison = df.Initial_tstat[index]    #get initial test statistic\n",
    "    counter = 0\n",
    "    \n",
    "    for list1 in final_list:  #len(final_list) = number of permutations\n",
    "        if abs(list1[index]) >= comparison:   \n",
    "            counter += 1\n",
    "    \n",
    "    p_val = (counter/len(final_list))    #divide number of tests above or equal to the test statistic by total number of tests\n",
    "\n",
    "    if p_val < 0.01:  #for 100,000 permutations\n",
    "        sig_edges.append(pathway_pair)  \n",
    "        \n",
    "print(len(sig_edges))\n",
    "\n",
    "with open(\"metabolomics/Data/sig_edges.txt\", \"wb\") as file:   #Pickling (stores as list format instead of string, easier to read in later)\n",
    "      pickle.dump(sig_edges , file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating through each permutation file for each pathway, stores into one list then outputs pathway pair if significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "#Download the initial test statistics\n",
    "df = pd.read_csv('metabolomics/Data/initial_tstats.csv', index_col=0)\n",
    "\n",
    "path = os.getcwd() + '/metabolomics/Results'\n",
    "\n",
    "edgelist = df.index\n",
    "\n",
    "\n",
    "pathway_list = []\n",
    "sig_edges = []\n",
    "\n",
    "for index,pathway_pair in enumerate(edgelist[:5]):   #test all pathways\n",
    "    for filename in os.listdir(path):\n",
    "        if filename != 'initial_tstats.csv':\n",
    "            with open(os.path.join(path, filename)) as file:    \n",
    "                lines = file.readlines()\n",
    "                pathway_stat = float(lines[0].split(',')[index])\n",
    "                pathway_list.append(pathway_stat)\n",
    "    \n",
    "    print(pathway_list, pathway_pair)\n",
    "\n",
    "    comparison = df.Initial_tstat[index]    #get initial test statistic\n",
    "    print(comparison)\n",
    "    counter = 0\n",
    "    \n",
    "    for num in pathway_list:  #len(pathway_list) = number of permutations\n",
    "        if abs(num) >= comparison:   \n",
    "            counter += 1\n",
    "    \n",
    "    print(counter)\n",
    "    p_val = (counter/len(pathway_list))    #divide number of tests above or equal to the test statistic by total number of tests\n",
    "\n",
    "    if p_val < 0.01:  #for 100,000 permutations\n",
    "        sig_edges.append(pathway_pair)  \n",
    "\n",
    "    pathway_list = []\n",
    "\n",
    "print(sig_edges)\n",
    "\n",
    "with open ('metabolomics/Data/sig_edges.txt', 'w') as file:\n",
    "     file.write(','.join(str(i) for i in sig_edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculting number of absolute values above test statistic for metabolomic data, I had all 100k files in a folder (but changed to placing 10k into 10 instead):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "#Download the initial test statistics\n",
    "df = pd.read_csv('metabolomics/Data/initial_tstats.csv', index_col=0)\n",
    "\n",
    "path = os.getcwd() + '/metabolomics/Results_pickled_100k'\n",
    "\n",
    "pathway_list = []\n",
    "\n",
    "\n",
    "#Get the permutation values for randomly chosen pathway pairs\n",
    "\n",
    "index = random.randrange(0, len(df)) #Gives index from 0 to (len(df)-1), better for indexing with unpickled files which are stored as lists\n",
    "for filename in os.listdir(path):\n",
    "        if filename.startswith('Run'):\n",
    "            with open(os.path.join(path, filename),'rb') as file:\n",
    "                list1 = pickle.load(file)   \n",
    "                pathway_list.append(list1[index])\n",
    "with open('metabolomics/Data/test_distribution'+str(index)+'.txt', 'w') as file:\n",
    "    file.write(','.join(str(i) for i in pathway_list))\n",
    "pathway_list = []\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
